{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用协同过滤实现电影推荐\n",
    "\n",
    "**作者：** [HUANGCHENGAI](https://github.com/HUANGCHENGAI) <br>\n",
    "**日期：** 2021.03 <br>\n",
    "**摘要：** 本案例使用飞桨框架实现推荐电影的协同过滤算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、介绍\n",
    "\n",
    "此示例演示使用[Movielens 数据集](https://www.kaggle.com/c/movielens-100k)基于PaddlePaddle2.0向用户推荐电影的协作过滤算法。MovieLens 评级数据集列出了一组用户对一组电影的评分。目标是能够预测用户尚未观看的电影的收视率。然后，可以向用户推荐预测收视率最高的电影。\n",
    "\n",
    "模型中的步骤如下：\n",
    "\n",
    "    1.通过嵌入矩阵将用户 ID 映射到\"用户向量\"\n",
    "\n",
    "    2.通过嵌入矩阵将电影 ID 映射到\"电影载体\"\n",
    "\n",
    "    3.计算用户矢量和电影矢量之间的点产品，以获得用户和电影之间的匹配分数（预测评级）。\n",
    "\n",
    "    4.使用所有已知的用户电影对通过梯度下降训练嵌入。\n",
    "\n",
    "\n",
    "引用：\n",
    "\n",
    "+ [Item-based collaborative filtering recommendation algorithms](https://dl.acm.org/doi/pdf/10.1145/371920.372071)\n",
    "\n",
    "+ [Neural Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/3038912.3052569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、 环境设置\n",
    "\n",
    "本教程基于Paddle 2.0 编写，如果您的环境不是本版本，请先参考官网[安装](https://www.paddlepaddle.org.cn/install/quick) Paddle 2.0 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "from paddle.io import Dataset\r\n",
    "\r\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、数据集\n",
    "\n",
    "这个数据集（ml-latest-small）描述了[MovieLens](http://movielens.org)的五星评级和自由文本标记活动。它包含100836个收视率和3683个标签应用程序，涵盖9742部电影。这些数据由610名用户在1996年3月29日至2018年9月24日期间创建。\n",
    "\n",
    "该数据集于2018年9月26日生成，用户是随机选择的。所有选定的用户都对至少20部电影进行了评分。不包括人口统计信息。每个用户都由一个id表示，不提供其他信息。数据包含在文件中`links.csv`, `movies.csv`, `ratings.csv`以及`tags.csv`。\n",
    "\n",
    "**用户ID**\n",
    "\n",
    "MovieLens的用户是随机选择的\n",
    "\n",
    "**电影ID**\n",
    "\n",
    "数据集中只包含至少具有一个分级或标记的电影，这些电影id与MovieLens网站上使用的一致.。\n",
    "\n",
    "分级数据文件结构(ratings.csv)\n",
    "\n",
    "所有评级都包含在文件中`ratings.csv`. 文件头行后的每一行代表一个用户对一部电影的一个分级，格式如下：\n",
    "userId，movieId，rating，timestamp\n",
    "\n",
    "\n",
    "**标记数据文件结构(tags.csv)**\n",
    "\n",
    "文件中包含所有标记`tags.csv`. 文件头行后的每一行代表一个用户应用于一部电影的一个标记，格式如下：\n",
    "userId，movieId，tag，timestamp\n",
    "\n",
    "\n",
    "**电影数据文件结构(movies.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID、片名、类型\n",
    "\n",
    "**链接数据文件结构(links.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID，imdbId，tmdbId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/data71839/ml-latest-small.zip\r\n",
      "   creating: ml-latest-small/\r\n",
      "  inflating: ml-latest-small/links.csv  \r\n",
      "  inflating: ml-latest-small/tags.csv  \r\n",
      "  inflating: ml-latest-small/ratings.csv  \r\n",
      "  inflating: ml-latest-small/README.txt  \r\n",
      "  inflating: ml-latest-small/movies.csv  \r\n"
     ]
    }
   ],
   "source": [
    "!unzip data/data71839/ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1 数据处理\n",
    "\n",
    "执行一些预处理，将用户和电影编码为整数指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ml-latest-small/ratings.csv')\r\n",
    "user_ids = df[\"userId\"].unique().tolist()\r\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\r\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\r\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\r\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\r\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\r\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\r\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\r\n",
    "\r\n",
    "num_users = len(user2user_encoded)\r\n",
    "num_movies = len(movie_encoded2movie)\r\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\r\n",
    "# 最小和最大额定值将在以后用于标准化额定值\r\n",
    "min_rating = min(df[\"rating\"])\r\n",
    "max_rating = max(df[\"rating\"])\r\n",
    "\r\n",
    "print(\r\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\r\n",
    "        num_users, num_movies, min_rating, max_rating\r\n",
    "    )\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 准备训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (1,)\n",
      "[ 431 4730] [0.8888889]\n",
      "[128, 2]\n",
      "[128, 1]\n",
      "[128, 2]\n",
      "[128, 1]\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=42)\r\n",
    "x = df[[\"user\", \"movie\"]].values\r\n",
    "# 规范化0和1之间的目标。使训练更容易。\r\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\r\n",
    "# 假设对90%的数据进行训练，对10%的数据进行验证。\r\n",
    "train_indices = int(0.9 * df.shape[0])\r\n",
    "x_train, x_val, y_train, y_val = (\r\n",
    "    x[:train_indices],\r\n",
    "    x[train_indices:],\r\n",
    "    y[:train_indices],\r\n",
    "    y[train_indices:],\r\n",
    ")\r\n",
    "y_train = y_train[: ,np.newaxis]\r\n",
    "y_val = y_val[: ,np.newaxis]\r\n",
    "y_train = y_train.astype(np.float32)\r\n",
    "y_val = y_val.astype(np.float32)\r\n",
    "\r\n",
    "# 自定义数据集\r\n",
    "#映射式(map-style)数据集需要继承paddle.io.Dataset\r\n",
    "class SelfDefinedDataset(Dataset):\r\n",
    "    def __init__(self, data_x, data_y, mode = 'train'):\r\n",
    "        super(SelfDefinedDataset, self).__init__()\r\n",
    "        self.data_x = data_x\r\n",
    "        self.data_y = data_y\r\n",
    "        self.mode = mode\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        if self.mode == 'predict':\r\n",
    "           return self.data_x[idx]\r\n",
    "        else:\r\n",
    "           return self.data_x[idx], self.data_y[idx]\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.data_x)\r\n",
    "        \r\n",
    "traindataset = SelfDefinedDataset(x_train, y_train)\r\n",
    "for data, label in traindataset:\r\n",
    "    print(data.shape, label.shape)\r\n",
    "    print(data, label)\r\n",
    "    break\r\n",
    "train_loader = paddle.io.DataLoader(traindataset, batch_size = 128, shuffle = True)\r\n",
    "for batch_id, data in enumerate(train_loader()):\r\n",
    "    x_data = data[0]\r\n",
    "    y_data = data[1]\r\n",
    "\r\n",
    "    print(x_data.shape)\r\n",
    "    print(y_data.shape)\r\n",
    "    break\r\n",
    "\r\n",
    "testdataset = SelfDefinedDataset(x_val, y_val)\r\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 128, shuffle = True)        \r\n",
    "for batch_id, data in enumerate(test_loader()):\r\n",
    "    x_data = data[0]\r\n",
    "    y_data = data[1]\r\n",
    "\r\n",
    "    print(x_data.shape)\r\n",
    "    print(y_data.shape)\r\n",
    "    break\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、模型组网\n",
    "\n",
    "将用户和电影嵌入到 50 维向量中。\n",
    "\n",
    "该模型计算用户和电影嵌入之间的匹配分数，并添加每部电影和每个用户的偏差。比赛分数通过 sigmoid 缩放到间隔[0, 1]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\r\n",
    "\r\n",
    "class RecommenderNet(nn.Layer):\r\n",
    "    def __init__(self, num_users, num_movies, embedding_size):\r\n",
    "        super(RecommenderNet, self).__init__()\r\n",
    "        self.num_users = num_users\r\n",
    "        self.num_movies = num_movies\r\n",
    "        self.embedding_size = embedding_size\r\n",
    "        weight_attr_user = paddle.ParamAttr(\r\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\r\n",
    "            initializer = nn.initializer.KaimingNormal()\r\n",
    "            )\r\n",
    "        self.user_embedding = nn.Embedding(\r\n",
    "            num_users,\r\n",
    "            embedding_size,\r\n",
    "            weight_attr=weight_attr_user\r\n",
    "        )\r\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\r\n",
    "        weight_attr_movie = paddle.ParamAttr(\r\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\r\n",
    "            initializer = nn.initializer.KaimingNormal()\r\n",
    "            )\r\n",
    "        self.movie_embedding = nn.Embedding(\r\n",
    "            num_movies,\r\n",
    "            embedding_size,\r\n",
    "            weight_attr=weight_attr_movie\r\n",
    "        )\r\n",
    "        self.movie_bias = nn.Embedding(num_movies, 1)\r\n",
    "\r\n",
    "    def forward(self, inputs):\r\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\r\n",
    "        user_bias = self.user_bias(inputs[:, 0])\r\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\r\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\r\n",
    "        dot_user_movie = paddle.dot(user_vector, movie_vector)\r\n",
    "        x = dot_user_movie + user_bias + movie_bias\r\n",
    "        x = nn.functional.sigmoid(x)\r\n",
    "\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、模型训练\n",
    "\n",
    "后台可通过VisualDl观察Loss曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/5\n",
      "step  70/709 [=>............................] - loss: 0.6928 - acc: 0.8712 - ETA: 2s - 3ms/st"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT64, but right dtype is VarType.FP32, the right dtype will convert to VarType.INT64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 120/709 [====>.........................] - loss: 0.6908 - acc: 0.8718 - ETA: 1s - 3ms/stepstep 709/709 [==============================] - loss: 0.6730 - acc: 0.8687 - 3ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/0\n",
      "Epoch 2/5\n",
      "step 709/709 [==============================] - loss: 0.6548 - acc: 0.8687 - 3ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/1\n",
      "Epoch 3/5\n",
      "step 709/709 [==============================] - loss: 0.6267 - acc: 0.8687 - 3ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/2\n",
      "Epoch 4/5\n",
      "step 709/709 [==============================] - loss: 0.6012 - acc: 0.8687 - 3ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/3\n",
      "Epoch 5/5\n",
      "step 709/709 [==============================] - loss: 0.6231 - acc: 0.8687 - 3ms/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/4\n",
      "save checkpoint at /home/aistudio/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "model = paddle.Model(model)\r\n",
    "\r\n",
    "optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.0003)\r\n",
    "loss = nn.BCELoss()\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "\r\n",
    "# 设置visualdl路径\r\n",
    "log_dir = './visualdl'\r\n",
    "callback = paddle.callbacks.VisualDL(log_dir=log_dir)\r\n",
    "\r\n",
    "model.prepare(optimizer, loss, metric)\r\n",
    "model.fit(train_loader, epochs=5, save_dir='./checkpoints', verbose=1, callbacks=callback)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 79/79 [==============================] - loss: 0.5982 - acc: 0.8713 - 3ms/step         \n",
      "Eval samples: 10084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.INT64, but right dtype is VarType.FP32, the right dtype will convert to VarType.INT64\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.5982282], 'acc': 0.8712812376041253}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 1/1 [==============================] - 17ms/step\n",
      "Predict samples: 9492\n",
      "[ 280  261  318   43  230  472 2393 8253  964 1874]\n",
      "用户的ID为: 594\n",
      "================================\n",
      "用户评分较高的电影：\n",
      "--------------------------------\n",
      "Demolition Man (1993) : Action|Adventure|Sci-Fi\n",
      "Executive Decision (1996) : Action|Adventure|Thriller\n",
      "Matrix, The (1999) : Action|Sci-Fi|Thriller\n",
      "Bruce Almighty (2003) : Comedy|Drama|Fantasy|Romance\n",
      "Chasing Liberty (2004) : Comedy|Romance\n",
      "--------------------------------\n",
      "为用户推荐的10部电影：\n",
      "--------------------------------\n",
      "Usual Suspects, The (1995) : Crime|Mystery|Thriller\n",
      "Star Wars: Episode IV - A New Hope (1977) : Action|Adventure|Sci-Fi\n",
      "Pulp Fiction (1994) : Comedy|Crime|Drama|Thriller\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Forrest Gump (1994) : Comedy|Drama|Romance|War\n",
      "Schindler's List (1993) : Drama|War\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : Action|Adventure|Sci-Fi\n",
      "American History X (1998) : Crime|Drama\n",
      "Fight Club (1999) : Action|Crime|Drama|Thriller\n",
      "Dark Knight, The (2008) : Action|Crime|Drama|IMAX\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv('ml-latest-small/movies.csv')\r\n",
    "\r\n",
    "# 获取一个用户，查看他的推荐电影\r\n",
    "user_id = df.userId.sample(1).iloc[0]\r\n",
    "movies_watched_by_user = df[df.userId == user_id]\r\n",
    "movies_not_watched = movie_df[\r\n",
    "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\r\n",
    "][\"movieId\"]\r\n",
    "movies_not_watched = list(\r\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\r\n",
    ")\r\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\r\n",
    "user_encoder = user2user_encoded.get(user_id)\r\n",
    "user_movie_array = np.hstack(\r\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\r\n",
    ")\r\n",
    "testdataset = SelfDefinedDataset(user_movie_array, user_movie_array, mode = 'predict')\r\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 9703, shuffle = False, return_list=True,)   \r\n",
    "\r\n",
    "ratings = model.predict(test_loader)\r\n",
    "ratings = np.array(ratings)\r\n",
    "ratings = np.squeeze(ratings, 0)\r\n",
    "ratings = np.squeeze(ratings, 2)\r\n",
    "ratings = np.squeeze(ratings, 0)\r\n",
    "top_ratings_indices = ratings.argsort()[::-1][0:10]\r\n",
    "\r\n",
    "print(top_ratings_indices)\r\n",
    "recommended_movie_ids = [\r\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\r\n",
    "]\r\n",
    "\r\n",
    "print(\"用户的ID为: {}\".format(user_id))\r\n",
    "print(\"====\" * 8)\r\n",
    "print(\"用户评分较高的电影：\")\r\n",
    "print(\"----\" * 8)\r\n",
    "top_movies_user = (\r\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\r\n",
    "    .head(5)\r\n",
    "    .movieId.values\r\n",
    ")\r\n",
    "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\r\n",
    "for row in movie_df_rows.itertuples():\r\n",
    "    print(row.title, \":\", row.genres)\r\n",
    "\r\n",
    "print(\"----\" * 8)\r\n",
    "print(\"为用户推荐的10部电影：\")\r\n",
    "print(\"----\" * 8)\r\n",
    "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\r\n",
    "for row in recommended_movies.itertuples():\r\n",
    "    print(row.title, \":\", row.genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
