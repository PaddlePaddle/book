{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用协同过滤实现电影推荐\n",
    "\n",
    "**作者：** [HUANGCHENGAI](https://github.com/HUANGCHENGAI) <br>\n",
    "**日期：** 2021.06 <br>\n",
    "**摘要：** 本案例使用飞桨框架实现推荐电影的协同过滤算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、介绍\n",
    "\n",
    "此示例演示使用[Movielens 数据集](https://www.kaggle.com/c/movielens-100k)基于PaddlePaddle2.1向用户推荐电影的协作过滤算法。MovieLens 评级数据集列出了一组用户对一组电影的评分。目标是能够预测用户尚未观看的电影的收视率。然后，可以向用户推荐预测收视率最高的电影。\n",
    "\n",
    "模型中的步骤如下：\n",
    "\n",
    "    1.通过嵌入矩阵将用户 ID 映射到\"用户向量\"\n",
    "\n",
    "    2.通过嵌入矩阵将电影 ID 映射到\"电影载体\"\n",
    "\n",
    "    3.计算用户矢量和电影矢量之间的点产品，以获得用户和电影之间的匹配分数（预测评级）。\n",
    "\n",
    "    4.使用所有已知的用户电影对通过梯度下降训练嵌入。\n",
    "\n",
    "\n",
    "引用：\n",
    "\n",
    "+ [Item-based collaborative filtering recommendation algorithms](https://dl.acm.org/doi/pdf/10.1145/371920.372071)\n",
    "\n",
    "+ [Neural Collaborative Filtering](https://dl.acm.org/doi/pdf/10.1145/3038912.3052569)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、 环境设置\n",
    "\n",
    "本教程基于Paddle 2.1 编写，如果你的环境不是本版本，请先参考官网[安装](https://www.paddlepaddle.org.cn/install/quick) Paddle 2.1 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import Dataset\n",
    "print(paddle.__version__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、数据集\n",
    "\n",
    "这个数据集（ml-latest-small）描述了[MovieLens](http://movielens.org)的五星评级和自由文本标记活动。它包含100836个收视率和3683个标签应用程序，涵盖9742部电影。这些数据由610名用户在1996年3月29日至2018年9月24日期间创建。\n",
    "\n",
    "该数据集于2018年9月26日生成，用户是随机选择的。所有选定的用户都对至少20部电影进行了评分。不包括人口统计信息。每个用户都由一个id表示，不提供其他信息。数据包含在文件中`links.csv`, `movies.csv`, `ratings.csv`以及`tags.csv`。\n",
    "\n",
    "**用户ID**\n",
    "\n",
    "MovieLens的用户是随机选择的\n",
    "\n",
    "**电影ID**\n",
    "\n",
    "数据集中只包含至少具有一个分级或标记的电影，这些电影id与MovieLens网站上使用的一致.。\n",
    "\n",
    "分级数据文件结构(ratings.csv)\n",
    "\n",
    "所有评级都包含在文件中`ratings.csv`. 文件头行后的每一行代表一个用户对一部电影的一个分级，格式如下：\n",
    "userId，movieId，rating，timestamp\n",
    "\n",
    "\n",
    "**标记数据文件结构(tags.csv)**\n",
    "\n",
    "文件中包含所有标记`tags.csv`. 文件头行后的每一行代表一个用户应用于一部电影的一个标记，格式如下：\n",
    "userId，movieId，tag，timestamp\n",
    "\n",
    "\n",
    "**电影数据文件结构(movies.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID、片名、类型\n",
    "\n",
    "**链接数据文件结构(links.csv)**\n",
    "\n",
    "格式如下：\n",
    "电影ID，imdbId，tmdbId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-28 15:44:44--  https://bj.bcebos.com/v1/ai-studio-online/e1686458bb494866ab51d5e2738a68387d2aa14f31164735ae601eda5c7bc938?responseContentDisposition=attachment%3B%20filename%3Dml-latest-small.zip&authorization=bce-auth-v1%2F0ef6765c1e494918bc0d4c3ca3e5c6d1%2F2021-03-01T12%3A21%3A46Z%2F-1%2F%2F6dddaaacf7aa37c7445d3100844c71f9dd09fe938627f3ac86d0621e3f420f92\n",
      "Resolving bj.bcebos.com (bj.bcebos.com)... 10.70.0.165\n",
      "Connecting to bj.bcebos.com (bj.bcebos.com)|10.70.0.165|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/octet-stream]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "100%[======================================>] 978,202     3.27MB/s   in 0.3s   \n",
      "\n",
      "2021-06-28 15:44:45 (3.27 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n",
      "Archive:  ./ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "!wget -O ml-latest-small.zip https://bj.bcebos.com/v1/ai-studio-online/e1686458bb494866ab51d5e2738a68387d2aa14f31164735ae601eda5c7bc938\\?responseContentDisposition\\=attachment%3B%20filename%3Dml-latest-small.zip\\&authorization\\=bce-auth-v1%2F0ef6765c1e494918bc0d4c3ca3e5c6d1%2F2021-03-01T12%3A21%3A46Z%2F-1%2F%2F6dddaaacf7aa37c7445d3100844c71f9dd09fe938627f3ac86d0621e3f420f92\n",
    "!unzip ./ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 数据处理\n",
    "\n",
    "执行一些预处理，将用户和电影编码为整数指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "user_ids = df[\"userId\"].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df[\"movieId\"].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
    "df[\"movie\"] = df[\"movieId\"].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df[\"rating\"] = df[\"rating\"].values.astype(np.float32)\n",
    "# 最小和最大额定值将在以后用于标准化额定值\n",
    "min_rating = min(df[\"rating\"])\n",
    "max_rating = max(df[\"rating\"])\n",
    "\n",
    "print(\n",
    "    \"Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}\".format(\n",
    "        num_users, num_movies, min_rating, max_rating\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 准备训练和验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,) (1,)\n",
      "[ 431 4730] [0.8888889]\n",
      "[128, 2]\n",
      "[128, 1]\n",
      "[128, 2]\n",
      "[128, 1]\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[[\"user\", \"movie\"]].values\n",
    "# 规范化0和1之间的目标。使训练更容易。\n",
    "y = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "# 假设对90%的数据进行训练，对10%的数据进行验证。\n",
    "train_indices = int(0.9 * df.shape[0])\n",
    "x_train, x_val, y_train, y_val = (\n",
    "    x[:train_indices],\n",
    "    x[train_indices:],\n",
    "    y[:train_indices],\n",
    "    y[train_indices:],\n",
    ")\n",
    "y_train = y_train[: ,np.newaxis]\n",
    "y_val = y_val[: ,np.newaxis]\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "\n",
    "# 自定义数据集\n",
    "#映射式(map-style)数据集需要继承paddle.io.Dataset\n",
    "class SelfDefinedDataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, mode = 'train'):\n",
    "        super(SelfDefinedDataset, self).__init__()\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'predict':\n",
    "           return self.data_x[idx]\n",
    "        else:\n",
    "           return self.data_x[idx], self.data_y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "        \n",
    "traindataset = SelfDefinedDataset(x_train, y_train)\n",
    "for data, label in traindataset:\n",
    "    print(data.shape, label.shape)\n",
    "    print(data, label)\n",
    "    break\n",
    "train_loader = paddle.io.DataLoader(traindataset, batch_size = 128, shuffle = True)\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    break\n",
    "\n",
    "testdataset = SelfDefinedDataset(x_val, y_val)\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 128, shuffle = True)        \n",
    "for batch_id, data in enumerate(test_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "\n",
    "    print(x_data.shape)\n",
    "    print(y_data.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、模型组网\n",
    "\n",
    "将用户和电影嵌入到 50 维向量中。\n",
    "\n",
    "该模型计算用户和电影嵌入之间的匹配分数，并添加每部电影和每个用户的偏差。比赛分数通过 sigmoid 缩放到间隔[0, 1]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class RecommenderNet(nn.Layer):\n",
    "    def __init__(self, num_users, num_movies, embedding_size):\n",
    "        super(RecommenderNet, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        weight_attr_user = paddle.ParamAttr(\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\n",
    "            initializer = nn.initializer.KaimingNormal()\n",
    "            )\n",
    "        self.user_embedding = nn.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            weight_attr=weight_attr_user\n",
    "        )\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        weight_attr_movie = paddle.ParamAttr(\n",
    "            regularizer = paddle.regularizer.L2Decay(1e-6),\n",
    "            initializer = nn.initializer.KaimingNormal()\n",
    "            )\n",
    "        self.movie_embedding = nn.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            weight_attr=weight_attr_movie\n",
    "        )\n",
    "        self.movie_bias = nn.Embedding(num_movies, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = paddle.dot(user_vector, movie_vector)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        x = nn.functional.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、模型训练\n",
    "\n",
    "后台可通过VisualDl观察Loss曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/5\n",
      "step 709/709 [==============================] - loss: 0.6713 - acc: 0.8687 - 6ms/step          \n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/0\n",
      "Epoch 2/5\n",
      "step 709/709 [==============================] - loss: 0.6455 - acc: 0.8687 - 6ms/step          \n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/1\n",
      "Epoch 3/5\n",
      "step 709/709 [==============================] - loss: 0.6038 - acc: 0.8687 - 6ms/step          \n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/2\n",
      "Epoch 4/5\n",
      "step 709/709 [==============================] - loss: 0.6063 - acc: 0.8687 - 6ms/step          \n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/3\n",
      "Epoch 5/5\n",
      "step 709/709 [==============================] - loss: 0.5917 - acc: 0.8687 - 6ms/step          \n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/4\n",
      "save checkpoint at /home/chenlong21/online_repo/book/paddle2.0_docs/Collaborative_filtering/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "model = paddle.Model(model)\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=0.0003)\n",
    "loss = nn.BCELoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "# 设置visualdl路径\n",
    "log_dir = './visualdl'\n",
    "callback = paddle.callbacks.VisualDL(log_dir=log_dir)\n",
    "\n",
    "model.prepare(optimizer, loss, metric)\n",
    "model.fit(train_loader, epochs=5, save_dir='./checkpoints', verbose=1, callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "step 79/79 [==============================] - loss: 0.6109 - acc: 0.8713 - 4ms/step          \n",
      "Eval samples: 10084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.6108578], 'acc': 0.8712812376041253}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_loader, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n",
      "WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: \n",
      "\n",
      "import numpy as np\n",
      "from paddle.io import DataLoader, Dataset\n",
      "\n",
      "class RandomDataset(Dataset):\n",
      "    def __getitem__(self, idx):\n",
      "        data = np.random.random((2, 3)).astype('float32')\n",
      "\n",
      "        return data\n",
      "\n",
      "    def __len__(self):\n",
      "        return 10\n",
      "\n",
      "dataset = RandomDataset()\n",
      "loader = DataLoader(dataset, batch_size=1)\n",
      "data = next(loader())\n",
      "\n",
      "In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 1/1 [==============================] - 30ms/step\n",
      "Predict samples: 9464\n",
      "[ 942 5574  979 1639  993  980  540  977  904  988]\n",
      "用户的ID为: 432\n",
      "================================\n",
      "用户评分较高的电影：\n",
      "--------------------------------\n",
      "Lion King, The (1994) : Adventure|Animation|Children|Drama|Musical|IMAX\n",
      "Misérables, Les (1998) : Crime|Drama|Romance|War\n",
      "Exorcist, The (1973) : Horror|Mystery\n",
      "[REC] (2007) : Drama|Horror|Thriller\n",
      "Paranormal Activity (2009) : Horror|Thriller\n",
      "--------------------------------\n",
      "为用户推荐的10部电影：\n",
      "--------------------------------\n",
      "Fargo (1996) : Comedy|Crime|Drama|Thriller\n",
      "Reservoir Dogs (1992) : Crime|Mystery|Thriller\n",
      "Monty Python and the Holy Grail (1975) : Adventure|Comedy|Fantasy\n",
      "One Flew Over the Cuckoo's Nest (1975) : Drama\n",
      "Princess Bride, The (1987) : Action|Adventure|Comedy|Fantasy|Romance\n",
      "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) : Action|Adventure\n",
      "Apocalypse Now (1979) : Action|Drama|War\n",
      "Goodfellas (1990) : Crime|Drama\n",
      "Saving Private Ryan (1998) : Action|Drama|War\n",
      "Eternal Sunshine of the Spotless Mind (2004) : Drama|Romance|Sci-Fi\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv('ml-latest-small/movies.csv')\n",
    "\n",
    "# 获取一个用户，查看他的推荐电影\n",
    "user_id = df.userId.sample(1).iloc[0]\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df[\"movieId\"].isin(movies_watched_by_user.movieId.values)\n",
    "][\"movieId\"]\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys()))\n",
    ")\n",
    "movies_not_watched = [[movie2movie_encoded.get(x)] for x in movies_not_watched]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)\n",
    ")\n",
    "testdataset = SelfDefinedDataset(user_movie_array, user_movie_array, mode = 'predict')\n",
    "test_loader = paddle.io.DataLoader(testdataset, batch_size = 9703, shuffle = False, return_list=True,)   \n",
    "\n",
    "ratings = model.predict(test_loader)\n",
    "ratings = np.array(ratings)\n",
    "ratings = np.squeeze(ratings, 0)\n",
    "ratings = np.squeeze(ratings, 2)\n",
    "ratings = np.squeeze(ratings, 0)\n",
    "top_ratings_indices = ratings.argsort()[::-1][0:10]\n",
    "\n",
    "print(top_ratings_indices)\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(\"用户的ID为: {}\".format(user_id))\n",
    "print(\"====\" * 8)\n",
    "print(\"用户评分较高的电影：\")\n",
    "print(\"----\" * 8)\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieId.values\n",
    ")\n",
    "movie_df_rows = movie_df[movie_df[\"movieId\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title, \":\", row.genres)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"为用户推荐的10部电影：\")\n",
    "print(\"----\" * 8)\n",
    "recommended_movies = movie_df[movie_df[\"movieId\"].isin(recommended_movie_ids)]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, \":\", row.genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Paddle2.1.1",
   "language": "python",
   "name": "paddle2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
