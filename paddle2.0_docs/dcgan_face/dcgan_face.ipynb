{
 "cells": [
  {
   "source": [
    "# 通过DCGAN实现人脸图像生成\n",
    "\n",
    "作者:[ZMpursue](https://github.com/ZMpursue)  \n",
    "日期:2020.10.26\n",
    "\n",
    "本教程将通过一个示例对DCGAN进行介绍。在向其展示许多真实人脸照片（数据集：[Celeb-A Face](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)）后，我们将训练一个生成对抗网络（GAN）来产生新人脸。本文将对该实现进行详尽的解释，并阐明此模型的工作方式和原因。并不需要过多专业知识，但是可能需要新手花一些时间来理解的模型训练的实际情况。为了节省时间，请尽量选择GPU进行训练。\n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 简介\n",
    "本项目基于paddlepaddle，结合生成对抗网络（DCGAN）,通过弱监督学习的方式，训练生成真实人脸照片\n",
    "\n",
    "### 1.1 什么是GAN？\n",
    "\n",
    "生成对抗网络（Generative Adversarial Network [1]，简称GAN）是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。该方法最初由 lan·Goodfellow 等人于2014年提出，原论文见 [Generative Adversarial Network](https://arxiv.org/abs/1406.2661)。\n",
    "\n",
    "  生成对抗网络由一个生成网络与一个判别网络组成。生成网络从潜在空间（latent space）中随机采样作为输入，其输出结果需要尽量模仿训练集中的真实样本。判别网络的输入为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，其目的是将生成网络生成的样本和真实样本尽可能的区分开[2] ）。 \n",
    "  \n",
    "让$x$是代表图像的数据。$D(x)$是判别器网络，输出的概率为$x$来自训练数据还是生成器。在这里输入$D(x)$的$x$是CHW大小为3x128x128的图像。使得$x$来自训练数据时$D(x)$尽量接近1，$x$来自生成器时$D(x)$尽量接近0。$D(x)$也可以被认为是传统的二进制分类器。\n",
    "\n",
    "对于生成器网络，$z$为从标准正态分布采样的潜在空间向量。$G(z)$表示生成器函数，该函数将矢量$z$映射到数据空间。生成器的目标是拟合训练数据($p_{data}$)的分布，以便可以从该估计分布中生成假样本($p_g$)。\n",
    "\n",
    "所以，$D(G(z))$是生成器$G$输出是真实的图像的概率。如Goodfellow的论文所述，$D$和$G$玩一个minimax游戏，其中$D$尝试最大化其正确分类真假的可能性$logD(x)$，以及$G$试图最小化以下可能性$D$会预测其输出是假的$log(1-D(G(x)))$。\n",
    "\n",
    "GAN的损失函数可表示为：\n",
    "\n",
    "> $\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(z)))\\big]$\n",
    "\n",
    "从理论上讲，此minimax游戏的解决方案是$p_g = p_{data}$，鉴别者会盲目猜测输入是真实的还是假的。但是，GAN的收敛理论仍在积极研究中，实际上GAN常常会遇到梯度消失/爆炸问题。  \n",
    "生成对抗网络常用于生成以假乱真的图片。此外，该方法还被用于生成视频、三维物体模型等。\n",
    "\n",
    "\n",
    "### 1.2 什么是DCGAN？\n",
    "\n",
    "DCGAN是深层卷积网络与 GAN 的结合，其基本原理与 GAN 相同，只是将生成网络和判别网络用两个卷积网络（CNN）替代。为了提高生成样本的质量和网络的收敛速度，论文中的 DCGAN 在网络结构上进行了一些改进：\n",
    "\n",
    " * 取消 pooling 层：在网络中，所有的pooling层使用步幅卷积（strided convolutions）(判别器)和微步幅度卷积（fractional-strided convolutions）(生成器)进行替换。\n",
    " * 加入 batch normalization：在生成器和判别器中均加入batchnorm。\n",
    " * 使用全卷积网络：去掉了FC层，以实现更深的网络结构。\n",
    " * 激活函数：在生成器（G）中，最后一层使用Tanh函数，其余层采用 ReLu 函数 ; 判别器（D）中都采用LeakyReLu。  \n",
    "\n",
    "  ### 1.3 本文的改进\n",
    "         \n",
    "   * 将Adam优化器beta1参数设置为0.8，具体请参考[原论文](https://arxiv.org/abs/1412.6980)\n",
    "   * 将BatchNorm批归一化中momentum参数设置为0.5\n",
    "   * 将判别器(D)激活函数由elu改为leaky_relu，并将alpha参数设置为0.2\n",
    "   * 生成器输出，判别器输入改为[3,128,128]\n",
    "   * 损失函数选用Softmax_with_cross_entropy\n",
    "   ---\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 环境设置及数据集\n",
    "\n",
    "环境：paddlepaddle、scikit-image、numpy、matplotlib  \n",
    "\n",
    "在本教程中，我们将使用[Celeb-A Faces](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)数据集，该数据集可以在链接的网站或[AI Studio](https://aistudio.baidu.com/aistudio/datasetdetail/39207)中下载。数据集将下载为名为img_align_celeba.zip的文件。下载后，并将zip文件解压缩到该目录中。  \n",
    "img_align_celeba目录结构应为： \n",
    "```\n",
    "/path/to/project  \n",
    "\t-> img_align_celeba  \n",
    "\t\t-> 188242.jpg  \n",
    "\t\t-> 173822.jpg  \n",
    "\t\t-> 284702.jpg  \n",
    "\t\t-> 537394.jpg  \n",
    "\t\t...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.3 数据集预处理\n",
    "多线程处理，以裁切坐标(0,20)和(128,148)，将输入网络的图片裁切到128*128。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os.path\n",
    "import os\n",
    "import threading\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "'''多线程将图片缩放后再裁切到128*128分辨率'''\n",
    "#裁切图片宽度\n",
    "w = 128\n",
    "#裁切图片高度\n",
    "h = 128\n",
    "#裁切点横坐标(以图片左上角为原点)\n",
    "x = 0\n",
    "#裁切点纵坐标\n",
    "y = 20\n",
    "\n",
    "def cutArray(l, num):\n",
    "  avg = len(l) / float(num)\n",
    "  o = []\n",
    "  last = 0.0\n",
    "\n",
    "  while last < len(l):\n",
    "    o.append(l[int(last):int(last + avg)])\n",
    "    last += avg\n",
    "\n",
    "  return o\n",
    "  \n",
    "def convertjpg(jpgfile,outdir,width=w,height=h):\n",
    "    img=Image.open(jpgfile)\n",
    "    (l,h) = img.size\n",
    "    rate = min(l,h) / width\n",
    "    try:\n",
    "        img = img.resize((int(l // rate),int(h // rate)),Image.BILINEAR)\n",
    "        img = img.crop((x,y,width+x,height+y))\n",
    "        img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "class thread(threading.Thread):\n",
    "    def __init__(self, threadID, inpath, outpath, files):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.inpath = inpath\n",
    "        self.outpath = outpath\n",
    "        self.files = files\n",
    "    def run(self):\n",
    "        count = 0\n",
    "        try:\n",
    "            for file in self.files:\n",
    "                convertjpg(self.inpath + file,self.outpath)\n",
    "                count = count + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        print('已处理图片数量：' +  str(count))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    inpath = './work/img_align_celeba/'\n",
    "    outpath = './work/imgs/'\n",
    "    if not os.path.exists(outpath):\n",
    "        os.mkdir(outpath)\n",
    "    files =  os.listdir(inpath)\n",
    "    files = cutArray(files,8)\n",
    "    T1 = thread(1, inpath, outpath, files[0])\n",
    "    T2 = thread(2, inpath, outpath, files[1])\n",
    "    T3 = thread(3, inpath, outpath, files[2])\n",
    "    T4 = thread(4, inpath, outpath, files[3])\n",
    "    T5 = thread(5, inpath, outpath, files[4])\n",
    "    T6 = thread(6, inpath, outpath, files[5])\n",
    "    T7 = thread(7, inpath, outpath, files[6])\n",
    "    T8 = thread(8, inpath, outpath, files[7])\n",
    "    \n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T3.start()\n",
    "    T4.start()\n",
    "    T5.start()\n",
    "    T6.start()\n",
    "    T7.start()\n",
    "    T8.start()\n",
    "    \n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    T3.join()\n",
    "    T4.join()\n",
    "    T5.join()\n",
    "    T6.join()\n",
    "    T7.join()\n",
    "    T8.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 模型组网\n",
    "### 3.1 定义数据预处理工具-DataReader\n",
    "具体参考[DataReader教程](https://www.paddlepaddle.org.cn/documentation/docs/zh/advanced_guide/data_preparing/static_mode/reader_cn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paddle.dataset as dataset\n",
    "from skimage import io,color,transform\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import six\n",
    "\n",
    "img_dim = 128\n",
    "\n",
    "'''准备数据，定义Reader()'''\n",
    "PATH = 'work/imgs/'\n",
    "TEST = 'work/imgs/'\n",
    "class DataGenerater:\n",
    "    def __init__(self):\n",
    "        '''初始化'''\n",
    "        self.datalist = os.listdir(PATH)\n",
    "        self.testlist = os.listdir(TEST)\n",
    "\n",
    "    def load(self, image):\n",
    "        '''读取图片'''\n",
    "        img = io.imread(image)\n",
    "        img = transform.resize(img,(img_dim,img_dim))\n",
    "        img = img.transpose()\n",
    "        img = img.astype('float32')\n",
    "        return img\n",
    "\n",
    "    def create_train_reader(self):\n",
    "        '''给dataset定义reader'''\n",
    "\n",
    "        def reader():\n",
    "            for img in self.datalist:\n",
    "                #print(img)\n",
    "                try:\n",
    "                    i = self.load(PATH + img)\n",
    "                    yield i.astype('float32')\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        return reader\n",
    "\n",
    "    def create_test_reader(self,):\n",
    "        '''给test定义reader'''\n",
    "        def reader():\n",
    "            for img in self.datalist:\n",
    "                #print(img)\n",
    "                try:\n",
    "                    i = self.load(PATH + img)\n",
    "                    yield i.astype('float32')\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "        return reader\n",
    "\n",
    "def train(batch_sizes = 32):\n",
    "    reader = DataGenerater().create_train_reader()\n",
    "    return reader\n",
    "\n",
    "def test():\n",
    "    reader = DataGenerater().create_test_reader()\n",
    "    return reader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 测试DataReader并输出图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        reader=train(), buf_size=128\n",
    "    ),\n",
    "    batch_size=128\n",
    ")\n",
    "for batch_id, data in enumerate(train_reader()):\n",
    "    \n",
    "    plt.figure(figsize=(15,15))\n",
    "    try:\n",
    "        for i in range(100):\n",
    "            image = data[i].transpose()\n",
    "            plt.subplot(10, 10, i + 1)\n",
    "            plt.imshow(image, vmin=-1, vmax=1)\n",
    "            plt.axis('off')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "        plt.suptitle('\\n Training Images',fontsize=30)\n",
    "        plt.show()\n",
    "        break\n",
    "    except IOError:\n",
    "        print(IOError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 权重初始化\n",
    "在 DCGAN 论文中，作者指定所有模型权重应从均值为0、标准差为0.02的正态分布中随机初始化。  \n",
    "在Fluid中，调用fluid.initializer.NormalInitializer实现initialize设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_initializer=fluid.initializer.NormalInitializer(loc=0.0, scale=0.02)\r\n",
    "bn_initializer=fluid.initializer.NormalInitializer(loc=1.0, scale=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.4 定义网络功能模块\n",
    "包括卷积层、转置卷积层、$BatchNorm$层、全连接层和卷积$BatchNorm$组 \n",
    "* 转置卷积层：在生成器中，需要用随机采样值生成全尺寸图像，dcgan使用转置卷积层进行上采样，在Fluid中，调用 fluid.layers.conv2d_transpose 实现转置卷积。\n",
    "* BatchNorm层：调用 fluid.layers.batch_norm 接口实现bn层，激活函数默认使用ReLu。\n",
    "* 卷积层：调用 fluid.nets.simple_img_conv_pool 实现卷积池化组，卷积核大小为5x5，池化窗口大小为2x2，窗口滑动步长为2，激活函数类型由具体网络结构指定。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_cudnn = True\n",
    "use_gpu = True\n",
    "n = 0\n",
    "\n",
    "###BatchNorm层\n",
    "def bn(x, name=None, act=None,momentum=0.5):\n",
    "    return fluid.layers.batch_norm(\n",
    "        x,\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_bn_weight_1_\",\n",
    "            initializer=bn_initializer,\n",
    "            trainable=True),\n",
    "        # 指定权重参数属性的对象\n",
    "        bias_attr=None,\n",
    "        # 指定偏置的属性的对象\n",
    "        moving_mean_name=name + '3',\n",
    "        # moving_mean的名称\n",
    "        moving_variance_name=name + '4',\n",
    "        # moving_variance的名称\n",
    "        name=name,\n",
    "        act=act,\n",
    "        momentum=momentum,\n",
    "    )\n",
    "\n",
    "\n",
    "###卷积层\n",
    "def conv(x, num_filters,name=None, act=None):\n",
    "    return fluid.nets.simple_img_conv_pool(\n",
    "        input=x,\n",
    "        filter_size=5,\n",
    "        num_filters=num_filters,\n",
    "        pool_size=2,\n",
    "        # 池化窗口大小\n",
    "        pool_stride=2,\n",
    "        # 池化滑动步长\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_conv_weight_1_\",\n",
    "            initializer=conv_initializer,\n",
    "            trainable=True),\n",
    "        bias_attr=False,\n",
    "        use_cudnn=use_cudnn,\n",
    "        act=act\n",
    "    )\n",
    "\n",
    "###全连接层\n",
    "def fc(x, num_filters, name=None, act=None):\n",
    "    return fluid.layers.fc(\n",
    "        input=x,\n",
    "        size=num_filters,\n",
    "        act=act,\n",
    "        param_attr=name + 'w',\n",
    "        bias_attr=name + 'b'\n",
    "    )\n",
    "\n",
    "###转置卷积层\n",
    "def deconv(x, num_filters, name=None, filter_size=5, stride=2, dilation=1, padding=2, output_size=None, act=None):\n",
    "    return fluid.layers.conv2d_transpose(\n",
    "        input=x,\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_conv_weight_2_\",\n",
    "            initializer=conv_initializer,\n",
    "            trainable=True),\n",
    "        bias_attr=False,\n",
    "        num_filters=num_filters,\n",
    "        # 滤波器数量\n",
    "        output_size=output_size,\n",
    "        # 输出图片大小\n",
    "        filter_size=filter_size,\n",
    "        # 滤波器大小\n",
    "        stride=stride,\n",
    "        # 步长\n",
    "        dilation=dilation,\n",
    "        # 膨胀比例大小\n",
    "        padding=padding,\n",
    "        use_cudnn=use_cudnn,\n",
    "        # 是否使用cudnn内核\n",
    "        act=act\n",
    "        # 激活函数\n",
    "    )\n",
    "\n",
    "#卷积BatchNorm组\n",
    "def conv_bn_layer(input,\n",
    "                  ch_out,\n",
    "                  filter_size,\n",
    "                  stride,\n",
    "                  padding,\n",
    "                  act=None,\n",
    "                  groups=64,\n",
    "                  name=None):\n",
    "    tmp = fluid.layers.conv2d(\n",
    "        input=input,\n",
    "        filter_size=filter_size,\n",
    "        num_filters=ch_out,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        act=None,\n",
    "        bias_attr=False,\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_conv_weight_3_\",\n",
    "            initializer=conv_initializer,\n",
    "            trainable=True),\n",
    "    )\n",
    "    return fluid.layers.batch_norm(\n",
    "        input=tmp,\n",
    "        act=act,\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_bn_weight_2_\",\n",
    "            initializer=bn_initializer,\n",
    "            trainable=True),\n",
    "        # 指定权重参数属性的对象\n",
    "        bias_attr=None,\n",
    "        # 指定偏置的属性的对象\n",
    "        moving_mean_name=name + '_bn_3',\n",
    "        # moving_mean的名称\n",
    "        moving_variance_name=name + '_bn_4',\n",
    "        # moving_variance的名称\n",
    "        name=name + '_bn_',\n",
    "        momentum=0.5,\n",
    "    )\n",
    "\n",
    "def conv_layer(input,\n",
    "                  ch_out,\n",
    "                  filter_size,\n",
    "                  stride,\n",
    "                  padding,\n",
    "                  act=None,\n",
    "                  name=None):\n",
    "    return fluid.layers.conv2d(\n",
    "        input=input,\n",
    "        filter_size=filter_size,\n",
    "        num_filters=ch_out,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        act=None,\n",
    "        bias_attr=False,\n",
    "        param_attr=fluid.ParamAttr(\n",
    "            name=name+\"_conv_weight_4_\",\n",
    "            initializer=conv_initializer,\n",
    "            trainable=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.5 判别器\n",
    "如上文所述，生成器$D$是一个二进制分类网络，它以图像作为输入，输出图像是真实的（相对应$G$生成的假样本）的概率。输入$Shape$为[3,128,128]的RGB图像，通过一系列的$Conv2d$，$BatchNorm2d$和$LeakyReLU$层对其进行处理，然后通过全连接层输出的神经元个数为2，对应两个标签的预测概率。\n",
    "\n",
    "* 将BatchNorm批归一化中momentum参数设置为0.5\n",
    "* 将判别器(D)激活函数leaky_relu的alpha参数设置为0.2\n",
    "\n",
    "> 输入:  为大小128x128的RGB三通道图片  \n",
    "> 输出:  经过一层全连接层最后为shape为[batch_size,2]的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###判别器\n",
    "def D(x):\n",
    "    # (128 + 2 * 1 - 4) / 2 + 1 = 64\n",
    "    x = conv_layer(x, 128, 4, 2, 1, act=None, name='d_conv_1')\n",
    "    x = fluid.layers.leaky_relu(x,alpha=0.2,name='d_leaky_relu_1')\n",
    "\n",
    "    # (64 + 2 * 1 - 4) / 2 + 1 = 32\n",
    "    x = conv_bn_layer(x, 256, 4, 2, 1, act=None, name='d_conv_bn_2')\n",
    "    x = fluid.layers.leaky_relu(x,alpha=0.2,name='d_leaky_relu_2')\n",
    "\n",
    "    # (32 + 2 * 1 - 4) / 2 + 1 = 16\n",
    "    x = conv_bn_layer(x, 385, 4, 2, 1, act=None, name='d_conv_bn_3')\n",
    "    x = fluid.layers.leaky_relu(x,alpha=0.2,name='d_leaky_relu_3')\n",
    "\n",
    "    # (16 + 2 * 1 - 4) / 2 + 1 = 8\n",
    "    x = conv_bn_layer(x, 768, 4, 2, 1, act=None, name='d_conv_bn_4')\n",
    "    x = fluid.layers.leaky_relu(x,alpha=0.2,name='d_leaky_relu_4')\n",
    "\n",
    "    # (8 + 2 * 1 - 4) / 2 + 1 = 4\n",
    "    x = conv_bn_layer(x, 1024, 4, 2, 1, act=None, name='d_conv_bn_5')\n",
    "    x = fluid.layers.leaky_relu(x,alpha=0.2,name='d_leaky_relu_5')\n",
    "\n",
    "    # (4 + 2 * 1 - 4) / 2 + 1 = 2\n",
    "    x = conv_bn_layer(x, 512, 4, 2, 1, act=None, name='d_conv_bn_6')\n",
    "    x = fluid.layers.leaky_relu(x, alpha=0.2, name='d_leaky_relu_6')\n",
    "\n",
    "    x = fluid.layers.reshape(x,shape=[-1, 2048])\n",
    "    x = fc(x, 2, name='d_fc1')\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.6 生成器\n",
    "生成器$G$旨在映射潜在空间矢量$z$到数据空间。由于我们的数据是图像，因此转换$z$到数据空间意味着最终创建具有与训练图像相同大小[3,128,128]的RGB图像。在网络设计中，这是通过一系列二维卷积转置层来完成的，每个层都与$BatchNorm$层和$ReLu$激活函数。生成器的输出通过$tanh$函数输出，以使其返回到输入数据范围[−1,1]。值得注意的是，在卷积转置层之后存在$BatchNorm$函数，因为这是DCGAN论文的关键改进。这些层有助于训练过程中的梯度更好地流动。  \n",
    "\n",
    "**生成器网络结构**  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ca0434dd681849338b1c0c46285616f72add01ab894b4e95848daecd5a72e3cb)\n",
    "\n",
    "* 将$BatchNorm$批归一化中$momentum$参数设置为0.5\n",
    "\n",
    "> 输入:Tensor的Shape为[batch_size,100]其中每个数值大小为0~1之间的float32随机数  \n",
    "> 输出:3x128x128RGB三通道图片\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###生成器\n",
    "def G(x):\n",
    "    x = fluid.layers.reshape(x, shape=[-1, 100, 1, 1])\n",
    "\n",
    "    # 2 * (1 - 1) - 2 * 0  + 4 = 4\n",
    "    x = deconv(x, num_filters=2048, filter_size=4, stride=1, padding=0, name='g_deconv_0')\n",
    "    x = bn(x, name='g_bn_1', act='relu', momentum=0.5)\n",
    "\n",
    "    # 2 * (4 - 1) - 2 * 1  + 4 = 8\n",
    "    x = deconv(x, num_filters=1024, filter_size=4, stride=2, padding=1, name='g_deconv_1')\n",
    "    x = bn(x, name='g_bn_2', act='relu', momentum=0.5)\n",
    "\n",
    "    # 2 * (8 - 1) - 2 * 1  + 4 = 16\n",
    "    x = deconv(x, num_filters=1024 , filter_size=4, stride=2, padding=1, name='g_deconv_2')\n",
    "    x = bn(x, name='g_bn_3', act='relu', momentum=0.5)\n",
    "\n",
    "    # 2 * (16 - 1) - 2 * 1  + 4 = 32\n",
    "    x = deconv(x, num_filters=768, filter_size=4, stride=2, padding=1, name='g_deconv_3')\n",
    "    x = bn(x, name='g_bn_4', act='relu', momentum=0.5)\n",
    "\n",
    "    # 1 * (16 - 1) - 2 * 1  + 3 = 32\n",
    "    x = deconv(x, num_filters=512, filter_size=3, stride=1, padding=1, name='g_deconv_4')\n",
    "    x = bn(x, name='g_bn_5', act='relu', momentum=0.5)\n",
    "\n",
    "    # 2 * (32 - 1) - 2 * 1  + 4 = 64\n",
    "    x = deconv(x, num_filters=512, filter_size=4, stride=2, padding=1, name='g_deconv_5')\n",
    "    x = bn(x, name='g_bn_6', act='relu',momentum=0.5)\n",
    "\n",
    "    # 2 * (64 - 1) - 2 * 1  + 4 = 128\n",
    "    x = deconv(x, num_filters=3, filter_size=4, stride=2, padding=1, name='g_deconv_6', act='tanh')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.7 损失函数\n",
    "选用Softmax_with_cross_entropy,公式如下:\n",
    "\n",
    "  $loss_j =  -\\text{logits}_{label_j} +\\log\\left(\\sum_{i=0}^{K}\\exp(\\text{logits}_i)\\right), j = 1,..., K$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###损失函数\n",
    "def loss(x, label):\n",
    "    return fluid.layers.mean(fluid.layers.softmax_with_cross_entropy(logits=x, label=label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4 模型训练\n",
    " 设置的超参数为：\n",
    " * 学习率：0.0002\n",
    " * 输入图片长和宽：128\n",
    " * Epoch: 8\n",
    " * Mini-Batch：128\n",
    " * 输入Tensor长度：100\n",
    " * Adam：Beta1：0.5，Beta2：0.999  \n",
    " \n",
    "训练过程中的每一次迭代，生成器和判别器分别设置自己的迭代次数。为了避免判别器快速收敛到0，本教程默认每迭代一次，训练一次判别器，两次生成器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "img_dim = 128\n",
    "LEARENING_RATE = 0.0002\n",
    "SHOWNUM = 12\n",
    "epoch = 6\n",
    "output = \"work/Output/\"\n",
    "batch_size = 128\n",
    "G_DIMENSION = 100\n",
    "beta1=0.5\n",
    "beta2=0.999\n",
    "d_program = fluid.Program()\n",
    "dg_program = fluid.Program()\n",
    "\n",
    "###定义判别器program\n",
    "# program_guard()接口配合with语句将with block中的算子和变量添加指定的全局主程序（main_program)和启动程序（start_progrom)\n",
    "with fluid.program_guard(d_program):\n",
    "    # 输入图片大小为128*128\n",
    "    img = fluid.layers.data(name='img', shape=[None,3,img_dim,img_dim], dtype='float32')\n",
    "    # 标签shape=1\n",
    "    label = fluid.layers.data(name='label', shape=[None,1], dtype='int64')\n",
    "    d_logit = D(img)\n",
    "    d_loss = loss(x=d_logit, label=label)\n",
    "\n",
    "###定义生成器program\n",
    "with fluid.program_guard(dg_program):\n",
    "    noise = fluid.layers.data(name='noise', shape=[None,G_DIMENSION], dtype='float32')\n",
    "    # 噪声数据作为输入得到生成照片\n",
    "    g_img = G(x=noise)\n",
    "    g_program = dg_program.clone()\n",
    "    g_program_test = dg_program.clone(for_test=True)\n",
    "\n",
    "    # 判断生成图片为真实样本的概率\n",
    "    dg_logit = D(g_img)\n",
    "\n",
    "    # 计算生成图片被判别为真实样本的loss\n",
    "    dg_loss = loss(\n",
    "        x=dg_logit,\n",
    "        label=fluid.layers.fill_constant_batch_size_like(input=noise, dtype='int64', shape=[-1,1], value=1)\n",
    "    )\n",
    "\n",
    "###优化函数\n",
    "opt = fluid.optimizer.Adam(learning_rate=LEARENING_RATE,beta1=beta1,beta2=beta2)\n",
    "opt.minimize(loss=d_loss)\n",
    "parameters = [p.name for p in g_program.global_block().all_parameters()]\n",
    "opt.minimize(loss=dg_loss, parameter_list=parameters)\n",
    "\n",
    "train_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        reader=train(), buf_size=110000\n",
    "    ),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_reader = paddle.batch(\n",
    "    paddle.reader.shuffle(\n",
    "        reader=test(), buf_size=10000\n",
    "    ),\n",
    "    batch_size=10\n",
    ")\n",
    "###执行器\n",
    "if use_gpu:\n",
    "    exe = fluid.Executor(fluid.CUDAPlace(0))\n",
    "else:\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "start_program = fluid.default_startup_program()\n",
    "exe.run(start_program)\n",
    "#加载模型\n",
    "# fluid.io.load_persistables(exe,'work/Model/D/',d_program)\n",
    "# fluid.io.load_persistables(exe,'work/Model/G/',dg_program)\n",
    "\n",
    "###训练过程\n",
    "t_time = 0\n",
    "losses = [[], []]\n",
    "# 判别器迭代次数\n",
    "NUM_TRAIN_TIME_OF_DG = 2\n",
    "# 最终生成的噪声数据\n",
    "const_n = np.random.uniform(\n",
    "    low=0.0, high=1.0,\n",
    "    size=[batch_size, G_DIMENSION]).astype('float32')\n",
    "test_const_n = np.random.uniform(\n",
    "    low=0.0, high=1.0,\n",
    "    size=[100, G_DIMENSION]).astype('float32')\n",
    "\n",
    "#plt.ion()\n",
    "now = 0\n",
    "for pass_id in range(epoch):\n",
    "    fluid.io.save_persistables(exe, 'work/Model/G', dg_program)\n",
    "    fluid.io.save_persistables(exe, 'work/Model/D', d_program)\n",
    "    # enumerate()函数将一个可遍历的数据对象组合成一个序列列表\n",
    "    for batch_id, data in enumerate(train_reader()):  \n",
    "        if len(data) != batch_size:\n",
    "            continue\n",
    "\n",
    "        # 生成训练过程的噪声数据\n",
    "        noise_data = np.random.uniform(\n",
    "            low=0.0, high=1.0,\n",
    "            size=[batch_size, G_DIMENSION]).astype('float32')\n",
    "        # 真实图片\n",
    "        real_image = np.array(data)\n",
    "        # 真实标签\n",
    "        real_labels = np.ones(shape=[batch_size,1], dtype='int64')\n",
    "        # 虚假标签\n",
    "        fake_labels = np.zeros(shape=[batch_size,1], dtype='int64')\n",
    "        s_time = time.time()\n",
    "        # 虚假图片\n",
    "        generated_image = exe.run(g_program,\n",
    "                                  feed={'noise': noise_data},\n",
    "                                  fetch_list=[g_img])[0]\n",
    "\n",
    "\n",
    "        ###训练判别器\n",
    "        # D函数判断虚假图片为假的loss\n",
    "        d_loss_1 = exe.run(d_program,\n",
    "                           feed={\n",
    "                               'img': generated_image,\n",
    "                               'label': fake_labels,\n",
    "                           },\n",
    "                           fetch_list=[d_loss])[0][0]\n",
    "        # D函数判断真实图片为真的loss\n",
    "        d_loss_2 = exe.run(d_program,\n",
    "                           feed={\n",
    "                               'img': real_image,\n",
    "                               'label': real_labels,\n",
    "                           },\n",
    "                           fetch_list=[d_loss])[0][0]\n",
    "\n",
    "        d_loss_n = d_loss_1 + d_loss_2\n",
    "        losses[0].append(d_loss_n)\n",
    "\n",
    "        ###训练生成器\n",
    "        for _ in six.moves.xrange(NUM_TRAIN_TIME_OF_DG):\n",
    "            # uniform()方法从一个均匀分布[low,high)中随机采样\n",
    "            noise_data = np.random.uniform(  \n",
    "                low=0.0, high=1.0,\n",
    "                size=[batch_size, G_DIMENSION]).astype('float32')\n",
    "            dg_loss_n = exe.run(dg_program,\n",
    "                                feed={'noise': noise_data},\n",
    "                                fetch_list=[dg_loss])[0][0]\n",
    "        losses[1].append(dg_loss_n)\n",
    "        t_time += (time.time() - s_time)\n",
    "        if batch_id % 100 == 0:\n",
    "            if not os.path.exists(output):\n",
    "                os.makedirs(output)\n",
    "            # 每轮的生成结果\n",
    "            generated_image = exe.run(g_program_test, feed={'noise': test_const_n}, fetch_list=[g_img])[0]\n",
    "            imgs = []\n",
    "            plt.figure(figsize=(15,15))\n",
    "            try:\n",
    "                for i in range(100):\n",
    "                    image = generated_image[i].transpose()\n",
    "                    image = np.where(image > 0, image, 0)\n",
    "                    plt.subplot(10, 10, i + 1)\n",
    "                    plt.imshow(image, vmin=-1, vmax=1)\n",
    "                    plt.axis('off')\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "                msg = 'Epoch ID={0} Batch ID={1} \\n\\n D-Loss={2} G-Loss={3}'.format(pass_id, batch_id, d_loss_n, dg_loss_n)\n",
    "                plt.suptitle(msg,fontsize=20)\n",
    "                plt.draw()\n",
    "                plt.savefig('{}/{:04d}_{:04d}.png'.format(output, pass_id, batch_id),bbox_inches='tight')\n",
    "                plt.pause(0.01)\n",
    "                display.clear_output(wait=True)\n",
    "            except IOError:\n",
    "                print(IOError)\n",
    "\n",
    "\n",
    "#plt.ioff()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "x = np.arange(len(losses[0]))\n",
    "plt.title('Generator and Discriminator Loss During Training')\n",
    "plt.xlabel('Number of Batch')\n",
    "plt.plot(x,np.array(losses[0]),label='D Loss')\n",
    "plt.plot(x,np.array(losses[1]),label='G Loss')\n",
    "plt.legend()\n",
    "plt.savefig('work/Generator and Discriminator Loss During Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5 模型评估\n",
    "### 生成器$G$和判别器$D$的损失与迭代变化图\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8c94b567738c423ba5a421a40ccf5f57fd8defc3b62d46f28cc5d3aa3439bf42)\n",
    "\n",
    "### 对比真实人脸图像（图一）和生成人脸图像（图二）\n",
    "#### 图一\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/622fff7b67a240ff8a1fceb209fc27445c929099365c44e8bd006569bf26e0a6)\n",
    "### 图二\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ed33cf82762d4ae79feef82b77604273303cc38b8f5d4728a632b492f2665ed4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6 模型预测\n",
    "### 输入随机数让生成器$G$生成随机人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import IPython.display as display\n",
    "\n",
    "'''定义超参数'''\n",
    "img_dim = 128\n",
    "output = \"Output/\"\n",
    "G_DIMENSION = 100\n",
    "#生成图片数量\n",
    "number = 20\n",
    "use_gpu = True\n",
    "dg_program = fluid.Program()\n",
    "d_program = fluid.Program()\n",
    "\n",
    "\n",
    "###定义判别器program\n",
    "# program_guard()接口配合with语句将with block中的算子和变量添加指定的全局主程序（main_program)和启动程序（start_progrom)\n",
    "with fluid.program_guard(d_program):\n",
    "    # 输入图片大小为128*128\n",
    "    img = fluid.layers.data(name='img', shape=[None,3,img_dim,img_dim], dtype='float32')\n",
    "    # 标签shape=1\n",
    "    label = fluid.layers.data(name='label', shape=[None,1], dtype='int64')\n",
    "    d_logit = D(img)\n",
    "    d_loss = loss(x=d_logit, label=label)\n",
    "\n",
    "###定义生成器program\n",
    "with fluid.program_guard(dg_program):\n",
    "    noise = fluid.layers.data(name='noise', shape=[None,G_DIMENSION], dtype='float32')\n",
    "    # 噪声数据作为输入得到生成照片\n",
    "    g_img = G(x=noise)\n",
    "    g_program = dg_program.clone()\n",
    "    g_program_test = dg_program.clone(for_test=True)\n",
    "\n",
    "    # 判断生成图片为真实样本的概率\n",
    "    dg_logit = D(g_img)\n",
    "\n",
    "    # 计算生成图片被判别为真实样本的loss\n",
    "    dg_loss = loss(\n",
    "        x=dg_logit,\n",
    "        label=fluid.layers.fill_constant_batch_size_like(input=noise, dtype='int64', shape=[-1,1], value=1)\n",
    "    )\n",
    "\n",
    "if use_gpu:\n",
    "    exe = fluid.Executor(fluid.CUDAPlace(0))\n",
    "else:\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "start_program = fluid.default_startup_program()\n",
    "exe.run(start_program)\n",
    "fluid.io.load_persistables(exe,'work/Model/D/',d_program)\n",
    "fluid.io.load_persistables(exe,'work/Model/G/',dg_program)\n",
    "try:\n",
    "    const_n = []\n",
    "    for m in range(number):\n",
    "        noise = np.random.uniform(low=0.0, high=1.0,size=[G_DIMENSION]).astype('float32')\n",
    "        const_n.append(noise)\n",
    "    const_n = np.array(const_n).astype('float32')\n",
    "    generated_image = exe.run(g_program, feed={'noise': const_n}, fetch_list=[g_img])[0]\n",
    "    for j in range(number):\n",
    "        image = generated_image[j].transpose()\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "        plt.savefig('work/Generate/generated_' + str(j + 1), bbox_inches='tight')\n",
    "        plt.close()\n",
    "except IOError:\n",
    "    print(IOError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 8 项目总结\n",
    "简单介绍了一下DCGAN的原理，通过对原项目的改进和优化，一步一步依次对生成器和判别器以及训练过程进行介绍。\n",
    "DCGAN采用一个随机噪声向量作为输入，输入通过与CNN类似但是相反的结构，将输入放大成二维数据。采用这种结构的生成模型和CNN结构的判别模型，DCGAN在图片生成上可以达到相当可观的效果。本案例中，我们利用DCGAN生成了人脸照片，您可以尝试更换数据集生成符合个人需求的图片，或尝试修改网络结构观察不一样的生成效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 9 参考文献\n",
    "[1] Goodfellow, Ian J.; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua. Generative Adversarial Networks. 2014. arXiv:1406.2661 [stat.ML].\n",
    "\n",
    "[2] Andrej Karpathy, Pieter Abbeel, Greg Brockman, Peter Chen, Vicki Cheung, Rocky Duan, Ian Goodfellow, Durk Kingma, Jonathan Ho, Rein Houthooft, Tim Salimans, John Schulman, Ilya Sutskever, And Wojciech Zaremba, Generative Models, OpenAI, [April 7, 2016]\n",
    "\n",
    "[3] alimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi. Improved Techniques for Training GANs. 2016. arXiv:1606.03498 [cs.LG].\n",
    "\n",
    "[4] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[J]. Computer Science, 2015.\n",
    "\n",
    "[5]Kingma D , Ba J . Adam: A Method for Stochastic Optimization[J]. Computer ence, 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('base': conda)",
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}