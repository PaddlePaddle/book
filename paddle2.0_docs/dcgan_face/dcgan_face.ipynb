{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# é€šè¿‡DCGANå®ç°äººè„¸å›¾åƒç”Ÿæˆ\n",
    "\n",
    "ä½œè€…:[ZMpursue](https://github.com/ZMpursue)  \n",
    "æ—¥æœŸ:2020.10.26\n",
    "\n",
    "æœ¬æ•™ç¨‹å°†é€šè¿‡ä¸€ä¸ªç¤ºä¾‹å¯¹DCGANè¿›è¡Œä»‹ç»ã€‚åœ¨å‘å…¶å±•ç¤ºè®¸å¤šçœŸå®äººè„¸ç…§ç‰‡ï¼ˆæ•°æ®é›†ï¼š[Celeb-A Face](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)ï¼‰åï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ¥äº§ç”Ÿæ–°äººè„¸ã€‚æœ¬æ–‡å°†å¯¹è¯¥å®ç°è¿›è¡Œè¯¦å°½çš„è§£é‡Šï¼Œå¹¶é˜æ˜æ­¤æ¨¡å‹çš„å·¥ä½œæ–¹å¼å’ŒåŸå› ã€‚å¹¶ä¸éœ€è¦è¿‡å¤šä¸“ä¸šçŸ¥è¯†ï¼Œä½†æ˜¯å¯èƒ½éœ€è¦æ–°æ‰‹èŠ±ä¸€äº›æ—¶é—´æ¥ç†è§£çš„æ¨¡å‹è®­ç»ƒçš„å®é™…æƒ…å†µã€‚ä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œè¯·å°½é‡é€‰æ‹©GPUè¿›è¡Œè®­ç»ƒã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1 ç®€ä»‹\n",
    "æœ¬é¡¹ç›®åŸºäºpaddlepaddleï¼Œç»“åˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆDCGANï¼‰,é€šè¿‡å¼±ç›‘ç£å­¦ä¹ çš„æ–¹å¼ï¼Œè®­ç»ƒç”ŸæˆçœŸå®äººè„¸ç…§ç‰‡\n",
    "\n",
    "### 1.1 ä»€ä¹ˆæ˜¯GANï¼Ÿ\n",
    "\n",
    "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGenerative Adversarial Network [1]ï¼Œç®€ç§°GANï¼‰æ˜¯éç›‘ç£å¼å­¦ä¹ çš„ä¸€ç§æ–¹æ³•ï¼Œé€šè¿‡è®©ä¸¤ä¸ªç¥ç»ç½‘ç»œç›¸äº’åšå¼ˆçš„æ–¹å¼è¿›è¡Œå­¦ä¹ ã€‚è¯¥æ–¹æ³•æœ€åˆç”± lanÂ·Goodfellow ç­‰äººäº2014å¹´æå‡ºï¼ŒåŸè®ºæ–‡è§ [Generative Adversarial Network](https://arxiv.org/abs/1406.2661)ã€‚\n",
    "\n",
    "  ç”Ÿæˆå¯¹æŠ—ç½‘ç»œç”±ä¸€ä¸ªç”Ÿæˆç½‘ç»œä¸ä¸€ä¸ªåˆ¤åˆ«ç½‘ç»œç»„æˆã€‚ç”Ÿæˆç½‘ç»œä»æ½œåœ¨ç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­éšæœºé‡‡æ ·ä½œä¸ºè¾“å…¥ï¼Œå…¶è¾“å‡ºç»“æœéœ€è¦å°½é‡æ¨¡ä»¿è®­ç»ƒé›†ä¸­çš„çœŸå®æ ·æœ¬ã€‚åˆ¤åˆ«ç½‘ç»œçš„è¾“å…¥ä¸ºçœŸå®æ ·æœ¬æˆ–ç”Ÿæˆç½‘ç»œçš„è¾“å‡ºï¼Œå…¶ç›®çš„æ˜¯å°†å°½å¯èƒ½çš„åˆ†è¾¨è¾“å…¥ä¸ºçœŸå®æ ·æœ¬æˆ–ç”Ÿæˆç½‘ç»œçš„è¾“å‡ºã€‚è€Œç”Ÿæˆç½‘ç»œåˆ™è¦å°½å¯èƒ½åœ°æ¬ºéª—åˆ¤åˆ«ç½‘ç»œã€‚ä¸¤ä¸ªç½‘ç»œç›¸äº’å¯¹æŠ—ã€ä¸æ–­è°ƒæ•´å‚æ•°ã€‚ \n",
    "  \n",
    "è®©$x$æ˜¯ä»£è¡¨å›¾åƒçš„æ•°æ®ã€‚$D(x)$æ˜¯åˆ¤åˆ«å™¨ç½‘ç»œï¼Œè¾“å‡ºçš„æ¦‚ç‡ä¸º$x$æ¥è‡ªè®­ç»ƒæ•°æ®è¿˜æ˜¯ç”Ÿæˆå™¨ã€‚å‡è®¾$x$ä¸ºCHWæ ¼å¼ï¼Œå¤§å°ä¸º3x64x64çš„å›¾åƒæ•°æ®ï¼ŒDä¸ºåˆ¤åˆ«å™¨ç½‘ç»œï¼Œ$D(x)$ä¸º$ğ‘¥$æ¥è‡ªè®­ç»ƒæ•°æ®è¿˜æ˜¯ç”Ÿæˆå™¨ã€‚å½“$ğ‘¥$æ¥è‡ªè®­ç»ƒæ•°æ®æ—¶$ğ·(ğ‘¥)$å°½é‡æ¥è¿‘1ï¼Œ$ğ‘¥$æ¥è‡ªç”Ÿæˆå™¨æ—¶$ğ·(ğ‘¥)$å°½é‡æ¥è¿‘0ã€‚ å› æ­¤ï¼Œ$ğ·(ğ‘¥)$ä¹Ÿå¯ä»¥è¢«è®¤ä¸ºæ˜¯ä¼ ç»Ÿçš„äºŒåˆ†ç±»å™¨ã€‚\n",
    "\n",
    "å¯¹äºç”Ÿæˆå™¨ç½‘ç»œï¼Œ å‡è®¾$z$ä¸ºä»æ ‡å‡†æ­£æ€åˆ†å¸ƒé‡‡æ ·çš„ç©ºé—´å‘é‡ã€‚$G(z)$è¡¨ç¤ºç”Ÿæˆå™¨ç½‘ç»œï¼Œè¯¥ç½‘ç»œå°†çŸ¢é‡$z$æ˜ å°„åˆ°æ•°æ®ç©ºé—´ï¼Œ$G(z)$è¡¨ç¤ºç”Ÿæˆå™¨ç½‘ç»œè¾“å‡ºçš„å›¾åƒã€‚ç”Ÿæˆå™¨çš„ç›®æ ‡æ˜¯æ‹Ÿåˆè®­ç»ƒæ•°æ®($p_{data}$)çš„åˆ†å¸ƒï¼Œä»¥ä¾¿å¯ä»¥ä»è¯¥ä¼°è®¡åˆ†å¸ƒä¸­ç”Ÿæˆå‡æ ·æœ¬($p_g$)ã€‚\n",
    "\n",
    "æ‰€ä»¥ï¼Œ$D(G(z))$æ˜¯ç”Ÿæˆå™¨$G$è¾“å‡ºæ˜¯çœŸå®çš„å›¾åƒçš„æ¦‚ç‡ã€‚å¦‚Goodfellowçš„è®ºæ–‡æ‰€è¿°ï¼Œ$D$å’Œ$G$ç©ä¸€ä¸ªminmaxæ¸¸æˆï¼Œå…¶ä¸­$D$å°è¯•æœ€å¤§åŒ–å…¶æ­£ç¡®åˆ†ç±»çœŸå‡çš„å¯èƒ½æ€§$logD(x)$ï¼Œä»¥åŠ$G$è¯•å›¾æœ€å°åŒ–ä»¥ä¸‹å¯èƒ½æ€§$D$ä¼šé¢„æµ‹å…¶è¾“å‡ºæ˜¯å‡çš„$log(1-D(G(x)))$ã€‚\n",
    "\n",
    "GANçš„æŸå¤±å‡½æ•°å¯è¡¨ç¤ºä¸ºï¼š\n",
    "\n",
    "> $\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(z)))\\big]$\n",
    "\n",
    "ä»ç†è®ºä¸Šè®²ï¼Œæ­¤minmaxæ¸¸æˆçš„è§£å†³æ–¹æ¡ˆæ˜¯$p_g = p_{data}$ï¼Œé‰´åˆ«è€…ä¼šç›²ç›®çŒœæµ‹è¾“å…¥æ˜¯çœŸå®çš„è¿˜æ˜¯å‡çš„ã€‚ä½†æ˜¯ï¼ŒGANçš„æ”¶æ•›ç†è®ºä»åœ¨ç§¯æç ”ç©¶ä¸­ï¼Œå®é™…ä¸ŠGANå¸¸å¸¸ä¼šé‡åˆ°æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸é—®é¢˜ã€‚  \n",
    "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå¸¸ç”¨äºç”Ÿæˆä»¥å‡ä¹±çœŸçš„å›¾ç‰‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¢«ç”¨äºç”Ÿæˆè§†é¢‘ã€ä¸‰ç»´ç‰©ä½“æ¨¡å‹ç­‰ã€‚\n",
    "\n",
    "\n",
    "### 1.2 ä»€ä¹ˆæ˜¯DCGANï¼Ÿ\n",
    "\n",
    "DCGANæ˜¯æ·±å±‚å·ç§¯ç½‘ç»œä¸GANçš„ç»“åˆï¼Œå…¶åŸºæœ¬åŸç†ä¸GANç›¸åŒï¼Œåªæ˜¯å°†ç”Ÿæˆç½‘ç»œå’Œåˆ¤åˆ«ç½‘ç»œç”¨ä¸¤ä¸ªå·ç§¯ç½‘ç»œï¼ˆCNNï¼‰æ›¿ä»£ã€‚ä¸ºäº†æé«˜ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œç½‘ç»œçš„æ”¶æ•›é€Ÿåº¦ï¼Œè®ºæ–‡ä¸­çš„ DCGAN åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¸€äº›æ”¹è¿›ï¼š\n",
    "\n",
    " * å–æ¶ˆ pooling å±‚ï¼šåœ¨ç½‘ç»œä¸­ï¼Œæ‰€æœ‰çš„poolingå±‚ä½¿ç”¨æ­¥å¹…å·ç§¯ï¼ˆstrided convolutionsï¼‰(åˆ¤åˆ«å™¨)å’Œå¾®æ­¥å¹…åº¦å·ç§¯ï¼ˆfractional-strided convolutionsï¼‰(ç”Ÿæˆå™¨)è¿›è¡Œæ›¿æ¢ã€‚\n",
    " * åŠ å…¥batchnormï¼šåœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­å‡åŠ å…¥batchnormã€‚\n",
    " * ä½¿ç”¨å…¨å·ç§¯ç½‘ç»œï¼šå»æ‰äº†FCå±‚ï¼Œä»¥å®ç°æ›´æ·±çš„ç½‘ç»œç»“æ„ã€‚\n",
    " * æ¿€æ´»å‡½æ•°ï¼šåœ¨ç”Ÿæˆå™¨ï¼ˆGï¼‰ä¸­ï¼Œæœ€åä¸€å±‚ä½¿ç”¨Tanhå‡½æ•°ï¼Œå…¶ä½™å±‚é‡‡ç”¨ReLUå‡½æ•° ; åˆ¤åˆ«å™¨ï¼ˆDï¼‰ä¸­éƒ½é‡‡ç”¨LeakyReLUã€‚  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2 ç¯å¢ƒè®¾ç½®åŠæ•°æ®é›†\n",
    "\n",
    "ç¯å¢ƒï¼špaddlepaddleã€scikit-imageã€numpyã€matplotlib  \n",
    "\n",
    "åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨[Celeb-A Faces](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†å¯ä»¥åœ¨é“¾æ¥çš„ç½‘ç«™æˆ–[AI Studio](https://aistudio.baidu.com/aistudio/datasetdetail/39207)ä¸­ä¸‹è½½ã€‚æ•°æ®é›†å°†ä¸‹è½½ä¸ºåä¸ºimg_align_celeba.zipçš„æ–‡ä»¶ã€‚ä¸‹è½½åï¼Œå¹¶å°†zipæ–‡ä»¶è§£å‹ç¼©åˆ°è¯¥ç›®å½•ä¸­ã€‚  \n",
    "img_align_celebaç›®å½•ç»“æ„åº”ä¸ºï¼š \n",
    "```\n",
    "/path/to/project  \n",
    "\t-> img_align_celeba  \n",
    "\t\t-> 188242.jpg  \n",
    "\t\t-> 173822.jpg  \n",
    "\t\t-> 284702.jpg  \n",
    "\t\t-> 537394.jpg  \n",
    "\t\t...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2.1 æ•°æ®é›†é¢„å¤„ç†\n",
    "å¤šçº¿ç¨‹å¤„ç†ï¼Œä»¥è£åˆ‡åæ ‡(0,10)å’Œ(64,74)ï¼Œå°†è¾“å…¥ç½‘ç»œçš„å›¾ç‰‡è£åˆ‡åˆ°64*64ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os.path\n",
    "import os\n",
    "import threading\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "'''å¤šçº¿ç¨‹å°†å›¾ç‰‡ç¼©æ”¾åå†è£åˆ‡åˆ°64*64åˆ†è¾¨ç‡'''\n",
    "#è£åˆ‡å›¾ç‰‡å®½åº¦\n",
    "w = 64\n",
    "#è£åˆ‡å›¾ç‰‡é«˜åº¦\n",
    "h = 64\n",
    "#è£åˆ‡ç‚¹æ¨ªåæ ‡(ä»¥å›¾ç‰‡å·¦ä¸Šè§’ä¸ºåŸç‚¹)\n",
    "x = 0\n",
    "#è£åˆ‡ç‚¹çºµåæ ‡\n",
    "y = 20\n",
    "\n",
    "def cutArray(l, num):\n",
    "  avg = len(l) / float(num)\n",
    "  o = []\n",
    "  last = 0.0\n",
    "\n",
    "  while last < len(l):\n",
    "    o.append(l[int(last):int(last + avg)])\n",
    "    last += avg\n",
    "\n",
    "  return o\n",
    "  \n",
    "def convertjpg(jpgfile,outdir,width=w,height=h):\n",
    "    img=Image.open(jpgfile)\n",
    "    (l,h) = img.size\n",
    "    rate = min(l,h) / width\n",
    "    try:\n",
    "        img = img.resize((int(l // rate),int(h // rate)),Image.BILINEAR)\n",
    "        img = img.crop((x,y,width+x,height+y))\n",
    "        img.save(os.path.join(outdir,os.path.basename(jpgfile)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "class thread(threading.Thread):\n",
    "    def __init__(self, threadID, inpath, outpath, files):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.threadID = threadID\n",
    "        self.inpath = inpath\n",
    "        self.outpath = outpath\n",
    "        self.files = files\n",
    "    def run(self):\n",
    "        count = 0\n",
    "        try:\n",
    "            for file in self.files:\n",
    "                convertjpg(self.inpath + file,self.outpath)\n",
    "                count = count + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        print('å·²å¤„ç†å›¾ç‰‡æ•°é‡ï¼š' +  str(count))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    inpath = './work/img_align_celeba/'\n",
    "    outpath = './work/imgs/'\n",
    "    if not os.path.exists(outpath):\n",
    "        os.mkdir(outpath)\n",
    "    files =  os.listdir(inpath)\n",
    "    files = cutArray(files,8)\n",
    "    T1 = thread(1, inpath, outpath, files[0])\n",
    "    T2 = thread(2, inpath, outpath, files[1])\n",
    "    T3 = thread(3, inpath, outpath, files[2])\n",
    "    T4 = thread(4, inpath, outpath, files[3])\n",
    "    T5 = thread(5, inpath, outpath, files[4])\n",
    "    T6 = thread(6, inpath, outpath, files[5])\n",
    "    T7 = thread(7, inpath, outpath, files[6])\n",
    "    T8 = thread(8, inpath, outpath, files[7])\n",
    "    \n",
    "    T1.start()\n",
    "    T2.start()\n",
    "    T3.start()\n",
    "    T4.start()\n",
    "    T5.start()\n",
    "    T6.start()\n",
    "    T7.start()\n",
    "    T8.start()\n",
    "    \n",
    "    T1.join()\n",
    "    T2.join()\n",
    "    T3.join()\n",
    "    T4.join()\n",
    "    T5.join()\n",
    "    T6.join()\n",
    "    T7.join()\n",
    "    T8.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3 æ¨¡å‹ç»„ç½‘\n",
    "### 3.1 å®šä¹‰æ•°æ®é¢„å¤„ç†å·¥å…·-Paddle.io.Dataset\n",
    "å…·ä½“å‚è€ƒ[Paddle.io.Datasetæ•™ç¨‹](https://www.paddlepaddle.org.cn/documentation/docs/zh/2.0-rc/api/paddle/io/Dataset_cn.html#dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import io,color,transform\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "import six\n",
    "from PIL import Image as PilImage\n",
    "from paddle.static import InputSpec\n",
    "paddle.enable_static()\n",
    "img_dim = 64\n",
    "\n",
    "'''å‡†å¤‡æ•°æ®ï¼Œå®šä¹‰Reader()'''\n",
    "PATH = 'work/imgs/'\n",
    "\n",
    "class DataGenerater(Dataset):\n",
    "    \"\"\"\n",
    "    æ•°æ®é›†å®šä¹‰\n",
    "    \"\"\"\n",
    "    def __init__(self,path=PATH):\n",
    "        \"\"\"\n",
    "        æ„é€ å‡½æ•°\n",
    "        \"\"\"\n",
    "        super(DataGenerater, self).__init__()\n",
    "        self.dir = path\n",
    "        self.datalist = os.listdir(PATH)\n",
    "        self.image_size = (img_dim,img_dim)\n",
    "    \n",
    "    # æ¯æ¬¡è¿­ä»£æ—¶è¿”å›æ•°æ®å’Œå¯¹åº”çš„æ ‡ç­¾\n",
    "    def __getitem__(self, idx):\n",
    "        return self._load_img(self.dir + self.datalist[idx])\n",
    "\n",
    "    # è¿”å›æ•´ä¸ªæ•°æ®é›†çš„æ€»æ•°\n",
    "    def __len__(self):\n",
    "        return len(self.datalist)\n",
    "    \n",
    "    def _load_img(self, path):\n",
    "        \"\"\"\n",
    "        ç»Ÿä¸€çš„å›¾åƒå¤„ç†æ¥å£å°è£…ï¼Œç”¨äºè§„æ•´å›¾åƒå¤§å°å’Œé€šé“\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = io.imread(path)\n",
    "            img = transform.resize(img,self.image_size)\n",
    "            img = img.transpose()\n",
    "            img = img.astype('float32')\n",
    "        except Exception as e:\n",
    "                print(e)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 æµ‹è¯•Paddle.io.DataLoaderå¹¶è¾“å‡ºå›¾ç‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = DataGenerater()\n",
    "img = paddle.static.data(name='img', shape=[None,3,img_dim,img_dim], dtype='float32')\n",
    "train_loader = paddle.io.DataLoader(\n",
    "    train_dataset, \n",
    "    places=paddle.CPUPlace(), \n",
    "    feed_list = [img],\n",
    "    batch_size=128, \n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    use_buffer_reader=True,\n",
    "    use_shared_memory=False,\n",
    "    drop_last=True,\n",
    "    )\n",
    "\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    try:\n",
    "        for i in range(100):\n",
    "            image = np.array(data[0]['img'][i])[0].transpose((2,1,0))\n",
    "            plt.subplot(10, 10, i + 1)\n",
    "            plt.imshow(image, vmin=-1, vmax=1)\n",
    "            plt.axis('off')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "        plt.suptitle('\\n Training Images',fontsize=30)\n",
    "        plt.show()\n",
    "        break\n",
    "    except IOError:\n",
    "        print(IOError)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 æƒé‡åˆå§‹åŒ–\n",
    "åœ¨ DCGAN è®ºæ–‡ä¸­ï¼Œä½œè€…æŒ‡å®šæ‰€æœ‰æ¨¡å‹æƒé‡åº”ä»å‡å€¼ä¸º0ã€æ ‡å‡†å·®ä¸º0.02çš„æ­£æ€åˆ†å¸ƒä¸­éšæœºåˆå§‹åŒ–ã€‚  \n",
    "è°ƒç”¨paddle.nn.initializer.Normalå®ç°initializeè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_initializer=paddle.nn.initializer.Normal(mean=0.0, std=0.02)\n",
    "bn_initializer=paddle.nn.initializer.Normal(mean=1.0, std=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.4 åˆ¤åˆ«å™¨\n",
    "å¦‚ä¸Šæ–‡æ‰€è¿°ï¼Œç”Ÿæˆå™¨$D$æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶åˆ†ç±»ç½‘ç»œï¼Œå®ƒä»¥å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºå›¾åƒæ˜¯çœŸå®çš„ï¼ˆç›¸å¯¹åº”$G$ç”Ÿæˆçš„å‡æ ·æœ¬ï¼‰çš„æ¦‚ç‡ã€‚è¾“å…¥$Shape$ä¸º[3,64,64]çš„RGBå›¾åƒï¼Œé€šè¿‡ä¸€ç³»åˆ—çš„$Conv2d$ï¼Œ$BatchNorm2d$å’Œ$LeakyReLU$å±‚å¯¹å…¶è¿›è¡Œå¤„ç†ï¼Œç„¶åé€šè¿‡å…¨è¿æ¥å±‚è¾“å‡ºçš„ç¥ç»å…ƒä¸ªæ•°ä¸º2ï¼Œå¯¹åº”ä¸¤ä¸ªæ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡ã€‚\n",
    "\n",
    "* å°†BatchNormæ‰¹å½’ä¸€åŒ–ä¸­momentumå‚æ•°è®¾ç½®ä¸º0.5\n",
    "* å°†åˆ¤åˆ«å™¨(D)æ¿€æ´»å‡½æ•°leaky_reluçš„alphaå‚æ•°è®¾ç½®ä¸º0.2\n",
    "\n",
    "> è¾“å…¥:  ä¸ºå¤§å°64x64çš„RGBä¸‰é€šé“å›¾ç‰‡  \n",
    "> è¾“å‡º:  ç»è¿‡ä¸€å±‚å…¨è¿æ¥å±‚æœ€åä¸ºshapeä¸º[batch_size,2]çš„Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "class Discriminator(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv_1 = nn.Conv2D(\n",
    "            3,64,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_1_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.conv_2 = nn.Conv2D(\n",
    "            64,128,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_2_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_2 = nn.BatchNorm2D(\n",
    "            128,\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_2_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_3 = nn.Conv2D(\n",
    "            128,256,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_3_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_3 = nn.BatchNorm2D(\n",
    "            256,\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_3_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_4 = nn.Conv2D(\n",
    "            256,512,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_4_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_4 = nn.BatchNorm2D(\n",
    "            512,\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_4_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_5 = nn.Conv2D(\n",
    "            512,1,4,1,0,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_5_\",initializer=conv_initializer)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\n",
    "        x = self.conv_4(x)\n",
    "        x = self.bn_4(x)\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\n",
    "        x = self.conv_5(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.5 ç”Ÿæˆå™¨\n",
    "ç”Ÿæˆå™¨$G$æ—¨åœ¨æ˜ å°„æ½œåœ¨ç©ºé—´çŸ¢é‡$z$åˆ°æ•°æ®ç©ºé—´ã€‚ç”±äºæˆ‘ä»¬çš„æ•°æ®æ˜¯å›¾åƒï¼Œå› æ­¤è½¬æ¢$z$åˆ°æ•°æ®ç©ºé—´æ„å‘³ç€æœ€ç»ˆåˆ›å»ºå…·æœ‰ä¸è®­ç»ƒå›¾åƒç›¸åŒå¤§å°[3,64,64]çš„RGBå›¾åƒã€‚åœ¨ç½‘ç»œè®¾è®¡ä¸­ï¼Œè¿™æ˜¯é€šè¿‡ä¸€ç³»åˆ—äºŒç»´å·ç§¯è½¬ç½®å±‚æ¥å®Œæˆçš„ï¼Œæ¯ä¸ªå±‚éƒ½ä¸$BatchNorm$å±‚å’Œ$ReLu$æ¿€æ´»å‡½æ•°ã€‚ç”Ÿæˆå™¨çš„è¾“å‡ºé€šè¿‡$tanh$å‡½æ•°è¾“å‡ºï¼Œä»¥ä½¿å…¶è¿”å›åˆ°è¾“å…¥æ•°æ®èŒƒå›´[âˆ’1,1]ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨å·ç§¯è½¬ç½®å±‚ä¹‹åå­˜åœ¨$BatchNorm$å‡½æ•°ï¼Œå› ä¸ºè¿™æ˜¯DCGANè®ºæ–‡çš„å…³é”®æ”¹è¿›ã€‚è¿™äº›å±‚æœ‰åŠ©äºè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢¯åº¦æ›´å¥½åœ°æµåŠ¨ã€‚  \n",
    "\n",
    "**ç”Ÿæˆå™¨ç½‘ç»œç»“æ„**  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ca0434dd681849338b1c0c46285616f72add01ab894b4e95848daecd5a72e3cb)\n",
    "\n",
    "* å°†$BatchNorm$æ‰¹å½’ä¸€åŒ–ä¸­$momentum$å‚æ•°è®¾ç½®ä¸º0.5\n",
    "\n",
    "> è¾“å…¥:Tensorçš„Shapeä¸º[batch_size,100]å…¶ä¸­æ¯ä¸ªæ•°å€¼å¤§å°ä¸º0~1ä¹‹é—´çš„float32éšæœºæ•°  \n",
    "> è¾“å‡º:3x64x64RGBä¸‰é€šé“å›¾ç‰‡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class Generator(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv_1 = nn.Conv2DTranspose(\n",
    "            100,512,4,1,0,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_1_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_1 = nn.BatchNorm2D(\n",
    "            512,\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_1_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_2 = nn.Conv2DTranspose(\n",
    "            512,256,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_2_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_2 = nn.BatchNorm2D(\n",
    "            256,\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_2_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_3 = nn.Conv2DTranspose(\n",
    "            256,128,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_3_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_3 = nn.BatchNorm2D(\n",
    "            128,\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_3_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_4 = nn.Conv2DTranspose(\n",
    "            128,64,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_4_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.bn_4 = nn.BatchNorm2D(\n",
    "            64,\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_4_bn_weight_\",initializer=bn_initializer),momentum=0.8\n",
    "            )\n",
    "        self.conv_5 = nn.Conv2DTranspose(\n",
    "            64,3,4,2,1,\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_5_\",initializer=conv_initializer)\n",
    "            )\n",
    "        self.tanh = paddle.nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.bn_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_4(x)\n",
    "        x = self.bn_4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv_5(x)\n",
    "        x = self.tanh(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.6 æŸå¤±å‡½æ•°\n",
    "é€‰ç”¨BCELoss,å…¬å¼å¦‚ä¸‹:\n",
    "\n",
    "  $Out = -1 * (label * log(input) + (1 - label) * log(1 - input))$\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###æŸå¤±å‡½æ•°\n",
    "loss = paddle.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4 æ¨¡å‹è®­ç»ƒ\n",
    " è®¾ç½®çš„è¶…å‚æ•°ä¸ºï¼š\n",
    " * å­¦ä¹ ç‡ï¼š0.0002\n",
    " * è¾“å…¥å›¾ç‰‡é•¿å’Œå®½ï¼š64\n",
    " * Epoch: 8\n",
    " * Mini-Batchï¼š128\n",
    " * è¾“å…¥Tensoré•¿åº¦ï¼š100\n",
    " * Adamï¼šBeta1ï¼š0.5ï¼ŒBeta2ï¼š0.999  \n",
    " \n",
    "è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¯ä¸€æ¬¡è¿­ä»£ï¼Œç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨åˆ†åˆ«è®¾ç½®è‡ªå·±çš„è¿­ä»£æ¬¡æ•°ã€‚ä¸ºäº†é¿å…åˆ¤åˆ«å™¨å¿«é€Ÿæ”¶æ•›åˆ°0ï¼Œæœ¬æ•™ç¨‹é»˜è®¤æ¯è¿­ä»£ä¸€æ¬¡ï¼Œè®­ç»ƒä¸€æ¬¡åˆ¤åˆ«å™¨ï¼Œä¸¤æ¬¡ç”Ÿæˆå™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "import warnings\n",
    "import paddle.optimizer as optim\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "img_dim = 64\n",
    "lr = 0.0002\n",
    "epoch = 5\n",
    "output = \"work/Output/\"\n",
    "batch_size = 128\n",
    "G_DIMENSION = 100\n",
    "beta1=0.5\n",
    "beta2=0.999\n",
    "output_path = 'work/Output'\n",
    "device = paddle.set_device('gpu')\n",
    "paddle.disable_static(device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "netD = Discriminator()\n",
    "netG = Generator()\n",
    "optimizerD = optim.Adam(parameters=netD.parameters(), learning_rate=lr, beta1=beta1, beta2=beta2)\n",
    "optimizerG = optim.Adam(parameters=netG.parameters(), learning_rate=lr, beta1=beta1, beta2=beta2)\n",
    "\n",
    "###è®­ç»ƒè¿‡ç¨‹\n",
    "losses = [[], []]\n",
    "#plt.ion()\n",
    "now = 0\n",
    "for pass_id in range(epoch):\n",
    "    \n",
    "    # enumerate()å‡½æ•°å°†ä¸€ä¸ªå¯éå†çš„æ•°æ®å¯¹è±¡ç»„åˆæˆä¸€ä¸ªåºåˆ—åˆ—è¡¨\n",
    "    for batch_id, data in enumerate(train_loader()):\n",
    "        #è®­ç»ƒåˆ¤åˆ«å™¨ \n",
    "        optimizerD.clear_grad()\n",
    "        real_cpu = data[0]\n",
    "        label = paddle.full((batch_size,1,1,1),real_label,dtype='float32')\n",
    "        output = netD(real_cpu)\n",
    "        errD_real = loss(output,label)\n",
    "        errD_real.backward()\n",
    "        optimizerD.step()\n",
    "        optimizerD.clear_grad()\n",
    "\n",
    "        noise = paddle.randn([batch_size,G_DIMENSION,1,1],'float32')\n",
    "        fake = netG(noise)\n",
    "        label = paddle.full((batch_size,1,1,1),fake_label,dtype='float32')\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = loss(output,label)\n",
    "        errD_fake.backward()\n",
    "        optimizerD.step()\n",
    "        optimizerD.clear_grad()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        \n",
    "        losses[0].append(errD.numpy()[0])\n",
    "        ###è®­ç»ƒç”Ÿæˆå™¨\n",
    "        optimizerG.clear_grad()\n",
    "        noise = paddle.randn([batch_size,G_DIMENSION,1,1],'float32')\n",
    "        fake = netG(noise)\n",
    "        label = paddle.full((batch_size,1,1,1),real_label,dtype=np.float32,)\n",
    "        output = netD(fake)\n",
    "        errG = loss(output,label)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        optimizerG.clear_grad()\n",
    "        \n",
    "        losses[1].append(errG.numpy()[0])\n",
    "        if batch_id % 100 == 0:\n",
    "            if not os.path.exists(output_path):\n",
    "                os.makedirs(output_path)\n",
    "            # æ¯è½®çš„ç”Ÿæˆç»“æœ\n",
    "            generated_image = netG(noise).numpy()\n",
    "            imgs = []\n",
    "            plt.figure(figsize=(15,15))\n",
    "            try:\n",
    "                for i in range(100):\n",
    "                    image = generated_image[i].transpose()\n",
    "                    image = np.where(image > 0, image, 0)\n",
    "                    plt.subplot(10, 10, i + 1)\n",
    "                    plt.imshow(image, vmin=-1, vmax=1)\n",
    "                    plt.axis('off')\n",
    "                    plt.xticks([])\n",
    "                    plt.yticks([])\n",
    "                    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "                msg = 'Epoch ID={0} Batch ID={1} \\n\\n D-Loss={2} G-Loss={3}'.format(pass_id, batch_id, errD.numpy()[0], errG.numpy()[0])\n",
    "                plt.suptitle(msg,fontsize=20)\n",
    "                plt.draw()\n",
    "                plt.savefig('{}/{:04d}_{:04d}.png'.format(output_path, pass_id, batch_id),bbox_inches='tight')\n",
    "                plt.pause(0.01)\n",
    "                display.clear_output(wait=True)\n",
    "            except IOError:\n",
    "                print(IOError)\n",
    "    paddle.save(netG.state_dict(), \"work/generator.params\")\n",
    "\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "x = np.arange(len(losses[0]))\n",
    "plt.title('Generator and Discriminator Loss During Training')\n",
    "plt.xlabel('Number of Batch')\n",
    "plt.plot(x,np.array(losses[0]),label='D Loss')\n",
    "plt.plot(x,np.array(losses[1]),label='G Loss')\n",
    "plt.legend()\n",
    "plt.savefig('work/Generator and Discriminator Loss During Training.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5 æ¨¡å‹è¯„ä¼°\n",
    "### ç”Ÿæˆå™¨$G$å’Œåˆ¤åˆ«å™¨$D$çš„æŸå¤±ä¸è¿­ä»£å˜åŒ–å›¾\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0c8cff8bf3a540bcb601bd24012f67dda622b0391f1d412ea2372693b67b4541)\n",
    "\n",
    "### å¯¹æ¯”çœŸå®äººè„¸å›¾åƒï¼ˆå›¾ä¸€ï¼‰å’Œç”Ÿæˆäººè„¸å›¾åƒï¼ˆå›¾äºŒï¼‰\n",
    "#### å›¾ä¸€\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/622fff7b67a240ff8a1fceb209fc27445c929099365c44e8bd006569bf26e0a6)\n",
    "### å›¾äºŒ\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ed33cf82762d4ae79feef82b77604273303cc38b8f5d4728a632b492f2665ed4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6 æ¨¡å‹é¢„æµ‹\n",
    "### è¾“å…¥éšæœºæ•°è®©ç”Ÿæˆå™¨$G$ç”Ÿæˆéšæœºäººè„¸\n",
    "ç”Ÿæˆçš„RGBä¸‰é€šé“64*64çš„å›¾ç‰‡è·¯å¾„ä½äºâ€œworl/Generate/â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "device = paddle.set_device('gpu')\n",
    "paddle.disable_static(device)\n",
    "try:\n",
    "    generate = Generator()\n",
    "    state_dict = paddle.load(\"work/generator.params\")\n",
    "    generate.set_state_dict(state_dict)\n",
    "    noise = paddle.randn([100,100,1,1],'float32')\n",
    "    generated_image = generate(noise).numpy()\n",
    "    for j in range(100):\n",
    "        image = generated_image[j].transpose()\n",
    "        plt.figure(figsize=(4,4))\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "        plt.savefig('work/Generate/generated_' + str(j + 1), bbox_inches='tight')\n",
    "        plt.close()\n",
    "except IOError:\n",
    "    print(IOError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7 é¡¹ç›®æ€»ç»“\n",
    "ç®€å•ä»‹ç»äº†ä¸€ä¸‹DCGANçš„åŸç†ï¼Œé€šè¿‡å¯¹åŸé¡¹ç›®çš„æ”¹è¿›å’Œä¼˜åŒ–ï¼Œä¸€æ­¥ä¸€æ­¥ä¾æ¬¡å¯¹ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä»¥åŠè®­ç»ƒè¿‡ç¨‹è¿›è¡Œä»‹ç»ã€‚\n",
    "DCGANé‡‡ç”¨ä¸€ä¸ªéšæœºå™ªå£°å‘é‡ä½œä¸ºè¾“å…¥ï¼Œè¾“å…¥é€šè¿‡ä¸CNNç±»ä¼¼ä½†æ˜¯ç›¸åçš„ç»“æ„ï¼Œå°†è¾“å…¥æ”¾å¤§æˆäºŒç»´æ•°æ®ã€‚é‡‡ç”¨è¿™ç§ç»“æ„çš„ç”Ÿæˆæ¨¡å‹å’ŒCNNç»“æ„çš„åˆ¤åˆ«æ¨¡å‹ï¼ŒDCGANåœ¨å›¾ç‰‡ç”Ÿæˆä¸Šå¯ä»¥è¾¾åˆ°ç›¸å½“å¯è§‚çš„æ•ˆæœã€‚æœ¬æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨DCGANç”Ÿæˆäº†äººè„¸ç…§ç‰‡ï¼Œæ‚¨å¯ä»¥å°è¯•æ›´æ¢æ•°æ®é›†ç”Ÿæˆç¬¦åˆä¸ªäººéœ€æ±‚çš„å›¾ç‰‡ï¼Œæˆ–å°è¯•ä¿®æ”¹ç½‘ç»œç»“æ„è§‚å¯Ÿä¸ä¸€æ ·çš„ç”Ÿæˆæ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 8 å‚è€ƒæ–‡çŒ®\n",
    "[1] Goodfellow, Ian J.; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua. Generative Adversarial Networks. 2014. arXiv:1406.2661 [stat.ML].\n",
    "\n",
    "[2] Andrej Karpathy, Pieter Abbeel, Greg Brockman, Peter Chen, Vicki Cheung, Rocky Duan, Ian Goodfellow, Durk Kingma, Jonathan Ho, Rein Houthooft, Tim Salimans, John Schulman, Ilya Sutskever, And Wojciech Zaremba, Generative Models, OpenAI, [April 7, 2016]\n",
    "\n",
    "[3] alimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi. Improved Techniques for Training GANs. 2016. arXiv:1606.03498 [cs.LG].\n",
    "\n",
    "[4] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[J]. Computer Science, 2015.\n",
    "\n",
    "[5]Kingma D , Ba J . Adam: A Method for Stochastic Optimization[J]. Computer ence, 2014."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
