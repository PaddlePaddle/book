{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **点云处理：基于Paddle2.0实现PointNet点云分类Conv2D版**\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>作者：[WhiteFireFox](https://github.com/WhiteFireFox)</font><br><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>日期：2021年2月26日</font><br><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>本示例在于演示如何基于Paddle2.0实现PointNet在ShapeNet数据集上进行点云分类处理。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **环境设置**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **数据集**\n",
    "## **①数据介绍**\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>ShapeNet数据集是一个注释丰富且规模较大的 3D 形状数据集，由斯坦福大学、普林斯顿大学和芝加哥丰田技术学院于 2015 年联合发布。</font><br><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>ShapeNet数据集的储存格式是h5文件，该文件中key值分别为：</font><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>1、data：这一份数据中所有点的xyz坐标，</font><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>2、label：这一份数据所属类别，如airplane等，</font><br>\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>3、pid：这一份数据中所有点所属的类型，如这一份数据属airplane类，则它包含的所有点的类型有机翼、机身等类型。</font>\n",
    "## **②解压数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip data/data70460/shapenet_part_seg_hdf5_data.zip\n",
    "!mv hdf5_data dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **③数据列表**\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>ShapeNet数据集所有的数据文件。</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list = ['ply_data_train0.h5', 'ply_data_train1.h5', 'ply_data_train2.h5', 'ply_data_train3.h5', 'ply_data_train4.h5', 'ply_data_train5.h5']\r\n",
    "test_list = ['ply_data_test0.h5', 'ply_data_test1.h5']\r\n",
    "val_list = ['ply_data_val0.h5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **④搭建数据生成器**\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>说明：将ShapeNet数据集全部读入后，按照Batchsize生成Mini-batch的数据。</font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pointDataLoader(mode='train'):\r\n",
    "    path = './dataset/'\r\n",
    "    MAX_POINT = 2048\r\n",
    "    if mode == 'train':\r\n",
    "        BATCHSIZE = 128\r\n",
    "    else:\r\n",
    "        BATCHSIZE = 32\r\n",
    "\r\n",
    "    datas = []\r\n",
    "    labels = []\r\n",
    "    targets = []\r\n",
    "    if mode == 'train':\r\n",
    "        for file_list in train_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :MAX_POINT, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            targets.extend(f['pid'][:, :MAX_POINT])\r\n",
    "            f.close()\r\n",
    "    elif mode == 'test':\r\n",
    "        for file_list in test_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :MAX_POINT, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            targets.extend(f['pid'][:, :MAX_POINT])\r\n",
    "            f.close()\r\n",
    "    else:\r\n",
    "        for file_list in val_list:\r\n",
    "            f = h5py.File(os.path.join(path, file_list), 'r')\r\n",
    "            datas.extend(f['data'][:, :MAX_POINT, :])\r\n",
    "            labels.extend(f['label'])\r\n",
    "            targets.extend(f['pid'][:, :MAX_POINT])\r\n",
    "            f.close()\r\n",
    "\r\n",
    "    datas = np.array(datas)\r\n",
    "    labels = np.array(labels)\r\n",
    "    targets = np.array(targets)\r\n",
    "    print('==========load over==========')\r\n",
    "\r\n",
    "    index_list = list(range(len(datas)))\r\n",
    "\r\n",
    "    def pointDataGenerator():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(index_list)\r\n",
    "        datas_list = []\r\n",
    "        labels_list = []\r\n",
    "        targets_list = []\r\n",
    "        for i in index_list:\r\n",
    "            target = np.reshape(targets[i], [MAX_POINT]).astype('int64')\r\n",
    "            datas_list.append(datas[i].T.astype('float32')) \r\n",
    "            labels_list.append(labels[i].astype('int64'))\r\n",
    "            targets_list.append(target)\r\n",
    "            if len(datas_list) == BATCHSIZE:\r\n",
    "                yield np.array(datas_list), np.array(labels_list), np.array(targets_list)\r\n",
    "                datas_list = []\r\n",
    "                labels_list = []\r\n",
    "                targets_list = []\r\n",
    "        if len(datas_list) > 0:\r\n",
    "            yield np.array(datas_list), np.array(labels_list), np.array(targets_list)\r\n",
    "\r\n",
    "    return pointDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **定义网络**\n",
    "&emsp;&emsp;&emsp;&emsp;<font size=4>PointNet是斯坦福大学研究人员提出的一个点云处理网络，在这篇论文中，它提出了空间变换网络（T-Net）解决点云的旋转问题（注：因为考虑到某一物体的点云旋转后还是该物体，所以需要有一个网络结构去学习并解决这个旋转问题），并且提出了采取MaxPooling的方法极大程度上地提取点云全局特征。</font><br><br>\n",
    "## **定义网络结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PointNet(paddle.nn.Layer):\n",
    "    def __init__(self, name_scope='PointNet_', num_classes=16, num_point=2048):\n",
    "        super(PointNet, self).__init__()\n",
    "        self.input_transform_net = nn.Sequential(\n",
    "            nn.Conv2D(3, 64, (1, 1)),\n",
    "            nn.BatchNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(64, 128, (1, 1)),\n",
    "            nn.BatchNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(128, 1024, (1, 1)),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2D((num_point, 1))\n",
    "        )\n",
    "        self.input_fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 9, \n",
    "                weight_attr=paddle.framework.ParamAttr(initializer=paddle.nn.initializer.Assign(paddle.zeros((256, 9)))),\n",
    "                bias_attr=paddle.framework.ParamAttr(initializer=paddle.nn.initializer.Assign(paddle.reshape(paddle.eye(3), [-1])))\n",
    "            )\n",
    "        )\n",
    "        self.mlp_1 = nn.Sequential(\n",
    "            nn.Conv2D(3, 64, (1, 1)),\n",
    "            nn.BatchNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(64, 64,(1, 1)),\n",
    "            nn.BatchNorm(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.feature_transform_net = nn.Sequential(\n",
    "            nn.Conv2D(64, 64, (1, 1)),\n",
    "            nn.BatchNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(64, 128, (1, 1)),\n",
    "            nn.BatchNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(128, 1024, (1, 1)),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.MaxPool2D((num_point, 1))\n",
    "        )\n",
    "        self.feature_fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64*64)\n",
    "        )\n",
    "        self.mlp_2 = nn.Sequential(\n",
    "            nn.Conv2D(64, 64, (1, 1)),\n",
    "            nn.BatchNorm(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(64, 128,(1, 1)),\n",
    "            nn.BatchNorm(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2D(128, 1024,(1, 1)),\n",
    "            nn.BatchNorm(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.7),\n",
    "            nn.Linear(256, num_classes),\n",
    "            nn.LogSoftmax(axis=-1)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        batchsize = inputs.shape[0]\n",
    "\n",
    "        t_net = self.input_transform_net(inputs)\n",
    "        t_net = paddle.squeeze(t_net, axis=[-2, -1])\n",
    "        t_net = self.input_fc(t_net)\n",
    "        t_net = paddle.reshape(t_net, [batchsize, 3, 3])\n",
    "\n",
    "        x = paddle.squeeze(inputs, axis=-1)\n",
    "        x = paddle.transpose(x, (0, 2, 1))\n",
    "        x = paddle.matmul(x, t_net)\n",
    "        x = paddle.transpose(x, (0, 2, 1))\n",
    "        x = paddle.unsqueeze(x, axis=-1)\n",
    "        x = self.mlp_1(x)\n",
    "\n",
    "        t_net = self.feature_transform_net(x)\n",
    "        t_net = paddle.squeeze(t_net, axis=[-2, -1])\n",
    "        t_net = self.feature_fc(t_net)\n",
    "        t_net = paddle.reshape(t_net, [batchsize, 64, 64])\n",
    "\n",
    "        x = paddle.squeeze(x, axis=-1)\n",
    "        x = paddle.transpose(x, (0, 2, 1))\n",
    "        x = paddle.matmul(x, t_net)\n",
    "        x = paddle.transpose(x, (0, 2, 1))\n",
    "        x = paddle.unsqueeze(x, axis=-1)\n",
    "        x = self.mlp_2(x)\n",
    "        x = paddle.max(x, axis=2)\n",
    "        x = paddle.squeeze(x, axis=-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## **网络结构可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      " Layer (type)        Input Shape          Output Shape         Param #    \n",
      "============================================================================\n",
      "   Conv2D-67     [[64, 3, 2048, 1]]    [64, 64, 2048, 1]         256      \n",
      " BatchNorm-67    [[64, 64, 2048, 1]]   [64, 64, 2048, 1]         256      \n",
      "   ReLU-103      [[64, 64, 2048, 1]]   [64, 64, 2048, 1]          0       \n",
      "   Conv2D-68     [[64, 64, 2048, 1]]   [64, 128, 2048, 1]       8,320     \n",
      " BatchNorm-68   [[64, 128, 2048, 1]]   [64, 128, 2048, 1]        512      \n",
      "   ReLU-104     [[64, 128, 2048, 1]]   [64, 128, 2048, 1]         0       \n",
      "   Conv2D-69    [[64, 128, 2048, 1]]  [64, 1024, 2048, 1]      132,096    \n",
      " BatchNorm-69   [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]       4,096     \n",
      "   ReLU-105     [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]         0       \n",
      " MaxPool2D-13   [[64, 1024, 2048, 1]]   [64, 1024, 1, 1]          0       \n",
      "   Linear-55        [[64, 1024]]           [64, 512]           524,800    \n",
      "   ReLU-106          [[64, 512]]           [64, 512]              0       \n",
      "   Linear-56         [[64, 512]]           [64, 256]           131,328    \n",
      "   ReLU-107          [[64, 256]]           [64, 256]              0       \n",
      "   Linear-57         [[64, 256]]            [64, 9]             2,313     \n",
      "   Conv2D-70     [[64, 3, 2048, 1]]    [64, 64, 2048, 1]         256      \n",
      " BatchNorm-70    [[64, 64, 2048, 1]]   [64, 64, 2048, 1]         256      \n",
      "   ReLU-108      [[64, 64, 2048, 1]]   [64, 64, 2048, 1]          0       \n",
      "   Conv2D-71     [[64, 64, 2048, 1]]   [64, 64, 2048, 1]        4,160     \n",
      " BatchNorm-71    [[64, 64, 2048, 1]]   [64, 64, 2048, 1]         256      \n",
      "   ReLU-109      [[64, 64, 2048, 1]]   [64, 64, 2048, 1]          0       \n",
      "   Conv2D-72     [[64, 64, 2048, 1]]   [64, 64, 2048, 1]        4,160     \n",
      " BatchNorm-72    [[64, 64, 2048, 1]]   [64, 64, 2048, 1]         256      \n",
      "   ReLU-110      [[64, 64, 2048, 1]]   [64, 64, 2048, 1]          0       \n",
      "   Conv2D-73     [[64, 64, 2048, 1]]   [64, 128, 2048, 1]       8,320     \n",
      " BatchNorm-73   [[64, 128, 2048, 1]]   [64, 128, 2048, 1]        512      \n",
      "   ReLU-111     [[64, 128, 2048, 1]]   [64, 128, 2048, 1]         0       \n",
      "   Conv2D-74    [[64, 128, 2048, 1]]  [64, 1024, 2048, 1]      132,096    \n",
      " BatchNorm-74   [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]       4,096     \n",
      "   ReLU-112     [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]         0       \n",
      " MaxPool2D-14   [[64, 1024, 2048, 1]]   [64, 1024, 1, 1]          0       \n",
      "   Linear-58        [[64, 1024]]           [64, 512]           524,800    \n",
      "   ReLU-113          [[64, 512]]           [64, 512]              0       \n",
      "   Linear-59         [[64, 512]]           [64, 256]           131,328    \n",
      "   ReLU-114          [[64, 256]]           [64, 256]              0       \n",
      "   Linear-60         [[64, 256]]           [64, 4096]         1,052,672   \n",
      "   Conv2D-75     [[64, 64, 2048, 1]]   [64, 64, 2048, 1]        4,160     \n",
      " BatchNorm-75    [[64, 64, 2048, 1]]   [64, 64, 2048, 1]         256      \n",
      "   ReLU-115      [[64, 64, 2048, 1]]   [64, 64, 2048, 1]          0       \n",
      "   Conv2D-76     [[64, 64, 2048, 1]]   [64, 128, 2048, 1]       8,320     \n",
      " BatchNorm-76   [[64, 128, 2048, 1]]   [64, 128, 2048, 1]        512      \n",
      "   ReLU-116     [[64, 128, 2048, 1]]   [64, 128, 2048, 1]         0       \n",
      "   Conv2D-77    [[64, 128, 2048, 1]]  [64, 1024, 2048, 1]      132,096    \n",
      " BatchNorm-77   [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]       4,096     \n",
      "   ReLU-117     [[64, 1024, 2048, 1]] [64, 1024, 2048, 1]         0       \n",
      "   Linear-61        [[64, 1024]]           [64, 512]           524,800    \n",
      "   ReLU-118          [[64, 512]]           [64, 512]              0       \n",
      "   Linear-62         [[64, 512]]           [64, 256]           131,328    \n",
      "   ReLU-119          [[64, 256]]           [64, 256]              0       \n",
      "   Dropout-7         [[64, 256]]           [64, 256]              0       \n",
      "   Linear-63         [[64, 256]]            [64, 10]            2,570     \n",
      " LogSoftmax-7        [[64, 10]]             [64, 10]              0       \n",
      "============================================================================\n",
      "Total params: 3,475,283\n",
      "Trainable params: 3,460,179\n",
      "Non-trainable params: 15,104\n",
      "----------------------------------------------------------------------------\n",
      "Input size (MB): 1.50\n",
      "Forward/backward pass size (MB): 11333.39\n",
      "Params size (MB): 13.26\n",
      "Estimated Total Size (MB): 11348.15\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_params': 3475283, 'trainable_params': 3460179}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointnet = PointNet()\r\n",
    "paddle.summary(pointnet, (64, 3, 2048, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================val===========================================\n",
      "validation: loss is: 0.12309393286705017, accuracy is: 0.9661017060279846\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    train_loader = pointDataLoader(mode='train')\n",
    "    val_loader = pointDataLoader(mode='val')\n",
    "\n",
    "    model = PointNet(num_classes=16, num_point=2048)\n",
    "    model.train()\n",
    "    optim = paddle.optimizer.Adam(parameters=model.parameters(), weight_decay=0.001)\n",
    "\n",
    "    epoch_num = 10\n",
    "    for epoch in range(epoch_num):\n",
    "        # train\n",
    "        print(\"===================================train===========================================\")\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            inputs = paddle.to_tensor(data[0])\n",
    "            inputs = inputs.unsqueeze(-1)\n",
    "            labels = paddle.to_tensor(data[1])\n",
    "\n",
    "            predicts = model(inputs)\n",
    "            loss = F.nll_loss(predicts, labels)\n",
    "            acc = paddle.metric.accuracy(predicts, labels)        \n",
    "\n",
    "            if batch_id % 20 == 0: \n",
    "                print(\"train: epoch: {}, batch_id: {}, loss is: {}, accuracy is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "            \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            paddle.save(model.state_dict(), './model/PointNet.pdparams')\n",
    "            paddle.save(optim.state_dict(), './model/PointNet.pdopt')\n",
    "        \n",
    "        # validation\n",
    "        print(\"===================================val===========================================\")\n",
    "        model.eval()\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        for batch_id, data in enumerate(val_loader()):\n",
    "            inputs = paddle.to_tensor(data[0])\n",
    "            inputs = inputs.unsqueeze(-1)\n",
    "            labels = paddle.to_tensor(data[1])\n",
    "\n",
    "            predicts = model(inputs)\n",
    "\n",
    "            loss = F.nll_loss(predicts, labels)\n",
    "            acc = paddle.metric.accuracy(predicts, labels)    \n",
    "            \n",
    "            losses.append(loss.numpy())\n",
    "            accuracies.append(acc.numpy())\n",
    "\n",
    "        avg_acc, avg_loss = np.mean(accuracies), np.mean(losses)\n",
    "        print(\"validation: loss is: {}, accuracy is: {}\".format(avg_loss, avg_acc))\n",
    "        model.train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **评估与测试**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========load over==========\n",
      "validation: loss is: 0.14321725070476532, accuracy is: 0.9639155864715576\n"
     ]
    }
   ],
   "source": [
    "def evaluation():\r\n",
    "    test_loader = pointDataLoader(mode='test')\r\n",
    "    model = PointNet()\r\n",
    "    model_state_dict = paddle.load('./model/PointNet.pdparams')\r\n",
    "    model.load_dict(model_state_dict)\r\n",
    "\r\n",
    "    model.eval()\r\n",
    "    accuracies = []\r\n",
    "    losses = []\r\n",
    "    for batch_id, data in enumerate(test_loader()):\r\n",
    "        inputs = paddle.to_tensor(data[0])\r\n",
    "        inputs = inputs.unsqueeze(-1)\r\n",
    "        labels = paddle.to_tensor(data[1])\r\n",
    "\r\n",
    "        predicts = model(inputs)\r\n",
    "\r\n",
    "        loss = F.nll_loss(predicts, labels)\r\n",
    "        acc = paddle.metric.accuracy(predicts, labels)    \r\n",
    "        \r\n",
    "        losses.append(loss.numpy())\r\n",
    "        accuracies.append(acc.numpy())\r\n",
    "\r\n",
    "    avg_acc, avg_loss = np.mean(accuracies), np.mean(losses)\r\n",
    "    print(\"validation: loss is: {}, accuracy is: {}\".format(avg_loss, avg_acc))\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "    evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
