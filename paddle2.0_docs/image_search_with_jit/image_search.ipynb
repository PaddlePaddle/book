{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用动转静完成以图搜图的部署\n",
    "\n",
    "作者: [PaddlePaddle](https://github.com/PaddlePaddle)\n",
    "\n",
    "日期: 2021.07\n",
    "\n",
    "摘要: 本示例简要介绍如何通过飞桨开源框架，使用动转静功能，完成图片搜索的部署。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、简要介绍\n",
    "\n",
    "在深度学习模型开发中，动态图代码更易编写和debug，但在部署性能上，静态图更具优势。而飞桨框架支持动态图转静态图（下文简称动转静）的功能，支持使用动态图编写组网代码，飞桨框架会对代码进行分析，自动转换为静态图网络结构，兼顾了动态图易用性和静态图部署性能两方面优势。\n",
    "\n",
    "本示例简要介绍如何通过飞桨开源框架，使用动转静功能，完成图片搜索的部署。\n",
    "\n",
    "本示例中的的大部分代码都源于 [基于图片相似度的图片搜索](https://www.paddlepaddle.org.cn/documentation/docs/zh/tutorial/cv_case/image_search/image_search.html) ，如果你想要了解关于组网和训练的更多信息，可以参考该示例。本示例将重点介绍，如何使用动转静完成模型的部署。\n",
    "\n",
    "关于动转静的更多文档，可以参考：[动态图转静态图-使用文档](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/04_dygraph_to_static/index_cn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、数据加载\n",
    "\n",
    "### 3.1 数据集介绍\n",
    "\n",
    "本示例采用 [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) 数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file /home/aistudio/.cache/paddle/dataset/cifar/cifar-10-python.tar.gz not found, downloading https://dataset.bj.bcebos.com/cifar/cifar-10-python.tar.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n"
     ]
    }
   ],
   "source": [
    "import paddle.vision.transforms as T\n",
    "\n",
    "transform = T.Compose([T.Transpose((2, 0, 1))])\n",
    "\n",
    "cifar10_train = paddle.vision.datasets.Cifar10(mode='train', transform=transform)\n",
    "x_train = np.zeros((50000, 3, 32, 32))\n",
    "y_train = np.zeros((50000, 1), dtype='int32')\n",
    "\n",
    "for i in range(len(cifar10_train)):\n",
    "    train_image, train_label = cifar10_train[i]\n",
    "    \n",
    "    # normalize the data\n",
    "    x_train[i,:, :, :] = train_image / 255.\n",
    "    y_train[i, 0] = train_label\n",
    "\n",
    "y_train = np.squeeze(y_train)\n",
    "\n",
    "cifar10_test = paddle.vision.datasets.cifar.Cifar10(mode='test', transform=transform)\n",
    "x_test = np.zeros((10000, 3, 32, 32), dtype='float32')\n",
    "y_test = np.zeros((10000, 1), dtype='int64')\n",
    "\n",
    "for i in range(len(cifar10_test)):\n",
    "    test_image, test_label = cifar10_test[i]\n",
    "   \n",
    "    # normalize the data\n",
    "    x_test[i,:, :, :] = test_image / 255.\n",
    "    y_test[i, 0] = test_label\n",
    "\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "height_width = 32\n",
    "\n",
    "def show_collage(examples):\n",
    "    box_size = height_width + 2\n",
    "    num_rows, num_cols = examples.shape[:2]\n",
    "\n",
    "    collage = Image.new(\n",
    "        mode=\"RGB\",\n",
    "        size=(num_cols * box_size, num_rows * box_size),\n",
    "        color=(255, 255, 255),\n",
    "    )\n",
    "    for row_idx in range(num_rows):\n",
    "        for col_idx in range(num_cols):\n",
    "            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n",
    "            array = array.transpose(1,2,0)\n",
    "            collage.paste(\n",
    "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
    "            )\n",
    "\n",
    "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
    "    return collage\n",
    "\n",
    "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
    "examples = x_train[sample_idxs]\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 构建训练数据\n",
    "图片检索的模型的训练样本跟常见的分类任务的训练样本不太一样的地方在于，每个训练样本并不是一个(image, class)这样的形式。而是（image0, image1, similary_or_not)的形式，即，每一个训练样本由两张图片组成，而其label是这两张图片是否相似的标志位（0或者1）。\n",
    "\n",
    "很自然的能够想到，来自同一个类别的两张图片，是相似的图片，而来自不同类别的两张图片，应该是不相似的图片。\n",
    "\n",
    "为了能够方便的抽样出相似图片（以及不相似图片）的样本，先建立能够根据类别找到该类别下所有图片的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_idx_to_train_idxs = defaultdict(list)\n",
    "for y_train_idx, y in enumerate(y_train):\n",
    "    class_idx_to_train_idxs[y].append(y_train_idx)\n",
    "\n",
    "class_idx_to_test_idxs = defaultdict(list)\n",
    "for y_test_idx, y in enumerate(y_test):\n",
    "    class_idx_to_test_idxs[y].append(y_test_idx)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "def reader_creator(num_batchs):\n",
    "    def reader():\n",
    "        iter_step = 0\n",
    "        while True:\n",
    "            if iter_step >= num_batchs:\n",
    "                break\n",
    "            iter_step += 1\n",
    "            x = np.empty((2, num_classes, 3, height_width, height_width), dtype=np.float32)\n",
    "            for class_idx in range(num_classes):\n",
    "                examples_for_class = class_idx_to_train_idxs[class_idx]\n",
    "                anchor_idx = random.choice(examples_for_class)\n",
    "                positive_idx = random.choice(examples_for_class)\n",
    "                while positive_idx == anchor_idx:\n",
    "                    positive_idx = random.choice(examples_for_class)\n",
    "                x[0, class_idx] = x_train[anchor_idx]\n",
    "                x[1, class_idx] = x_train[positive_idx]\n",
    "            yield x\n",
    "\n",
    "    return reader\n",
    "\n",
    "def anchor_positive_pairs(num_batchs=100):\n",
    "    return reader_creator(num_batchs)\n",
    "\n",
    "pairs_train_reader = anchor_positive_pairs(num_batchs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、模型组网：把图片转换为高维的向量表示的网络\n",
    "目标是首先把图片转换为高维空间的表示，然后计算图片在高维空间表示时的相似度。 下面的网络结构用来把一个形状为(3, 32, 32)的图片转换成形状为(8,)的向量。在有些资料中也会把这个转换成的向量称为Embedding，请注意，这与自然语言处理领域的词向量的区别。 下面的模型由三个连续的卷积加一个全局均值池化，然后用一个线性全链接层映射到维数为8的向量空间。为了后续计算余弦相似度时的便利，还在最后做了归一化。（即，余弦相似度的分母部分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=3, \n",
    "                                      out_channels=32, \n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=2)\n",
    "         \n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=32, \n",
    "                                      out_channels=64, \n",
    "                                      kernel_size=(3,3), \n",
    "                                      stride=2)       \n",
    "        \n",
    "        self.conv3 = paddle.nn.Conv2D(in_channels=64, \n",
    "                                      out_channels=128, \n",
    "                                      kernel_size=(3,3),\n",
    "                                      stride=2)\n",
    "       \n",
    "        self.gloabl_pool = paddle.nn.AdaptiveAvgPool2D((1,1))\n",
    "\n",
    "        self.fc1 = paddle.nn.Linear(in_features=128, out_features=8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.gloabl_pool(x)\n",
    "        x = paddle.squeeze(x, axis=[2, 3])\n",
    "        x = self.fc1(x)\n",
    "        x = x / paddle.norm(x, axis=1, keepdim=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    print('start training ... ')\n",
    "    model.train()\n",
    "\n",
    "    inverse_temperature = paddle.to_tensor(np.array([1.0/0.2], dtype='float32'))\n",
    "\n",
    "    epoch_num = 20\n",
    "    \n",
    "    opt = paddle.optimizer.Adam(learning_rate=0.0001,\n",
    "                                parameters=model.parameters())\n",
    "    \n",
    "    for epoch in range(epoch_num):\n",
    "        for batch_id, data in enumerate(pairs_train_reader()):\n",
    "            anchors_data, positives_data = data[0], data[1]\n",
    "\n",
    "            anchors = paddle.to_tensor(anchors_data)\n",
    "            positives = paddle.to_tensor(positives_data)\n",
    "            \n",
    "            anchor_embeddings = model(anchors)\n",
    "            positive_embeddings = model(positives)\n",
    "            \n",
    "            similarities = paddle.matmul(anchor_embeddings, positive_embeddings, transpose_y=True) \n",
    "            similarities = paddle.multiply(similarities, inverse_temperature)\n",
    "            \n",
    "            sparse_labels = paddle.arange(0, num_classes, dtype='int64')\n",
    "\n",
    "            loss = F.cross_entropy(similarities, sparse_labels)\n",
    "            \n",
    "            if batch_id % 500 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, loss.numpy()))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.clear_grad()\n",
    "\n",
    "model = MyNet()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、模型预测\n",
    "前述的模型训练训练结束之后，就可以用该网络结构来计算出任意一张图片的高维向量表示（embedding)，通过计算该图片与图片库中其他图片的高维向量表示之间的相似度，就可以按照相似程度进行排序，排序越靠前，则相似程度越高。\n",
    "\n",
    "下面对测试集中所有的图片都两两计算相似度，然后选一部分相似的图片展示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "near_neighbours_per_example = 10\n",
    "\n",
    "x_test_t = paddle.to_tensor(x_test)\n",
    "test_images_embeddings = model(x_test_t)\n",
    "similarities_matrix = paddle.matmul(test_images_embeddings, test_images_embeddings, transpose_y=True) \n",
    "\n",
    "indicies = paddle.argsort(similarities_matrix, descending=True)\n",
    "indicies = indicies.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples = np.empty(\n",
    "    (\n",
    "        num_classes,\n",
    "        near_neighbours_per_example + 1,\n",
    "        3,\n",
    "        height_width,\n",
    "        height_width,\n",
    "    ),\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "for row_idx in range(num_classes):\n",
    "    examples_for_class = class_idx_to_test_idxs[row_idx]\n",
    "    anchor_idx = random.choice(examples_for_class)\n",
    "    \n",
    "    examples[row_idx, 0] = x_test[anchor_idx]\n",
    "    anchor_near_neighbours = indicies[anchor_idx][1:near_neighbours_per_example+1]\n",
    "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
    "        examples[row_idx, col_idx + 1] = x_test[nn_idx]\n",
    "\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 七、基于 trace 保存&加载静态图模型\n",
    "\n",
    "trace是指在模型运行时记录下其运行过哪些算子。[TracedLayer](https://www.paddlepaddle.org.cn/documentation/docs/zh/api/paddle/jit/TracedLayer_cn.html) 就是基于这种技术，在一次执行动态图的过程中，记录所有运行的算子，并构建和保存静态图模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7.1 使用 ``save_inference_model`` 保存动转静模型\n",
    "\n",
    "下面就来看一下，如何使用trace 保存静态图模型。\n",
    "\n",
    "首先导入 ``TracedLayer``，然后使用 ``TracedLayer.trace`` 将动态图以图搜图模型 ``model`` 转换为静态图模型 ``static_layer`` ，用于后续的预测部署。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.jit import TracedLayer\n",
    "\n",
    "inputs = paddle.rand([10, 3, 32, 32])\n",
    "\n",
    "out_dygraph, static_layer = TracedLayer.trace(model, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用 ``save_inference_model`` 保存静态图模型，会产生两个文件 `save_infer_model.pdiparams` 和 `save_infer_model.pdmodel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "static_layer.save_inference_model('./save_infer_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7.2 使用 ``load_inference_model`` 加载动转静模型\n",
    "\n",
    "将模型导出后，需要使用 `paddle.static.load_inference_model` 加载模型。`load_inference_model` 需要指定执行器，因此先使用 `paddle.static.Executor` 构建执行器。\n",
    "\n",
    "需要注意的是，由于 Paddle 2.0 默认是动态图模式，而 `paddle.static.Executor` 与 `paddle.static.load_inference_model` 等 `paddle.static.*` 的API 只支持静态图模式下使用，因此，需要先使用 `paddle.enable_static` 切换为静态图模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.enable_static()\n",
    "exe = paddle.static.Executor(paddle.CUDAPlace(0))\n",
    "[inference_program, feed_target_names, fetch_targets] = paddle.static.load_inference_model('./save_infer_model', exe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 7.3 使用加载的动转静模型预测\n",
    "将模型加载完成后，使用 `exe.run` 获取预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "near_neighbours_per_example = 10\n",
    "test_images_embeddings = exe.run(inference_program,\n",
    "              feed={feed_target_names[0]: x_test},\n",
    "              fetch_list=fetch_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`test_images_embeddings` 即为预测结果。为了方便后续的结果展示，使用 `paddle.disable_static` 重新切换为动态图模式。以下的处理模式与第六节完全一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.disable_static()\n",
    "test_images_embeddings = paddle.to_tensor(test_images_embeddings)\n",
    "similarities_matrix = paddle.matmul(test_images_embeddings, test_images_embeddings, transpose_y=True) \n",
    "\n",
    "indicies = paddle.argsort(similarities_matrix, descending=True)[0]\n",
    "indicies = indicies.numpy()\n",
    "\n",
    "examples = np.empty(\n",
    "    (\n",
    "        num_classes,\n",
    "        near_neighbours_per_example + 1,\n",
    "        3,\n",
    "        height_width,\n",
    "        height_width,\n",
    "    ),\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "for row_idx in range(num_classes):\n",
    "    examples_for_class = class_idx_to_test_idxs[row_idx]\n",
    "    anchor_idx = random.choice(examples_for_class)\n",
    "    examples[row_idx, 0] = x_test[anchor_idx]\n",
    "    anchor_near_neighbours = indicies[anchor_idx][1:near_neighbours_per_example+1]\n",
    "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
    "        examples[row_idx, col_idx + 1] = x_test[nn_idx]\n",
    "\n",
    "show_collage(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 八、基于 paddle.jit.to_static 的实现动转静"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8.1 改写组网代码\n",
    "一般来说，相比于trace的方式，飞桨更推荐使用 paddle.jit.to_static 实现动转静，也被称为基于源代码转写的动态图转静态图，其基本原理是通过分析Python代码来将动态图代码转写为静态图代码，并在底层自动使用执行器运行，使用起来非常方便，只需要在原网络结构的 `forward` 前添加一个装饰器 `paddle.jit.to_static` 即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyNet2(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyNet2, self).__init__()\n",
    "\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=3, \n",
    "                                      out_channels=32, \n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=2)\n",
    "         \n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=32, \n",
    "                                      out_channels=64, \n",
    "                                      kernel_size=(3,3), \n",
    "                                      stride=2)       \n",
    "        \n",
    "        self.conv3 = paddle.nn.Conv2D(in_channels=64, \n",
    "                                      out_channels=128, \n",
    "                                      kernel_size=(3,3),\n",
    "                                      stride=2)\n",
    "       \n",
    "        self.gloabl_pool = paddle.nn.AdaptiveAvgPool2D((1,1))\n",
    "\n",
    "        self.fc1 = paddle.nn.Linear(in_features=128, out_features=8)\n",
    "    \n",
    "    # 在forward 前添加 paddle.jit.to_static 装饰器\n",
    "    @paddle.jit.to_static()\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.gloabl_pool(x)\n",
    "        x = paddle.squeeze(x, axis=[2, 3])\n",
    "        x = self.fc1(x)\n",
    "        x = x / paddle.norm(x, axis=1, keepdim=True)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "通过 `model.summary` 查看网络结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_2 = MyNet2()\n",
    "model_info = paddle.summary(model_2, (10, 3, 32, 32))\n",
    "print(model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8.2 模型训练\n",
    "使用 paddle.jit.to_static 装饰器后，训练方式仍与原动态图训练一致。因此这里直接传入 `model_2` 完成模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8.3 使用 `paddle.jit.save` 保存动转静模型\n",
    "使用 `paddle.jit.to_static` 转换模型后，需要调用 `paddle.jit.save` 将保存模型，以供后续的预测部署。保存后，会产生 `model.pdmodel` 和 `model.pdiparams` 两个文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.jit.save(model_2, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8.4 使用 `paddle.jit.load` 加载动转静模型\n",
    "\n",
    "将模型导出后，需要使用 `paddle.jit.load` 加载模型。加载后的模型可以直接用于预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_2 = paddle.jit.load('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 8.5 使用动转静模型\n",
    "\n",
    "前述的模型训练训练结束之后，就可以用该网络结构来计算出任意一张图片的高维向量表示（embedding)，通过计算该图片与图片库中其他图片的高维向量表示之间的相似度，就可以按照相似程度进行排序，排序越靠前，则相似程度越高。\n",
    "\n",
    "下面对测试集中所有的图片都两两计算相似度，然后选一部分相似的图片展示出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "near_neighbours_per_example = 10\n",
    "\n",
    "x_test_t = paddle.to_tensor(x_test)\n",
    "test_images_embeddings = model_2(x_test_t)\n",
    "similarities_matrix = paddle.matmul(test_images_embeddings, test_images_embeddings, transpose_y=True) \n",
    "\n",
    "indicies = paddle.argsort(similarities_matrix, descending=True)\n",
    "indicies = indicies.numpy()\n",
    "\n",
    "examples = np.empty(\n",
    "    (\n",
    "        num_classes,\n",
    "        near_neighbours_per_example + 1,\n",
    "        3,\n",
    "        height_width,\n",
    "        height_width,\n",
    "    ),\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "for row_idx in range(num_classes):\n",
    "    examples_for_class = class_idx_to_test_idxs[row_idx]\n",
    "    anchor_idx = random.choice(examples_for_class)\n",
    "    \n",
    "    examples[row_idx, 0] = x_test[anchor_idx]\n",
    "    anchor_near_neighbours = indicies[anchor_idx][1:near_neighbours_per_example+1]\n",
    "    for col_idx, nn_idx in enumerate(anchor_near_neighbours):\n",
    "        examples[row_idx, col_idx + 1] = x_test[nn_idx]\n",
    "\n",
    "show_collage(examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
