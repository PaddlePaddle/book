{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用序列到序列模型完成数字加法\n",
    "* 作者：[jm12138](https://github.com/jm12138)\n",
    "* 日期：2020.10.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 简要介绍\n",
    "* 本示例教程介绍如何使用飞桨完成一个数字加法任务\n",
    "* 我们将会使用飞桨提供的LSTM的API，组建一个序列到序列模型\n",
    "* 并在随机生成的数据集上完成数字加法任务的模型训练与预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 环境设置\n",
    "* 本示例教程基于飞桨2.0-rc版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle version: 2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "# 导入项目运行所需的包\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "\n",
    "from visualdl import LogWriter\n",
    "\n",
    "# 打印Paddle版本\n",
    "print('paddle version: %s' % paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 构建数据集\n",
    "* 随机生成数据，并使用生成的数据构造数据集\n",
    "* 通过继承paddle.io.Dataset来完成数据集的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating datas..\n",
      "making the dataset...\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 编码函数\n",
    "def encoder(text, LEN, label_dict):\n",
    "    # 文本转ID\n",
    "    ids = [label_dict[word] for word in text]\n",
    "    # 对长度进行补齐\n",
    "    ids += [label_dict[' ']]*(LEN-len(ids))\n",
    "    return ids\n",
    "\n",
    "# 单个数据生成函数\n",
    "def make_data(inputs, labels, DIGITS, label_dict):\n",
    "    MAXLEN = DIGITS + 1 + DIGITS\n",
    "    # 对输入输出文本进行ID编码\n",
    "    inputs = encoder(inputs, MAXLEN, label_dict)\n",
    "    labels = encoder(labels, DIGITS + 1, label_dict)\n",
    "    return inputs, labels\n",
    "\n",
    "# 批量数据生成函数\n",
    "def gen_datas(DATA_NUM, MAX_NUM, DIGITS, label_dict):\n",
    "    datas = []\n",
    "    while len(datas)<DATA_NUM:\n",
    "        # 随机取两个数\n",
    "        a = random.randint(0,MAX_NUM)\n",
    "        b = random.randint(0,MAX_NUM)\n",
    "        # 生成输入文本\n",
    "        inputs = '%d+%d' % (a, b)\n",
    "        # 生成输出文本\n",
    "        labels = str(eval(inputs))\n",
    "        # 生成单个数据\n",
    "        inputs, labels = [np.array(_).astype('int64') for _ in make_data(inputs, labels, DIGITS, label_dict)]\n",
    "        datas.append([inputs, labels])\n",
    "    return datas\n",
    "\n",
    "# 继承paddle.io.Dataset来构造数据集\n",
    "class Addition_Dataset(paddle.io.Dataset):\n",
    "    # 重写数据集初始化函数\n",
    "    def __init__(self, datas):\n",
    "        super(Addition_Dataset, self).__init__()\n",
    "        self.datas = datas\n",
    "    \n",
    "    # 重写生成样本的函数\n",
    "    def __getitem__(self, index):\n",
    "        data, label = [paddle.to_tensor(_) for _ in self.datas[index]]\n",
    "        return data, label\n",
    "\n",
    "    # 重写返回数据集大小的函数\n",
    "    def __len__(self):\n",
    "        return len(self.datas)\n",
    "\n",
    "print('generating datas..')\n",
    "\n",
    "# 定义字符表\n",
    "label_dict = {\n",
    "    '0': 0, '1': 1, '2': 2, '3': 3,\n",
    "    '4': 4, '5': 5, '6': 6, '7': 7,\n",
    "    '8': 8, '9': 9, '+': 10, ' ': 11\n",
    "}\n",
    "\n",
    "# 输入数字最大位数\n",
    "DIGITS = 2\n",
    "\n",
    "# 数据数量\n",
    "train_num = 5000\n",
    "dev_num = 500\n",
    "\n",
    "# 数据批大小\n",
    "batch_size = 32\n",
    "\n",
    "# 读取线程数\n",
    "num_workers = 8\n",
    "\n",
    "# 定义一些所需变量\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "MAX_NUM = 10**(DIGITS)-1\n",
    "\n",
    "# 生成数据\n",
    "train_datas = gen_datas(\n",
    "    train_num, \n",
    "    MAX_NUM,\n",
    "    DIGITS, \n",
    "    label_dict\n",
    ") \n",
    "dev_datas = gen_datas(\n",
    "    dev_num, \n",
    "    MAX_NUM,\n",
    "    DIGITS, \n",
    "    label_dict\n",
    ")\n",
    "\n",
    "# 实例化数据集\n",
    "train_dataset = Addition_Dataset(train_datas)\n",
    "dev_dataset = Addition_Dataset(dev_datas)\n",
    "\n",
    "print('making the dataset...')\n",
    "\n",
    "# 实例化数据读取器\n",
    "train_reader = paddle.io.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "dev_reader = paddle.io.DataLoader(\n",
    "    dev_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  模型组网\n",
    "* 通过继承paddle.nn.Layer类来搭建模型\n",
    "* 本次介绍的模型是一个简单的基于LSTM的Seq2Seq模型\n",
    "* 一共有如下四个主要的网络层：\n",
    "\n",
    "  1. 嵌入层(Embedding)：将输入的文本序列转为嵌入向量\n",
    "  2. 编码层(LSTM)：将嵌入向量进行编码\n",
    "  3. 解码层(LSTM)：将编码向量进行解码\n",
    "  4. 全连接层(Linear)：对解码完成的向量进行线性映射\n",
    "* 损失函数为交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 继承paddle.nn.Layer类\n",
    "class Addition_Model(nn.Layer):\n",
    "    # 重写初始化函数\n",
    "    # 参数：字符表长度、嵌入层大小、隐藏层大小、解码器层数、处理数字的最大位数\n",
    "    def __init__(self, char_len=12, embedding_size=128, hidden_size=128, num_layers=1, DIGITS=2):\n",
    "        super(Addition_Model, self).__init__()\n",
    "        # 初始化变量\n",
    "        self.DIGITS = DIGITS\n",
    "        self.MAXLEN = DIGITS + 1 + DIGITS\n",
    "        self.hidden_size = hidden_size\n",
    "        self.char_len = char_len\n",
    "\n",
    "        # 嵌入层\n",
    "        self.emb = nn.Embedding(\n",
    "            char_len, \n",
    "            embedding_size\n",
    "        )\n",
    "        \n",
    "        # 编码器\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=embedding_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1\n",
    "        )\n",
    "        \n",
    "        # 解码器\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_size, \n",
    "            char_len\n",
    "        )\n",
    "    \n",
    "    # 重写模型前向计算函数\n",
    "    # 参数：输入[None, MAXLEN]、标签[None, DIGITS + 1]\n",
    "    def forward(self, inputs, labels=None):\n",
    "        # 嵌入层\n",
    "        out = self.emb(inputs)\n",
    "\n",
    "        # 编码器\n",
    "        out, (_, _) = self.encoder(out)\n",
    "\n",
    "        # 按时间步切分编码器输出\n",
    "        out = paddle.split(out, self.MAXLEN, axis=1)\n",
    "\n",
    "        # 取最后一个时间步的输出并复制 DIGITS + 1 次\n",
    "        out = paddle.expand(out[-1], [out[-1].shape[0], self.DIGITS + 1, self.hidden_size])\n",
    "\n",
    "        # 解码器\n",
    "        out, (_, _) = self.decoder(out)\n",
    "\n",
    "        # 全连接\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # 如果标签存在，则计算其损失和准确率\n",
    "        if labels is not None:\n",
    "            # 转置解码器输出\n",
    "            tmp = paddle.transpose(out, [0, 2, 1])\n",
    "\n",
    "            # 计算交叉熵损失\n",
    "            loss = nn.functional.cross_entropy(tmp, labels, axis=1)\n",
    "\n",
    "            # 计算准确率\n",
    "            acc = paddle.metric.accuracy(paddle.reshape(out, [-1, self.char_len]), paddle.reshape(labels, [-1, 1]))\n",
    "\n",
    "            # 返回损失和准确率\n",
    "            return loss, acc\n",
    "\n",
    "        # 返回输出\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "* 使用Adam作为优化器进行模型训练\n",
    "* 以模型准确率作为评价指标\n",
    "* 使用VisualDL对训练数据进行可视化\n",
    "* 训练过程中会同时进行模型评估和最佳模型的保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch:0 step: 0 loss:2.486548 acc:0.072917\n",
      "eval epoch:0 step: 0 loss:2.486549 acc:0.072917\n",
      "saving the best_model...\n",
      "train epoch:0 step: 20 loss:2.260141 acc:0.333333\n",
      "train epoch:0 step: 40 loss:2.139997 acc:0.333333\n",
      "train epoch:0 step: 60 loss:1.820772 acc:0.406250\n",
      "train epoch:0 step: 80 loss:1.765519 acc:0.406250\n",
      "train epoch:0 step: 100 loss:1.852962 acc:0.427083\n",
      "train epoch:0 step: 120 loss:1.875763 acc:0.395833\n",
      "train epoch:0 step: 140 loss:1.733827 acc:0.406250\n",
      "train epoch:1 step: 160 loss:1.641314 acc:0.385417\n",
      "train epoch:1 step: 180 loss:1.601028 acc:0.395833\n",
      "train epoch:1 step: 200 loss:1.590695 acc:0.395833\n",
      "train epoch:1 step: 220 loss:1.590466 acc:0.458333\n",
      "train epoch:1 step: 240 loss:1.461456 acc:0.489583\n",
      "train epoch:1 step: 260 loss:1.590603 acc:0.447917\n",
      "train epoch:1 step: 280 loss:1.437094 acc:0.458333\n",
      "train epoch:1 step: 300 loss:1.439966 acc:0.489583\n",
      "train epoch:2 step: 320 loss:1.422302 acc:0.489583\n",
      "train epoch:2 step: 340 loss:1.355924 acc:0.437500\n",
      "train epoch:2 step: 360 loss:1.304865 acc:0.520833\n",
      "train epoch:2 step: 380 loss:1.230000 acc:0.593750\n",
      "train epoch:2 step: 400 loss:1.370301 acc:0.531250\n",
      "train epoch:2 step: 420 loss:1.302810 acc:0.520833\n",
      "train epoch:2 step: 440 loss:1.258698 acc:0.572917\n",
      "train epoch:2 step: 460 loss:1.224450 acc:0.572917\n",
      "train epoch:3 step: 480 loss:1.301404 acc:0.531250\n",
      "train epoch:3 step: 500 loss:1.178292 acc:0.593750\n",
      "eval epoch:3 step: 500 loss:1.178292 acc:0.593750\n",
      "saving the best_model...\n",
      "train epoch:3 step: 520 loss:1.138962 acc:0.666667\n",
      "train epoch:3 step: 540 loss:1.150443 acc:0.635417\n",
      "train epoch:3 step: 560 loss:1.240931 acc:0.593750\n",
      "train epoch:3 step: 580 loss:1.139939 acc:0.572917\n",
      "train epoch:3 step: 600 loss:1.162589 acc:0.520833\n",
      "train epoch:3 step: 620 loss:1.092722 acc:0.614583\n",
      "train epoch:4 step: 640 loss:1.183408 acc:0.572917\n",
      "train epoch:4 step: 660 loss:1.048823 acc:0.625000\n",
      "train epoch:4 step: 680 loss:1.121530 acc:0.614583\n",
      "train epoch:4 step: 700 loss:1.054723 acc:0.635417\n",
      "train epoch:4 step: 720 loss:1.028928 acc:0.614583\n",
      "train epoch:4 step: 740 loss:1.123822 acc:0.583333\n",
      "train epoch:4 step: 760 loss:1.042357 acc:0.593750\n",
      "train epoch:5 step: 780 loss:1.139612 acc:0.572917\n",
      "train epoch:5 step: 800 loss:0.970891 acc:0.635417\n",
      "train epoch:5 step: 820 loss:1.115770 acc:0.614583\n",
      "train epoch:5 step: 840 loss:0.989957 acc:0.625000\n",
      "train epoch:5 step: 860 loss:0.987128 acc:0.656250\n",
      "train epoch:5 step: 880 loss:0.974426 acc:0.614583\n",
      "train epoch:5 step: 900 loss:0.975975 acc:0.687500\n",
      "train epoch:5 step: 920 loss:1.016428 acc:0.656250\n",
      "train epoch:6 step: 940 loss:1.013526 acc:0.697917\n",
      "train epoch:6 step: 960 loss:0.998930 acc:0.645833\n",
      "train epoch:6 step: 980 loss:1.054841 acc:0.625000\n",
      "train epoch:6 step: 1000 loss:1.013767 acc:0.635417\n",
      "eval epoch:6 step: 1000 loss:1.013767 acc:0.635417\n",
      "saving the best_model...\n",
      "train epoch:6 step: 1020 loss:1.071271 acc:0.531250\n",
      "train epoch:6 step: 1040 loss:0.980852 acc:0.635417\n",
      "train epoch:6 step: 1060 loss:1.026074 acc:0.625000\n",
      "train epoch:6 step: 1080 loss:0.976788 acc:0.656250\n",
      "train epoch:7 step: 1100 loss:1.018781 acc:0.625000\n",
      "train epoch:7 step: 1120 loss:0.960916 acc:0.697917\n",
      "train epoch:7 step: 1140 loss:0.966610 acc:0.666667\n",
      "train epoch:7 step: 1160 loss:1.040557 acc:0.604167\n",
      "train epoch:7 step: 1180 loss:0.917395 acc:0.687500\n",
      "train epoch:7 step: 1200 loss:0.926229 acc:0.656250\n",
      "train epoch:7 step: 1220 loss:0.934969 acc:0.697917\n",
      "train epoch:7 step: 1240 loss:1.016266 acc:0.604167\n",
      "train epoch:8 step: 1260 loss:0.969778 acc:0.656250\n",
      "train epoch:8 step: 1280 loss:1.002266 acc:0.645833\n",
      "train epoch:8 step: 1300 loss:0.892168 acc:0.708333\n",
      "train epoch:8 step: 1320 loss:0.934409 acc:0.656250\n",
      "train epoch:8 step: 1340 loss:0.930469 acc:0.677083\n",
      "train epoch:8 step: 1360 loss:0.874903 acc:0.729167\n",
      "train epoch:8 step: 1380 loss:0.991352 acc:0.635417\n",
      "train epoch:8 step: 1400 loss:0.964139 acc:0.666667\n",
      "train epoch:9 step: 1420 loss:0.928553 acc:0.697917\n",
      "train epoch:9 step: 1440 loss:0.986520 acc:0.656250\n",
      "train epoch:9 step: 1460 loss:1.041585 acc:0.604167\n",
      "train epoch:9 step: 1480 loss:0.880398 acc:0.666667\n",
      "train epoch:9 step: 1500 loss:0.930438 acc:0.625000\n",
      "eval epoch:9 step: 1500 loss:0.930438 acc:0.625000\n",
      "train epoch:9 step: 1520 loss:0.912419 acc:0.666667\n",
      "train epoch:9 step: 1540 loss:0.859487 acc:0.687500\n",
      "train epoch:10 step: 1560 loss:0.878251 acc:0.666667\n",
      "train epoch:10 step: 1580 loss:0.888359 acc:0.677083\n",
      "train epoch:10 step: 1600 loss:0.949538 acc:0.645833\n",
      "train epoch:10 step: 1620 loss:0.956788 acc:0.635417\n",
      "train epoch:10 step: 1640 loss:0.906302 acc:0.635417\n",
      "train epoch:10 step: 1660 loss:0.840698 acc:0.677083\n",
      "train epoch:10 step: 1680 loss:0.865750 acc:0.645833\n",
      "train epoch:10 step: 1700 loss:0.870429 acc:0.666667\n",
      "train epoch:11 step: 1720 loss:0.806834 acc:0.718750\n",
      "train epoch:11 step: 1740 loss:0.896025 acc:0.645833\n",
      "train epoch:11 step: 1760 loss:0.806666 acc:0.697917\n",
      "train epoch:11 step: 1780 loss:0.851698 acc:0.697917\n",
      "train epoch:11 step: 1800 loss:0.825811 acc:0.656250\n",
      "train epoch:11 step: 1820 loss:0.767079 acc:0.739583\n",
      "train epoch:11 step: 1840 loss:0.885001 acc:0.645833\n",
      "train epoch:11 step: 1860 loss:0.768653 acc:0.729167\n",
      "train epoch:12 step: 1880 loss:0.781827 acc:0.770833\n",
      "train epoch:12 step: 1900 loss:0.932543 acc:0.656250\n",
      "train epoch:12 step: 1920 loss:0.842592 acc:0.697917\n",
      "train epoch:12 step: 1940 loss:0.782290 acc:0.729167\n",
      "train epoch:12 step: 1960 loss:0.781843 acc:0.718750\n",
      "train epoch:12 step: 1980 loss:0.866786 acc:0.708333\n",
      "train epoch:12 step: 2000 loss:0.880332 acc:0.687500\n",
      "eval epoch:12 step: 2000 loss:0.880332 acc:0.687500\n",
      "saving the best_model...\n",
      "train epoch:12 step: 2020 loss:0.823978 acc:0.697917\n",
      "train epoch:13 step: 2040 loss:0.901520 acc:0.697917\n",
      "train epoch:13 step: 2060 loss:0.765493 acc:0.750000\n",
      "train epoch:13 step: 2080 loss:0.812039 acc:0.697917\n",
      "train epoch:13 step: 2100 loss:0.792369 acc:0.739583\n",
      "train epoch:13 step: 2120 loss:0.717338 acc:0.729167\n",
      "train epoch:13 step: 2140 loss:0.764331 acc:0.729167\n",
      "train epoch:13 step: 2160 loss:0.771884 acc:0.739583\n",
      "train epoch:13 step: 2180 loss:0.758794 acc:0.739583\n",
      "train epoch:14 step: 2200 loss:0.742126 acc:0.708333\n",
      "train epoch:14 step: 2220 loss:0.676514 acc:0.791667\n",
      "train epoch:14 step: 2240 loss:0.709569 acc:0.718750\n",
      "train epoch:14 step: 2260 loss:0.831361 acc:0.666667\n",
      "train epoch:14 step: 2280 loss:0.717796 acc:0.739583\n",
      "train epoch:14 step: 2300 loss:0.692108 acc:0.760417\n",
      "train epoch:14 step: 2320 loss:0.721314 acc:0.697917\n",
      "train epoch:15 step: 2340 loss:0.650314 acc:0.812500\n",
      "train epoch:15 step: 2360 loss:0.717120 acc:0.708333\n",
      "train epoch:15 step: 2380 loss:0.691813 acc:0.718750\n",
      "train epoch:15 step: 2400 loss:0.671663 acc:0.750000\n",
      "train epoch:15 step: 2420 loss:0.648233 acc:0.781250\n",
      "train epoch:15 step: 2440 loss:0.610206 acc:0.802083\n",
      "train epoch:15 step: 2460 loss:0.646852 acc:0.760417\n",
      "train epoch:15 step: 2480 loss:0.694268 acc:0.770833\n",
      "train epoch:16 step: 2500 loss:0.632738 acc:0.791667\n",
      "eval epoch:16 step: 2500 loss:0.632738 acc:0.791667\n",
      "saving the best_model...\n",
      "train epoch:16 step: 2520 loss:0.608154 acc:0.760417\n",
      "train epoch:16 step: 2540 loss:0.580825 acc:0.812500\n",
      "train epoch:16 step: 2560 loss:0.641632 acc:0.760417\n",
      "train epoch:16 step: 2580 loss:0.557802 acc:0.864583\n",
      "train epoch:16 step: 2600 loss:0.614217 acc:0.770833\n",
      "train epoch:16 step: 2620 loss:0.735146 acc:0.666667\n",
      "train epoch:16 step: 2640 loss:0.543176 acc:0.833333\n",
      "train epoch:17 step: 2660 loss:0.556179 acc:0.843750\n",
      "train epoch:17 step: 2680 loss:0.511898 acc:0.843750\n",
      "train epoch:17 step: 2700 loss:0.619927 acc:0.781250\n",
      "train epoch:17 step: 2720 loss:0.497720 acc:0.875000\n",
      "train epoch:17 step: 2740 loss:0.585230 acc:0.739583\n",
      "train epoch:17 step: 2760 loss:0.480201 acc:0.854167\n",
      "train epoch:17 step: 2780 loss:0.422440 acc:0.864583\n",
      "train epoch:17 step: 2800 loss:0.486946 acc:0.854167\n",
      "train epoch:18 step: 2820 loss:0.416083 acc:0.885417\n",
      "train epoch:18 step: 2840 loss:0.428803 acc:0.864583\n",
      "train epoch:18 step: 2860 loss:0.433852 acc:0.885417\n",
      "train epoch:18 step: 2880 loss:0.395985 acc:0.895833\n",
      "train epoch:18 step: 2900 loss:0.383488 acc:0.895833\n",
      "train epoch:18 step: 2920 loss:0.377950 acc:0.937500\n",
      "train epoch:18 step: 2940 loss:0.381318 acc:0.895833\n",
      "train epoch:18 step: 2960 loss:0.319607 acc:0.927083\n",
      "train epoch:19 step: 2980 loss:0.325204 acc:0.916667\n",
      "train epoch:19 step: 3000 loss:0.368015 acc:0.864583\n",
      "eval epoch:19 step: 3000 loss:0.368015 acc:0.864583\n",
      "saving the best_model...\n",
      "train epoch:19 step: 3020 loss:0.359933 acc:0.864583\n",
      "train epoch:19 step: 3040 loss:0.285664 acc:0.947917\n",
      "train epoch:19 step: 3060 loss:0.297231 acc:0.895833\n",
      "train epoch:19 step: 3080 loss:0.314498 acc:0.927083\n",
      "train epoch:19 step: 3100 loss:0.313615 acc:0.895833\n",
      "train epoch:20 step: 3120 loss:0.327905 acc:0.895833\n",
      "train epoch:20 step: 3140 loss:0.316967 acc:0.906250\n",
      "train epoch:20 step: 3160 loss:0.262745 acc:0.958333\n",
      "train epoch:20 step: 3180 loss:0.176449 acc:0.968750\n",
      "train epoch:20 step: 3200 loss:0.248395 acc:0.937500\n",
      "train epoch:20 step: 3220 loss:0.263848 acc:0.958333\n",
      "train epoch:20 step: 3240 loss:0.249777 acc:0.958333\n",
      "train epoch:20 step: 3260 loss:0.250117 acc:0.927083\n",
      "train epoch:21 step: 3280 loss:0.201102 acc:0.968750\n",
      "train epoch:21 step: 3300 loss:0.225758 acc:0.947917\n",
      "train epoch:21 step: 3320 loss:0.201160 acc:0.979167\n",
      "train epoch:21 step: 3340 loss:0.169917 acc:0.989583\n",
      "train epoch:21 step: 3360 loss:0.219832 acc:0.958333\n",
      "train epoch:21 step: 3380 loss:0.213279 acc:0.958333\n",
      "train epoch:21 step: 3400 loss:0.202735 acc:0.989583\n",
      "train epoch:21 step: 3420 loss:0.203242 acc:0.958333\n",
      "train epoch:22 step: 3440 loss:0.171061 acc:0.989583\n",
      "train epoch:22 step: 3460 loss:0.166415 acc:0.979167\n",
      "train epoch:22 step: 3480 loss:0.170711 acc:0.989583\n",
      "train epoch:22 step: 3500 loss:0.152972 acc:0.968750\n",
      "eval epoch:22 step: 3500 loss:0.152972 acc:0.968750\n",
      "saving the best_model...\n",
      "train epoch:22 step: 3520 loss:0.103544 acc:0.989583\n",
      "train epoch:22 step: 3540 loss:0.130283 acc:0.989583\n",
      "train epoch:22 step: 3560 loss:0.186975 acc:0.937500\n",
      "train epoch:22 step: 3580 loss:0.168501 acc:0.968750\n",
      "train epoch:23 step: 3600 loss:0.160285 acc:0.968750\n",
      "train epoch:23 step: 3620 loss:0.140679 acc:0.979167\n",
      "train epoch:23 step: 3640 loss:0.129261 acc:0.979167\n",
      "train epoch:23 step: 3660 loss:0.100736 acc:0.989583\n",
      "train epoch:23 step: 3680 loss:0.126349 acc:0.989583\n",
      "train epoch:23 step: 3700 loss:0.126446 acc:1.000000\n",
      "train epoch:23 step: 3720 loss:0.154227 acc:0.979167\n",
      "train epoch:23 step: 3740 loss:0.117935 acc:1.000000\n",
      "train epoch:24 step: 3760 loss:0.123040 acc:1.000000\n",
      "train epoch:24 step: 3780 loss:0.085795 acc:1.000000\n",
      "train epoch:24 step: 3800 loss:0.099137 acc:0.989583\n",
      "train epoch:24 step: 3820 loss:0.099387 acc:0.989583\n",
      "train epoch:24 step: 3840 loss:0.077849 acc:1.000000\n",
      "train epoch:24 step: 3860 loss:0.099428 acc:0.989583\n",
      "train epoch:24 step: 3880 loss:0.094824 acc:0.979167\n",
      "train epoch:25 step: 3900 loss:0.074612 acc:1.000000\n",
      "train epoch:25 step: 3920 loss:0.064493 acc:0.989583\n",
      "train epoch:25 step: 3940 loss:0.099728 acc:0.979167\n",
      "train epoch:25 step: 3960 loss:0.108604 acc:0.979167\n",
      "train epoch:25 step: 3980 loss:0.135747 acc:0.968750\n",
      "train epoch:25 step: 4000 loss:0.102092 acc:0.989583\n",
      "eval epoch:25 step: 4000 loss:0.102092 acc:0.989583\n",
      "saving the best_model...\n",
      "train epoch:25 step: 4020 loss:0.083873 acc:0.979167\n",
      "train epoch:25 step: 4040 loss:0.087221 acc:0.989583\n",
      "train epoch:26 step: 4060 loss:0.128661 acc:0.979167\n",
      "train epoch:26 step: 4080 loss:0.134048 acc:0.958333\n",
      "train epoch:26 step: 4100 loss:0.106933 acc:0.989583\n",
      "train epoch:26 step: 4120 loss:0.089440 acc:0.979167\n",
      "train epoch:26 step: 4140 loss:0.108521 acc:0.958333\n",
      "train epoch:26 step: 4160 loss:0.194250 acc:0.958333\n",
      "train epoch:26 step: 4180 loss:0.054691 acc:1.000000\n",
      "train epoch:26 step: 4200 loss:0.107635 acc:0.979167\n",
      "train epoch:27 step: 4220 loss:0.067887 acc:0.989583\n",
      "train epoch:27 step: 4240 loss:0.050490 acc:1.000000\n",
      "train epoch:27 step: 4260 loss:0.060682 acc:1.000000\n",
      "train epoch:27 step: 4280 loss:0.085388 acc:0.989583\n",
      "train epoch:27 step: 4300 loss:0.067292 acc:0.989583\n",
      "train epoch:27 step: 4320 loss:0.030463 acc:1.000000\n",
      "train epoch:27 step: 4340 loss:0.050816 acc:1.000000\n",
      "train epoch:27 step: 4360 loss:0.066348 acc:0.979167\n",
      "train epoch:28 step: 4380 loss:0.080434 acc:0.979167\n",
      "train epoch:28 step: 4400 loss:0.022713 acc:1.000000\n",
      "train epoch:28 step: 4420 loss:0.031241 acc:1.000000\n",
      "train epoch:28 step: 4440 loss:0.040947 acc:1.000000\n",
      "train epoch:28 step: 4460 loss:0.043429 acc:1.000000\n",
      "train epoch:28 step: 4480 loss:0.033652 acc:1.000000\n",
      "train epoch:28 step: 4500 loss:0.038551 acc:1.000000\n",
      "eval epoch:28 step: 4500 loss:0.038551 acc:1.000000\n",
      "saving the best_model...\n",
      "train epoch:28 step: 4520 loss:0.046203 acc:1.000000\n",
      "train epoch:29 step: 4540 loss:0.030782 acc:1.000000\n",
      "train epoch:29 step: 4560 loss:0.046843 acc:0.989583\n",
      "train epoch:29 step: 4580 loss:0.037742 acc:1.000000\n",
      "train epoch:29 step: 4600 loss:0.041122 acc:1.000000\n",
      "train epoch:29 step: 4620 loss:0.038534 acc:1.000000\n",
      "train epoch:29 step: 4640 loss:0.027164 acc:1.000000\n",
      "train epoch:29 step: 4660 loss:0.062632 acc:0.979167\n",
      "train epoch:30 step: 4680 loss:0.049593 acc:0.989583\n",
      "train epoch:30 step: 4700 loss:0.044264 acc:1.000000\n",
      "train epoch:30 step: 4720 loss:0.024513 acc:1.000000\n",
      "train epoch:30 step: 4740 loss:0.023750 acc:1.000000\n",
      "train epoch:30 step: 4760 loss:0.028852 acc:1.000000\n",
      "train epoch:30 step: 4780 loss:0.031783 acc:1.000000\n",
      "train epoch:30 step: 4800 loss:0.038466 acc:0.989583\n",
      "train epoch:30 step: 4820 loss:0.019291 acc:1.000000\n",
      "train epoch:31 step: 4840 loss:0.028960 acc:1.000000\n",
      "train epoch:31 step: 4860 loss:0.022252 acc:1.000000\n",
      "train epoch:31 step: 4880 loss:0.034499 acc:0.989583\n",
      "train epoch:31 step: 4900 loss:0.107220 acc:0.958333\n",
      "train epoch:31 step: 4920 loss:0.158680 acc:0.947917\n",
      "train epoch:31 step: 4940 loss:0.448066 acc:0.854167\n",
      "train epoch:31 step: 4960 loss:0.123449 acc:0.968750\n",
      "train epoch:31 step: 4980 loss:0.166457 acc:0.947917\n",
      "train epoch:32 step: 5000 loss:0.146060 acc:0.979167\n",
      "eval epoch:32 step: 5000 loss:0.146060 acc:0.979167\n",
      "train epoch:32 step: 5020 loss:0.096237 acc:0.968750\n",
      "train epoch:32 step: 5040 loss:0.084249 acc:0.968750\n",
      "train epoch:32 step: 5060 loss:0.065500 acc:0.989583\n",
      "train epoch:32 step: 5080 loss:0.046099 acc:1.000000\n",
      "train epoch:32 step: 5100 loss:0.028598 acc:1.000000\n",
      "train epoch:32 step: 5120 loss:0.026211 acc:0.989583\n",
      "train epoch:32 step: 5140 loss:0.026206 acc:1.000000\n",
      "train epoch:33 step: 5160 loss:0.030863 acc:1.000000\n",
      "train epoch:33 step: 5180 loss:0.036857 acc:0.989583\n",
      "train epoch:33 step: 5200 loss:0.024915 acc:1.000000\n",
      "train epoch:33 step: 5220 loss:0.024145 acc:1.000000\n",
      "train epoch:33 step: 5240 loss:0.028263 acc:0.989583\n",
      "train epoch:33 step: 5260 loss:0.019190 acc:1.000000\n",
      "train epoch:33 step: 5280 loss:0.018305 acc:1.000000\n",
      "train epoch:33 step: 5300 loss:0.038324 acc:1.000000\n",
      "train epoch:34 step: 5320 loss:0.021196 acc:1.000000\n",
      "train epoch:34 step: 5340 loss:0.019400 acc:1.000000\n",
      "train epoch:34 step: 5360 loss:0.022801 acc:1.000000\n",
      "train epoch:34 step: 5380 loss:0.030529 acc:1.000000\n",
      "train epoch:34 step: 5400 loss:0.035136 acc:0.979167\n",
      "train epoch:34 step: 5420 loss:0.020913 acc:1.000000\n",
      "train epoch:34 step: 5440 loss:0.018717 acc:1.000000\n",
      "train epoch:35 step: 5460 loss:0.018810 acc:1.000000\n",
      "train epoch:35 step: 5480 loss:0.020277 acc:1.000000\n",
      "train epoch:35 step: 5500 loss:0.015930 acc:1.000000\n",
      "eval epoch:35 step: 5500 loss:0.015930 acc:1.000000\n",
      "train epoch:35 step: 5520 loss:0.011227 acc:1.000000\n",
      "train epoch:35 step: 5540 loss:0.014070 acc:1.000000\n",
      "train epoch:35 step: 5560 loss:0.011568 acc:1.000000\n",
      "train epoch:35 step: 5580 loss:0.017833 acc:1.000000\n",
      "train epoch:35 step: 5600 loss:0.026026 acc:0.989583\n",
      "train epoch:36 step: 5620 loss:0.014723 acc:1.000000\n",
      "train epoch:36 step: 5640 loss:0.016984 acc:1.000000\n",
      "train epoch:36 step: 5660 loss:0.012258 acc:1.000000\n",
      "train epoch:36 step: 5680 loss:0.011090 acc:1.000000\n",
      "train epoch:36 step: 5700 loss:0.013938 acc:1.000000\n",
      "train epoch:36 step: 5720 loss:0.009997 acc:1.000000\n",
      "train epoch:36 step: 5740 loss:0.018753 acc:1.000000\n",
      "train epoch:36 step: 5760 loss:0.015412 acc:1.000000\n",
      "train epoch:37 step: 5780 loss:0.010864 acc:1.000000\n",
      "train epoch:37 step: 5800 loss:0.009183 acc:1.000000\n",
      "train epoch:37 step: 5820 loss:0.019050 acc:1.000000\n",
      "train epoch:37 step: 5840 loss:0.016417 acc:1.000000\n",
      "train epoch:37 step: 5860 loss:0.023921 acc:1.000000\n",
      "train epoch:37 step: 5880 loss:0.008792 acc:1.000000\n",
      "train epoch:37 step: 5900 loss:0.010345 acc:1.000000\n",
      "train epoch:37 step: 5920 loss:0.007101 acc:1.000000\n",
      "train epoch:38 step: 5940 loss:0.013960 acc:1.000000\n",
      "train epoch:38 step: 5960 loss:0.011658 acc:1.000000\n",
      "train epoch:38 step: 5980 loss:0.010058 acc:1.000000\n",
      "train epoch:38 step: 6000 loss:0.006272 acc:1.000000\n",
      "eval epoch:38 step: 6000 loss:0.006272 acc:1.000000\n",
      "train epoch:38 step: 6020 loss:0.009750 acc:1.000000\n",
      "train epoch:38 step: 6040 loss:0.010266 acc:1.000000\n",
      "train epoch:38 step: 6060 loss:0.009202 acc:1.000000\n",
      "train epoch:38 step: 6080 loss:0.008116 acc:1.000000\n",
      "train epoch:39 step: 6100 loss:0.008218 acc:1.000000\n",
      "train epoch:39 step: 6120 loss:0.006503 acc:1.000000\n",
      "train epoch:39 step: 6140 loss:0.026469 acc:0.989583\n",
      "train epoch:39 step: 6160 loss:0.009548 acc:1.000000\n",
      "train epoch:39 step: 6180 loss:0.009454 acc:1.000000\n",
      "train epoch:39 step: 6200 loss:0.008672 acc:1.000000\n",
      "train epoch:39 step: 6220 loss:0.006432 acc:1.000000\n",
      "train epoch:40 step: 6240 loss:0.006211 acc:1.000000\n",
      "train epoch:40 step: 6260 loss:0.006354 acc:1.000000\n",
      "train epoch:40 step: 6280 loss:0.009316 acc:1.000000\n",
      "train epoch:40 step: 6300 loss:0.005327 acc:1.000000\n",
      "train epoch:40 step: 6320 loss:0.013754 acc:1.000000\n",
      "train epoch:40 step: 6340 loss:0.009717 acc:1.000000\n",
      "train epoch:40 step: 6360 loss:0.014396 acc:1.000000\n",
      "train epoch:40 step: 6380 loss:0.017245 acc:1.000000\n",
      "train epoch:41 step: 6400 loss:0.246784 acc:0.916667\n",
      "train epoch:41 step: 6420 loss:0.258765 acc:0.885417\n",
      "train epoch:41 step: 6440 loss:0.256785 acc:0.895833\n",
      "train epoch:41 step: 6460 loss:0.157417 acc:0.947917\n",
      "train epoch:41 step: 6480 loss:0.138986 acc:0.947917\n",
      "train epoch:41 step: 6500 loss:0.102885 acc:0.968750\n",
      "eval epoch:41 step: 6500 loss:0.102885 acc:0.968750\n",
      "train epoch:41 step: 6520 loss:0.113847 acc:0.968750\n",
      "train epoch:41 step: 6540 loss:0.058566 acc:0.979167\n",
      "train epoch:42 step: 6560 loss:0.015960 acc:1.000000\n",
      "train epoch:42 step: 6580 loss:0.014863 acc:1.000000\n",
      "train epoch:42 step: 6600 loss:0.022125 acc:1.000000\n",
      "train epoch:42 step: 6620 loss:0.012943 acc:1.000000\n",
      "train epoch:42 step: 6640 loss:0.038277 acc:0.979167\n",
      "train epoch:42 step: 6660 loss:0.014131 acc:1.000000\n",
      "train epoch:42 step: 6680 loss:0.011649 acc:1.000000\n",
      "train epoch:42 step: 6700 loss:0.010683 acc:1.000000\n",
      "train epoch:43 step: 6720 loss:0.009636 acc:1.000000\n",
      "train epoch:43 step: 6740 loss:0.011469 acc:1.000000\n",
      "train epoch:43 step: 6760 loss:0.032507 acc:0.989583\n",
      "train epoch:43 step: 6780 loss:0.024851 acc:1.000000\n",
      "train epoch:43 step: 6800 loss:0.006909 acc:1.000000\n",
      "train epoch:43 step: 6820 loss:0.009160 acc:1.000000\n",
      "train epoch:43 step: 6840 loss:0.008299 acc:1.000000\n",
      "train epoch:43 step: 6860 loss:0.005938 acc:1.000000\n",
      "train epoch:44 step: 6880 loss:0.018785 acc:0.989583\n",
      "train epoch:44 step: 6900 loss:0.006353 acc:1.000000\n",
      "train epoch:44 step: 6920 loss:0.024220 acc:0.989583\n",
      "train epoch:44 step: 6940 loss:0.004046 acc:1.000000\n",
      "train epoch:44 step: 6960 loss:0.008634 acc:1.000000\n",
      "train epoch:44 step: 6980 loss:0.005675 acc:1.000000\n",
      "train epoch:44 step: 7000 loss:0.005801 acc:1.000000\n",
      "eval epoch:44 step: 7000 loss:0.005801 acc:1.000000\n",
      "train epoch:45 step: 7020 loss:0.017801 acc:1.000000\n",
      "train epoch:45 step: 7040 loss:0.007127 acc:1.000000\n",
      "train epoch:45 step: 7060 loss:0.025303 acc:0.989583\n",
      "train epoch:45 step: 7080 loss:0.006672 acc:1.000000\n",
      "train epoch:45 step: 7100 loss:0.006055 acc:1.000000\n",
      "train epoch:45 step: 7120 loss:0.006293 acc:1.000000\n",
      "train epoch:45 step: 7140 loss:0.014894 acc:1.000000\n",
      "train epoch:45 step: 7160 loss:0.004794 acc:1.000000\n",
      "train epoch:46 step: 7180 loss:0.004096 acc:1.000000\n",
      "train epoch:46 step: 7200 loss:0.004971 acc:1.000000\n",
      "train epoch:46 step: 7220 loss:0.004630 acc:1.000000\n",
      "train epoch:46 step: 7240 loss:0.005007 acc:1.000000\n",
      "train epoch:46 step: 7260 loss:0.004737 acc:1.000000\n",
      "train epoch:46 step: 7280 loss:0.006080 acc:1.000000\n",
      "train epoch:46 step: 7300 loss:0.010356 acc:1.000000\n",
      "train epoch:46 step: 7320 loss:0.004719 acc:1.000000\n",
      "train epoch:47 step: 7340 loss:0.004255 acc:1.000000\n",
      "train epoch:47 step: 7360 loss:0.003938 acc:1.000000\n",
      "train epoch:47 step: 7380 loss:0.004570 acc:1.000000\n",
      "train epoch:47 step: 7400 loss:0.004550 acc:1.000000\n",
      "train epoch:47 step: 7420 loss:0.005193 acc:1.000000\n",
      "train epoch:47 step: 7440 loss:0.004975 acc:1.000000\n",
      "train epoch:47 step: 7460 loss:0.005385 acc:1.000000\n",
      "train epoch:47 step: 7480 loss:0.003343 acc:1.000000\n",
      "train epoch:48 step: 7500 loss:0.005988 acc:1.000000\n",
      "eval epoch:48 step: 7500 loss:0.005988 acc:1.000000\n",
      "train epoch:48 step: 7520 loss:0.004878 acc:1.000000\n",
      "train epoch:48 step: 7540 loss:0.004909 acc:1.000000\n",
      "train epoch:48 step: 7560 loss:0.004001 acc:1.000000\n",
      "train epoch:48 step: 7580 loss:0.004231 acc:1.000000\n",
      "train epoch:48 step: 7600 loss:0.005938 acc:1.000000\n",
      "train epoch:48 step: 7620 loss:0.003067 acc:1.000000\n",
      "train epoch:48 step: 7640 loss:0.005027 acc:1.000000\n",
      "train epoch:49 step: 7660 loss:0.010901 acc:1.000000\n",
      "train epoch:49 step: 7680 loss:0.003779 acc:1.000000\n",
      "train epoch:49 step: 7700 loss:0.003575 acc:1.000000\n",
      "train epoch:49 step: 7720 loss:0.004496 acc:1.000000\n",
      "train epoch:49 step: 7740 loss:0.002857 acc:1.000000\n",
      "train epoch:49 step: 7760 loss:0.003598 acc:1.000000\n",
      "train epoch:49 step: 7780 loss:0.003575 acc:1.000000\n",
      "train epoch:50 step: 7800 loss:0.013522 acc:1.000000\n",
      "train epoch:50 step: 7820 loss:0.008594 acc:1.000000\n",
      "train epoch:50 step: 7840 loss:0.015725 acc:0.989583\n",
      "train epoch:50 step: 7860 loss:0.004317 acc:1.000000\n",
      "train epoch:50 step: 7880 loss:0.002770 acc:1.000000\n",
      "train epoch:50 step: 7900 loss:0.003247 acc:1.000000\n",
      "train epoch:50 step: 7920 loss:0.004947 acc:1.000000\n",
      "train epoch:50 step: 7940 loss:0.003834 acc:1.000000\n",
      "train epoch:51 step: 7960 loss:0.002458 acc:1.000000\n",
      "train epoch:51 step: 7980 loss:0.005163 acc:1.000000\n",
      "train epoch:51 step: 8000 loss:0.012680 acc:1.000000\n",
      "eval epoch:51 step: 8000 loss:0.012680 acc:1.000000\n",
      "train epoch:51 step: 8020 loss:0.005761 acc:1.000000\n",
      "train epoch:51 step: 8040 loss:0.002730 acc:1.000000\n",
      "train epoch:51 step: 8060 loss:0.003493 acc:1.000000\n",
      "train epoch:51 step: 8080 loss:0.026745 acc:0.989583\n",
      "train epoch:51 step: 8100 loss:0.003065 acc:1.000000\n",
      "train epoch:52 step: 8120 loss:0.007833 acc:1.000000\n",
      "train epoch:52 step: 8140 loss:0.002838 acc:1.000000\n",
      "train epoch:52 step: 8160 loss:0.002589 acc:1.000000\n",
      "train epoch:52 step: 8180 loss:0.004229 acc:1.000000\n",
      "train epoch:52 step: 8200 loss:0.002767 acc:1.000000\n",
      "train epoch:52 step: 8220 loss:0.003908 acc:1.000000\n",
      "train epoch:52 step: 8240 loss:0.003461 acc:1.000000\n",
      "train epoch:52 step: 8260 loss:0.003138 acc:1.000000\n",
      "train epoch:53 step: 8280 loss:0.002818 acc:1.000000\n",
      "train epoch:53 step: 8300 loss:0.003466 acc:1.000000\n",
      "train epoch:53 step: 8320 loss:0.003065 acc:1.000000\n",
      "train epoch:53 step: 8340 loss:0.002633 acc:1.000000\n",
      "train epoch:53 step: 8360 loss:0.002649 acc:1.000000\n",
      "train epoch:53 step: 8380 loss:0.003003 acc:1.000000\n",
      "train epoch:53 step: 8400 loss:0.002908 acc:1.000000\n",
      "train epoch:53 step: 8420 loss:0.002991 acc:1.000000\n",
      "train epoch:54 step: 8440 loss:0.002491 acc:1.000000\n",
      "train epoch:54 step: 8460 loss:0.002902 acc:1.000000\n",
      "train epoch:54 step: 8480 loss:0.002936 acc:1.000000\n",
      "train epoch:54 step: 8500 loss:0.002032 acc:1.000000\n",
      "eval epoch:54 step: 8500 loss:0.002032 acc:1.000000\n",
      "train epoch:54 step: 8520 loss:0.004455 acc:1.000000\n",
      "train epoch:54 step: 8540 loss:0.002633 acc:1.000000\n",
      "train epoch:54 step: 8560 loss:0.002573 acc:1.000000\n",
      "train epoch:55 step: 8580 loss:0.002683 acc:1.000000\n",
      "train epoch:55 step: 8600 loss:0.002352 acc:1.000000\n",
      "train epoch:55 step: 8620 loss:0.002576 acc:1.000000\n",
      "train epoch:55 step: 8640 loss:0.002501 acc:1.000000\n",
      "train epoch:55 step: 8660 loss:0.002004 acc:1.000000\n",
      "train epoch:55 step: 8680 loss:0.010133 acc:1.000000\n",
      "train epoch:55 step: 8700 loss:0.008447 acc:1.000000\n",
      "train epoch:55 step: 8720 loss:0.002390 acc:1.000000\n",
      "train epoch:56 step: 8740 loss:0.002623 acc:1.000000\n",
      "train epoch:56 step: 8760 loss:0.002708 acc:1.000000\n",
      "train epoch:56 step: 8780 loss:0.007019 acc:1.000000\n",
      "train epoch:56 step: 8800 loss:0.002337 acc:1.000000\n",
      "train epoch:56 step: 8820 loss:0.006819 acc:1.000000\n",
      "train epoch:56 step: 8840 loss:0.001835 acc:1.000000\n",
      "train epoch:56 step: 8860 loss:0.007673 acc:1.000000\n",
      "train epoch:56 step: 8880 loss:0.001898 acc:1.000000\n",
      "train epoch:57 step: 8900 loss:0.004722 acc:1.000000\n",
      "train epoch:57 step: 8920 loss:0.004679 acc:1.000000\n",
      "train epoch:57 step: 8940 loss:0.001400 acc:1.000000\n",
      "train epoch:57 step: 8960 loss:0.001559 acc:1.000000\n",
      "train epoch:57 step: 8980 loss:0.001800 acc:1.000000\n",
      "train epoch:57 step: 9000 loss:0.002320 acc:1.000000\n",
      "eval epoch:57 step: 9000 loss:0.002320 acc:1.000000\n",
      "train epoch:57 step: 9020 loss:0.015068 acc:0.989583\n",
      "train epoch:57 step: 9040 loss:0.010595 acc:1.000000\n",
      "train epoch:58 step: 9060 loss:0.002078 acc:1.000000\n",
      "train epoch:58 step: 9080 loss:0.002369 acc:1.000000\n",
      "train epoch:58 step: 9100 loss:0.003558 acc:1.000000\n",
      "train epoch:58 step: 9120 loss:0.332378 acc:0.927083\n",
      "train epoch:58 step: 9140 loss:0.722719 acc:0.760417\n",
      "train epoch:58 step: 9160 loss:0.587800 acc:0.770833\n",
      "train epoch:58 step: 9180 loss:0.226562 acc:0.916667\n",
      "train epoch:58 step: 9200 loss:0.218447 acc:0.906250\n",
      "train epoch:59 step: 9220 loss:0.035710 acc:1.000000\n",
      "train epoch:59 step: 9240 loss:0.074230 acc:0.989583\n",
      "train epoch:59 step: 9260 loss:0.020366 acc:1.000000\n",
      "train epoch:59 step: 9280 loss:0.041202 acc:0.989583\n",
      "train epoch:59 step: 9300 loss:0.025127 acc:0.989583\n",
      "train epoch:59 step: 9320 loss:0.012637 acc:1.000000\n",
      "train epoch:59 step: 9340 loss:0.015185 acc:1.000000\n",
      "train epoch:60 step: 9360 loss:0.011637 acc:1.000000\n",
      "train epoch:60 step: 9380 loss:0.018426 acc:1.000000\n",
      "train epoch:60 step: 9400 loss:0.014776 acc:1.000000\n",
      "train epoch:60 step: 9420 loss:0.094073 acc:0.989583\n",
      "train epoch:60 step: 9440 loss:0.008631 acc:1.000000\n",
      "train epoch:60 step: 9460 loss:0.008755 acc:1.000000\n",
      "train epoch:60 step: 9480 loss:0.008431 acc:1.000000\n",
      "train epoch:60 step: 9500 loss:0.031825 acc:0.989583\n",
      "eval epoch:60 step: 9500 loss:0.031825 acc:0.989583\n",
      "train epoch:61 step: 9520 loss:0.007724 acc:1.000000\n",
      "train epoch:61 step: 9540 loss:0.007437 acc:1.000000\n",
      "train epoch:61 step: 9560 loss:0.006386 acc:1.000000\n",
      "train epoch:61 step: 9580 loss:0.005539 acc:1.000000\n",
      "train epoch:61 step: 9600 loss:0.011923 acc:1.000000\n",
      "train epoch:61 step: 9620 loss:0.005140 acc:1.000000\n",
      "train epoch:61 step: 9640 loss:0.004681 acc:1.000000\n",
      "train epoch:61 step: 9660 loss:0.004649 acc:1.000000\n",
      "train epoch:62 step: 9680 loss:0.003709 acc:1.000000\n",
      "train epoch:62 step: 9700 loss:0.005331 acc:1.000000\n",
      "train epoch:62 step: 9720 loss:0.003621 acc:1.000000\n",
      "train epoch:62 step: 9740 loss:0.002976 acc:1.000000\n",
      "train epoch:62 step: 9760 loss:0.003982 acc:1.000000\n",
      "train epoch:62 step: 9780 loss:0.003954 acc:1.000000\n",
      "train epoch:62 step: 9800 loss:0.003472 acc:1.000000\n",
      "train epoch:62 step: 9820 loss:0.003942 acc:1.000000\n",
      "train epoch:63 step: 9840 loss:0.009400 acc:1.000000\n",
      "train epoch:63 step: 9860 loss:0.002873 acc:1.000000\n",
      "train epoch:63 step: 9880 loss:0.002974 acc:1.000000\n",
      "train epoch:63 step: 9900 loss:0.003141 acc:1.000000\n",
      "train epoch:63 step: 9920 loss:0.002566 acc:1.000000\n",
      "train epoch:63 step: 9940 loss:0.002308 acc:1.000000\n",
      "train epoch:63 step: 9960 loss:0.012453 acc:1.000000\n",
      "train epoch:63 step: 9980 loss:0.003023 acc:1.000000\n",
      "train epoch:64 step: 10000 loss:0.003152 acc:1.000000\n",
      "eval epoch:64 step: 10000 loss:0.003152 acc:1.000000\n",
      "train epoch:64 step: 10020 loss:0.002176 acc:1.000000\n",
      "train epoch:64 step: 10040 loss:0.002388 acc:1.000000\n",
      "train epoch:64 step: 10060 loss:0.002137 acc:1.000000\n",
      "train epoch:64 step: 10080 loss:0.005776 acc:1.000000\n",
      "train epoch:64 step: 10100 loss:0.003295 acc:1.000000\n",
      "train epoch:64 step: 10120 loss:0.002191 acc:1.000000\n",
      "train epoch:65 step: 10140 loss:0.002372 acc:1.000000\n",
      "train epoch:65 step: 10160 loss:0.003169 acc:1.000000\n",
      "train epoch:65 step: 10180 loss:0.002575 acc:1.000000\n",
      "train epoch:65 step: 10200 loss:0.002097 acc:1.000000\n",
      "train epoch:65 step: 10220 loss:0.002909 acc:1.000000\n",
      "train epoch:65 step: 10240 loss:0.002255 acc:1.000000\n",
      "train epoch:65 step: 10260 loss:0.002684 acc:1.000000\n",
      "train epoch:65 step: 10280 loss:0.003133 acc:1.000000\n",
      "train epoch:66 step: 10300 loss:0.003015 acc:1.000000\n",
      "train epoch:66 step: 10320 loss:0.001876 acc:1.000000\n",
      "train epoch:66 step: 10340 loss:0.002027 acc:1.000000\n",
      "train epoch:66 step: 10360 loss:0.002110 acc:1.000000\n",
      "train epoch:66 step: 10380 loss:0.004557 acc:1.000000\n",
      "train epoch:66 step: 10400 loss:0.002331 acc:1.000000\n",
      "train epoch:66 step: 10420 loss:0.002424 acc:1.000000\n",
      "train epoch:66 step: 10440 loss:0.002320 acc:1.000000\n",
      "train epoch:67 step: 10460 loss:0.003074 acc:1.000000\n",
      "train epoch:67 step: 10480 loss:0.002787 acc:1.000000\n",
      "train epoch:67 step: 10500 loss:0.002740 acc:1.000000\n",
      "eval epoch:67 step: 10500 loss:0.002740 acc:1.000000\n",
      "train epoch:67 step: 10520 loss:0.010280 acc:1.000000\n",
      "train epoch:67 step: 10540 loss:0.002099 acc:1.000000\n",
      "train epoch:67 step: 10560 loss:0.002440 acc:1.000000\n",
      "train epoch:67 step: 10580 loss:0.002031 acc:1.000000\n",
      "train epoch:67 step: 10600 loss:0.002206 acc:1.000000\n",
      "train epoch:68 step: 10620 loss:0.005845 acc:1.000000\n",
      "train epoch:68 step: 10640 loss:0.002164 acc:1.000000\n",
      "train epoch:68 step: 10660 loss:0.001543 acc:1.000000\n",
      "train epoch:68 step: 10680 loss:0.002082 acc:1.000000\n",
      "train epoch:68 step: 10700 loss:0.002105 acc:1.000000\n",
      "train epoch:68 step: 10720 loss:0.002338 acc:1.000000\n",
      "train epoch:68 step: 10740 loss:0.002469 acc:1.000000\n",
      "train epoch:68 step: 10760 loss:0.003305 acc:1.000000\n",
      "train epoch:69 step: 10780 loss:0.001172 acc:1.000000\n",
      "train epoch:69 step: 10800 loss:0.003825 acc:1.000000\n",
      "train epoch:69 step: 10820 loss:0.001519 acc:1.000000\n",
      "train epoch:69 step: 10840 loss:0.001267 acc:1.000000\n",
      "train epoch:69 step: 10860 loss:0.001936 acc:1.000000\n",
      "train epoch:69 step: 10880 loss:0.001927 acc:1.000000\n",
      "train epoch:69 step: 10900 loss:0.002335 acc:1.000000\n",
      "train epoch:70 step: 10920 loss:0.002058 acc:1.000000\n",
      "train epoch:70 step: 10940 loss:0.001736 acc:1.000000\n",
      "train epoch:70 step: 10960 loss:0.001259 acc:1.000000\n",
      "train epoch:70 step: 10980 loss:0.001727 acc:1.000000\n",
      "train epoch:70 step: 11000 loss:0.001971 acc:1.000000\n",
      "eval epoch:70 step: 11000 loss:0.001971 acc:1.000000\n",
      "train epoch:70 step: 11020 loss:0.001450 acc:1.000000\n",
      "train epoch:70 step: 11040 loss:0.001734 acc:1.000000\n",
      "train epoch:70 step: 11060 loss:0.001433 acc:1.000000\n",
      "train epoch:71 step: 11080 loss:0.001150 acc:1.000000\n",
      "train epoch:71 step: 11100 loss:0.001348 acc:1.000000\n",
      "train epoch:71 step: 11120 loss:0.001277 acc:1.000000\n",
      "train epoch:71 step: 11140 loss:0.002246 acc:1.000000\n",
      "train epoch:71 step: 11160 loss:0.004686 acc:1.000000\n",
      "train epoch:71 step: 11180 loss:0.001382 acc:1.000000\n",
      "train epoch:71 step: 11200 loss:0.007673 acc:1.000000\n",
      "train epoch:71 step: 11220 loss:0.001436 acc:1.000000\n",
      "train epoch:72 step: 11240 loss:0.001184 acc:1.000000\n",
      "train epoch:72 step: 11260 loss:0.001866 acc:1.000000\n",
      "train epoch:72 step: 11280 loss:0.001293 acc:1.000000\n",
      "train epoch:72 step: 11300 loss:0.001328 acc:1.000000\n",
      "train epoch:72 step: 11320 loss:0.003046 acc:1.000000\n",
      "train epoch:72 step: 11340 loss:0.001129 acc:1.000000\n",
      "train epoch:72 step: 11360 loss:0.001333 acc:1.000000\n",
      "train epoch:72 step: 11380 loss:0.001094 acc:1.000000\n",
      "train epoch:73 step: 11400 loss:0.001332 acc:1.000000\n",
      "train epoch:73 step: 11420 loss:0.001203 acc:1.000000\n",
      "train epoch:73 step: 11440 loss:0.001161 acc:1.000000\n",
      "train epoch:73 step: 11460 loss:0.000953 acc:1.000000\n",
      "train epoch:73 step: 11480 loss:0.000914 acc:1.000000\n",
      "train epoch:73 step: 11500 loss:0.001389 acc:1.000000\n",
      "eval epoch:73 step: 11500 loss:0.001389 acc:1.000000\n",
      "train epoch:73 step: 11520 loss:0.001622 acc:1.000000\n",
      "train epoch:73 step: 11540 loss:0.001672 acc:1.000000\n",
      "train epoch:74 step: 11560 loss:0.001278 acc:1.000000\n",
      "train epoch:74 step: 11580 loss:0.001100 acc:1.000000\n",
      "train epoch:74 step: 11600 loss:0.002115 acc:1.000000\n",
      "train epoch:74 step: 11620 loss:0.000786 acc:1.000000\n",
      "train epoch:74 step: 11640 loss:0.001735 acc:1.000000\n",
      "train epoch:74 step: 11660 loss:0.001504 acc:1.000000\n",
      "train epoch:74 step: 11680 loss:0.000966 acc:1.000000\n",
      "train epoch:75 step: 11700 loss:0.001213 acc:1.000000\n",
      "train epoch:75 step: 11720 loss:0.001608 acc:1.000000\n",
      "train epoch:75 step: 11740 loss:0.001201 acc:1.000000\n",
      "train epoch:75 step: 11760 loss:0.001146 acc:1.000000\n",
      "train epoch:75 step: 11780 loss:0.005886 acc:1.000000\n",
      "train epoch:75 step: 11800 loss:0.001098 acc:1.000000\n",
      "train epoch:75 step: 11820 loss:0.004650 acc:1.000000\n",
      "train epoch:75 step: 11840 loss:0.001095 acc:1.000000\n",
      "train epoch:76 step: 11860 loss:0.000808 acc:1.000000\n",
      "train epoch:76 step: 11880 loss:0.000901 acc:1.000000\n",
      "train epoch:76 step: 11900 loss:0.001321 acc:1.000000\n",
      "train epoch:76 step: 11920 loss:0.000931 acc:1.000000\n",
      "train epoch:76 step: 11940 loss:0.001178 acc:1.000000\n",
      "train epoch:76 step: 11960 loss:0.001148 acc:1.000000\n",
      "train epoch:76 step: 11980 loss:0.001288 acc:1.000000\n",
      "train epoch:76 step: 12000 loss:0.001057 acc:1.000000\n",
      "eval epoch:76 step: 12000 loss:0.001057 acc:1.000000\n",
      "train epoch:77 step: 12020 loss:0.000743 acc:1.000000\n",
      "train epoch:77 step: 12040 loss:0.000911 acc:1.000000\n",
      "train epoch:77 step: 12060 loss:0.000826 acc:1.000000\n",
      "train epoch:77 step: 12080 loss:0.001134 acc:1.000000\n",
      "train epoch:77 step: 12100 loss:0.002004 acc:1.000000\n",
      "train epoch:77 step: 12120 loss:0.000878 acc:1.000000\n",
      "train epoch:77 step: 12140 loss:0.000753 acc:1.000000\n",
      "train epoch:77 step: 12160 loss:0.000927 acc:1.000000\n",
      "train epoch:78 step: 12180 loss:0.001339 acc:1.000000\n",
      "train epoch:78 step: 12200 loss:0.001096 acc:1.000000\n",
      "train epoch:78 step: 12220 loss:0.023044 acc:0.989583\n",
      "train epoch:78 step: 12240 loss:0.494969 acc:0.875000\n",
      "train epoch:78 step: 12260 loss:0.926390 acc:0.729167\n",
      "train epoch:78 step: 12280 loss:0.231422 acc:0.916667\n",
      "train epoch:78 step: 12300 loss:0.504258 acc:0.750000\n",
      "train epoch:78 step: 12320 loss:0.078475 acc:0.968750\n",
      "train epoch:79 step: 12340 loss:0.156801 acc:0.947917\n",
      "train epoch:79 step: 12360 loss:0.037007 acc:1.000000\n",
      "train epoch:79 step: 12380 loss:0.017994 acc:1.000000\n",
      "train epoch:79 step: 12400 loss:0.022405 acc:1.000000\n",
      "train epoch:79 step: 12420 loss:0.017862 acc:0.989583\n",
      "train epoch:79 step: 12440 loss:0.012562 acc:1.000000\n",
      "train epoch:79 step: 12460 loss:0.010923 acc:1.000000\n",
      "train epoch:80 step: 12480 loss:0.005559 acc:1.000000\n",
      "train epoch:80 step: 12500 loss:0.007535 acc:1.000000\n",
      "eval epoch:80 step: 12500 loss:0.007535 acc:1.000000\n",
      "train epoch:80 step: 12520 loss:0.008828 acc:1.000000\n",
      "train epoch:80 step: 12540 loss:0.006880 acc:1.000000\n",
      "train epoch:80 step: 12560 loss:0.004601 acc:1.000000\n",
      "train epoch:80 step: 12580 loss:0.007436 acc:1.000000\n",
      "train epoch:80 step: 12600 loss:0.007975 acc:1.000000\n",
      "train epoch:80 step: 12620 loss:0.003489 acc:1.000000\n",
      "train epoch:81 step: 12640 loss:0.002571 acc:1.000000\n",
      "train epoch:81 step: 12660 loss:0.003596 acc:1.000000\n",
      "train epoch:81 step: 12680 loss:0.002780 acc:1.000000\n",
      "train epoch:81 step: 12700 loss:0.009434 acc:1.000000\n",
      "train epoch:81 step: 12720 loss:0.003432 acc:1.000000\n",
      "train epoch:81 step: 12740 loss:0.002557 acc:1.000000\n",
      "train epoch:81 step: 12760 loss:0.003448 acc:1.000000\n",
      "train epoch:81 step: 12780 loss:0.011148 acc:1.000000\n",
      "train epoch:82 step: 12800 loss:0.002859 acc:1.000000\n",
      "train epoch:82 step: 12820 loss:0.002257 acc:1.000000\n",
      "train epoch:82 step: 12840 loss:0.002420 acc:1.000000\n",
      "train epoch:82 step: 12860 loss:0.002280 acc:1.000000\n",
      "train epoch:82 step: 12880 loss:0.002221 acc:1.000000\n",
      "train epoch:82 step: 12900 loss:0.001877 acc:1.000000\n",
      "train epoch:82 step: 12920 loss:0.001880 acc:1.000000\n",
      "train epoch:82 step: 12940 loss:0.001888 acc:1.000000\n",
      "train epoch:83 step: 12960 loss:0.011013 acc:1.000000\n",
      "train epoch:83 step: 12980 loss:0.002558 acc:1.000000\n",
      "train epoch:83 step: 13000 loss:0.002211 acc:1.000000\n",
      "eval epoch:83 step: 13000 loss:0.002211 acc:1.000000\n",
      "train epoch:83 step: 13020 loss:0.002261 acc:1.000000\n",
      "train epoch:83 step: 13040 loss:0.004423 acc:1.000000\n",
      "train epoch:83 step: 13060 loss:0.001885 acc:1.000000\n",
      "train epoch:83 step: 13080 loss:0.001940 acc:1.000000\n",
      "train epoch:83 step: 13100 loss:0.006050 acc:1.000000\n",
      "train epoch:84 step: 13120 loss:0.001938 acc:1.000000\n",
      "train epoch:84 step: 13140 loss:0.001837 acc:1.000000\n",
      "train epoch:84 step: 13160 loss:0.002179 acc:1.000000\n",
      "train epoch:84 step: 13180 loss:0.002200 acc:1.000000\n",
      "train epoch:84 step: 13200 loss:0.001810 acc:1.000000\n",
      "train epoch:84 step: 13220 loss:0.001651 acc:1.000000\n",
      "train epoch:84 step: 13240 loss:0.001898 acc:1.000000\n",
      "train epoch:85 step: 13260 loss:0.001496 acc:1.000000\n",
      "train epoch:85 step: 13280 loss:0.002194 acc:1.000000\n",
      "train epoch:85 step: 13300 loss:0.001946 acc:1.000000\n",
      "train epoch:85 step: 13320 loss:0.004466 acc:1.000000\n",
      "train epoch:85 step: 13340 loss:0.001309 acc:1.000000\n",
      "train epoch:85 step: 13360 loss:0.001494 acc:1.000000\n",
      "train epoch:85 step: 13380 loss:0.001447 acc:1.000000\n",
      "train epoch:85 step: 13400 loss:0.001491 acc:1.000000\n",
      "train epoch:86 step: 13420 loss:0.001344 acc:1.000000\n",
      "train epoch:86 step: 13440 loss:0.001975 acc:1.000000\n"
     ]
    }
   ],
   "source": [
    "# 初始化log写入器\n",
    "log_writer = LogWriter(logdir=\"./log\")\n",
    "\n",
    "# 模型参数设置\n",
    "embedding_size = 128\n",
    "hidden_size=128\n",
    "num_layers=1\n",
    "\n",
    "# 训练参数设置\n",
    "epoch_num = 200\n",
    "learning_rate = 0.001\n",
    "log_iter = 20\n",
    "eval_iter = 500\n",
    "\n",
    "# 定义一些所需变量\n",
    "global_step = 0\n",
    "log_step = 0\n",
    "max_acc = 0\n",
    "\n",
    "# 实例化模型\n",
    "model = Addition_Model(\n",
    "    char_len=len(label_dict), \n",
    "    embedding_size=embedding_size, \n",
    "    hidden_size=hidden_size, \n",
    "    num_layers=num_layers, \n",
    "    DIGITS=DIGITS)\n",
    "\n",
    "# 将模型设置为训练模式\n",
    "model.train()\n",
    "\n",
    "# 设置优化器，学习率，并且把模型参数给优化器\n",
    "opt = paddle.optimizer.Adam(\n",
    "    learning_rate=learning_rate,\n",
    "    parameters=model.parameters()\n",
    ")\n",
    "\n",
    "# 启动训练，循环epoch_num个轮次\n",
    "for epoch in range(epoch_num):\n",
    "    # 遍历数据集读取数据\n",
    "    for batch_id, data in enumerate(train_reader()):\n",
    "        # 读取数据\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 模型前向计算\n",
    "        loss, acc = model(inputs, labels=labels)\n",
    "\n",
    "        # 打印训练数据\n",
    "        if global_step%log_iter==0:\n",
    "            print('train epoch:%d step: %d loss:%f acc:%f' % (epoch, global_step, loss.numpy(), acc.numpy()))\n",
    "            log_writer.add_scalar(tag=\"train/loss\", step=log_step, value=loss.numpy())\n",
    "            log_writer.add_scalar(tag=\"train/acc\", step=log_step, value=acc.numpy())\n",
    "            log_step+=1\n",
    "\n",
    "        # 模型验证\n",
    "        if global_step%eval_iter==0:\n",
    "            model.eval()\n",
    "            losses = []\n",
    "            accs = []\n",
    "            for data in dev_reader():\n",
    "                loss, acc = model(inputs, labels=labels)\n",
    "                losses.append(loss.numpy())\n",
    "                accs.append(acc.numpy())\n",
    "            avg_loss = np.concatenate(losses).mean()\n",
    "            avg_acc = np.concatenate(accs).mean()\n",
    "            print('eval epoch:%d step: %d loss:%f acc:%f' % (epoch, global_step, avg_loss, avg_acc))\n",
    "            log_writer.add_scalar(tag=\"dev/loss\", step=log_step, value=avg_loss)\n",
    "            log_writer.add_scalar(tag=\"dev/acc\", step=log_step, value=avg_acc)\n",
    "\n",
    "            # 保存最佳模型\n",
    "            if avg_acc>max_acc:\n",
    "                max_acc = avg_acc\n",
    "                print('saving the best_model...')\n",
    "                paddle.save(model.state_dict(), 'best_model')\n",
    "            model.train()\n",
    "\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "\n",
    "        # 使用优化器进行参数优化\n",
    "        opt.step()\n",
    "\n",
    "        # 清除梯度\n",
    "        opt.clear_grad()\n",
    "\n",
    "        # 全局步数加一\n",
    "        global_step += 1\n",
    "\n",
    "# 保存最终模型\n",
    "paddle.save(model.state_dict(),'final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型测试\n",
    "* 使用保存的最佳模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 反转字符表\n",
    "label_dict_adv = {v: k for k, v in label_dict.items()}\n",
    "\n",
    "# 输入计算题目\n",
    "input_text = '12+40'\n",
    "\n",
    "# 编码输入为ID\n",
    "inputs = encoder(input_text, MAXLEN, label_dict)\n",
    "\n",
    "# 转换输入为向量形式\n",
    "inputs = np.array(inputs).reshape(-1, MAXLEN)\n",
    "inputs = paddle.to_tensor(inputs)\n",
    "\n",
    "# 加载模型\n",
    "params_dict= paddle.load('best_model')\n",
    "model.set_dict(params_dict)\n",
    "\n",
    "# 设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 模型推理\n",
    "out = model(inputs)\n",
    "\n",
    "# 结果转换\n",
    "result = ''.join([label_dict_adv[_] for _ in np.argmax(out.numpy(), -1).reshape(-1)])\n",
    "\n",
    "# 打印结果\n",
    "print('the model answer: %s=%s' % (input_text, result))\n",
    "print('the true answer: %s=%s' % (input_text, eval(input_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "* 你还可以通过变换网络结构，调整数据集，尝试不同的参数的方式来进一步提升本示例当中的数字加法的效果\n",
    "* 同时，也可以尝试在其他的类似的任务中用飞桨来完成实际的实践"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
