{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用序列到序列模型完成数字加法\n",
    "* 作者：[jm12138](https://github.com/jm12138)\n",
    "* 日期：2020.10.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 简要介绍\n",
    "* 本示例教程介绍如何使用飞桨完成一个数字加法任务\n",
    "* 我们将会使用飞桨提供的LSTM的API，组建一个序列到序列模型\n",
    "* 并在随机生成的数据集上完成数字加法任务的模型训练与预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 环境设置\n",
    "* 本示例教程基于飞桨2.0-beta版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle version: 2.0.0-beta0\n"
     ]
    }
   ],
   "source": [
    "# 导入项目运行所需的包\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "\r\n",
    "from visualdl import LogWriter\r\n",
    "\r\n",
    "# 打印Paddle版本\r\n",
    "print('paddle version: %s' % paddle.__version__)\r\n",
    "\r\n",
    "# 关闭静态图模型，使用动态图\r\n",
    "paddle.disable_static()\r\n",
    "\r\n",
    "# 设置CPU为运行位置\r\n",
    "place = paddle.CPUPlace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 构建数据集\n",
    "* 随机生成数据，并使用生成的数据构造数据集\n",
    "* 通过继承paddle.io.Dataset来完成数据集的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating datas..\n",
      "making the dataset...\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# 编码函数\r\n",
    "def encoder(text, LEN, label_dict):\r\n",
    "    # 文本转ID\r\n",
    "    ids = [label_dict[word] for word in text]\r\n",
    "    # 对长度进行补齐\r\n",
    "    ids += [label_dict[' ']]*(LEN-len(ids))\r\n",
    "    return ids\r\n",
    "\r\n",
    "# 单个数据生成函数\r\n",
    "def make_data(inputs, labels, DIGITS, label_dict):\r\n",
    "    MAXLEN = DIGITS + 1 + DIGITS\r\n",
    "    # 对输入输出文本进行ID编码\r\n",
    "    inputs = encoder(inputs, MAXLEN, label_dict)\r\n",
    "    labels = encoder(labels, DIGITS + 1, label_dict)\r\n",
    "    return inputs, labels\r\n",
    "\r\n",
    "# 批量数据生成函数\r\n",
    "def gen_datas(DATA_NUM, MAX_NUM, DIGITS, label_dict):\r\n",
    "    datas = []\r\n",
    "    while len(datas)<DATA_NUM:\r\n",
    "        # 随机取两个数\r\n",
    "        a = random.randint(0,MAX_NUM)\r\n",
    "        b = random.randint(0,MAX_NUM)\r\n",
    "        # 生成输入文本\r\n",
    "        inputs = '%d+%d' % (a, b)\r\n",
    "        # 生成输出文本\r\n",
    "        labels = str(eval(inputs))\r\n",
    "        # 生成单个数据\r\n",
    "        inputs, labels = [np.array(_).astype('int64') for _ in make_data(inputs, labels, DIGITS, label_dict)]\r\n",
    "        datas.append([inputs, labels])\r\n",
    "    return datas\r\n",
    "\r\n",
    "# 继承paddle.io.Dataset来构造数据集\r\n",
    "class Addition_Dataset(paddle.io.Dataset):\r\n",
    "    # 重写数据集初始化函数\r\n",
    "    def __init__(self, datas):\r\n",
    "        super(Addition_Dataset, self).__init__()\r\n",
    "        self.datas = datas\r\n",
    "    \r\n",
    "    # 重写生成样本的函数\r\n",
    "    def __getitem__(self, index):\r\n",
    "        data, label = [paddle.to_tensor(_) for _ in self.datas[index]]\r\n",
    "        return data, label\r\n",
    "\r\n",
    "    # 重写返回数据集大小的函数\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.datas)\r\n",
    "\r\n",
    "print('generating datas..')\r\n",
    "\r\n",
    "# 定义字符表\r\n",
    "label_dict = {\r\n",
    "    '0': 0, '1': 1, '2': 2, '3': 3,\r\n",
    "    '4': 4, '5': 5, '6': 6, '7': 7,\r\n",
    "    '8': 8, '9': 9, '+': 10, ' ': 11\r\n",
    "}\r\n",
    "\r\n",
    "# 输入数字最大位数\r\n",
    "DIGITS = 2\r\n",
    "\r\n",
    "# 数据数量\r\n",
    "train_num = 5000\r\n",
    "dev_num = 500\r\n",
    "\r\n",
    "# 数据批大小\r\n",
    "batch_size = 32\r\n",
    "\r\n",
    "# 读取线程数\r\n",
    "num_workers = 8\r\n",
    "\r\n",
    "# 定义一些所需变量\r\n",
    "MAXLEN = DIGITS + 1 + DIGITS\r\n",
    "MAX_NUM = 10**(DIGITS)-1\r\n",
    "\r\n",
    "# 生成数据\r\n",
    "train_datas = gen_datas(\r\n",
    "    train_num, \r\n",
    "    MAX_NUM,\r\n",
    "    DIGITS, \r\n",
    "    label_dict\r\n",
    ") \r\n",
    "dev_datas = gen_datas(\r\n",
    "    dev_num, \r\n",
    "    MAX_NUM,\r\n",
    "    DIGITS, \r\n",
    "    label_dict\r\n",
    ")\r\n",
    "\r\n",
    "# 实例化数据集\r\n",
    "train_dataset = Addition_Dataset(train_datas)\r\n",
    "dev_dataset = Addition_Dataset(dev_datas)\r\n",
    "\r\n",
    "print('making the dataset...')\r\n",
    "\r\n",
    "# 实例化数据读取器\r\n",
    "train_reader = paddle.io.DataLoader(\r\n",
    "    train_dataset,\r\n",
    "    places=place,\r\n",
    "    batch_size=batch_size,\r\n",
    "    shuffle=True,\r\n",
    "    drop_last=False,\r\n",
    "    num_workers=num_workers\r\n",
    ")\r\n",
    "dev_reader = paddle.io.DataLoader(\r\n",
    "    dev_dataset,\r\n",
    "    places=place,\r\n",
    "    batch_size=batch_size,\r\n",
    "    shuffle=False,\r\n",
    "    drop_last=False,\r\n",
    "    num_workers=num_workers\r\n",
    ")\r\n",
    "\r\n",
    "print('finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  模型组网\n",
    "* 通过继承paddle.nn.Layer类来搭建模型\n",
    "* 本次介绍的模型是一个简单的基于LSTM的Seq2Seq模型\n",
    "* 一共有如下四个主要的网络层：\n",
    "\n",
    "  1. 嵌入层(Embedding)：将输入的文本序列转为嵌入向量\n",
    "  2. 编码层(LSTM)：将嵌入向量进行编码\n",
    "  3. 解码层(LSTM)：将编码向量进行解码\n",
    "  4. 全连接层(Linear)：对解码完成的向量进行线性映射\n",
    "* 损失函数为交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 继承paddle.nn.Layer类\r\n",
    "class Addition_Model(nn.Layer):\r\n",
    "    # 重写初始化函数\r\n",
    "    # 参数：字符表长度、嵌入层大小、隐藏层大小、解码器层数、处理数字的最大位数\r\n",
    "    def __init__(self, char_len=12, embedding_size=128, hidden_size=128, num_layers=1, DIGITS=2):\r\n",
    "        super(Addition_Model, self).__init__()\r\n",
    "        # 初始化变量\r\n",
    "        self.DIGITS = DIGITS\r\n",
    "        self.MAXLEN = DIGITS + 1 + DIGITS\r\n",
    "        self.hidden_size = hidden_size\r\n",
    "        self.char_len = char_len\r\n",
    "\r\n",
    "        # 嵌入层\r\n",
    "        self.emb = nn.Embedding(\r\n",
    "            char_len, \r\n",
    "            embedding_size\r\n",
    "        )\r\n",
    "        \r\n",
    "        # 编码器\r\n",
    "        self.encoder = nn.LSTM(\r\n",
    "            input_size=embedding_size,\r\n",
    "            hidden_size=hidden_size,\r\n",
    "            num_layers=1\r\n",
    "        )\r\n",
    "        \r\n",
    "        # 解码器\r\n",
    "        self.decoder = nn.LSTM(\r\n",
    "            input_size=hidden_size,\r\n",
    "            hidden_size=hidden_size,\r\n",
    "            num_layers=num_layers\r\n",
    "        )\r\n",
    "        \r\n",
    "        # 全连接层\r\n",
    "        self.fc = nn.Linear(\r\n",
    "            hidden_size, \r\n",
    "            char_len\r\n",
    "        )\r\n",
    "    \r\n",
    "    # 重写模型前向计算函数\r\n",
    "    # 参数：输入[None, MAXLEN]、标签[None, DIGITS + 1]\r\n",
    "    def forward(self, inputs, labels=None):\r\n",
    "        # 嵌入层\r\n",
    "        out = self.emb(inputs)\r\n",
    "\r\n",
    "        # 编码器\r\n",
    "        out, (_, _) = self.encoder(out)\r\n",
    "\r\n",
    "        # 按时间步切分编码器输出\r\n",
    "        out = paddle.split(out, self.MAXLEN, axis=1)\r\n",
    "\r\n",
    "        # 取最后一个时间步的输出并复制 DIGITS + 1 次\r\n",
    "        out = paddle.expand(out[-1], [out[-1].shape[0], self.DIGITS + 1, self.hidden_size])\r\n",
    "\r\n",
    "        # 解码器\r\n",
    "        out, (_, _) = self.decoder(out)\r\n",
    "\r\n",
    "        # 全连接\r\n",
    "        out = self.fc(out)\r\n",
    "\r\n",
    "        # SoftMax层\r\n",
    "        out = nn.functional.softmax(out)\r\n",
    "\r\n",
    "        # 如果标签存在，则计算其损失和准确率\r\n",
    "        if labels is not None:\r\n",
    "            # 转置解码器输出\r\n",
    "            tmp = paddle.transpose(out, [0, 2, 1])\r\n",
    "\r\n",
    "            # 计算交叉熵损失\r\n",
    "            loss = nn.functional.cross_entropy(tmp, labels)\r\n",
    "\r\n",
    "            # 计算准确率\r\n",
    "            acc = paddle.metric.accuracy(paddle.reshape(out, [-1, self.char_len]), paddle.reshape(labels, [-1, 1]))\r\n",
    "\r\n",
    "            # 返回损失和准确率\r\n",
    "            return loss, acc\r\n",
    "\r\n",
    "        # 返回输出\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型训练与评估\n",
    "* 使用Adam作为优化器进行模型训练\n",
    "* 以模型准确率作为评价指标\n",
    "* 使用VisualDL对训练数据进行可视化\n",
    "* 训练过程中会同时进行模型评估和最佳模型的保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch:0 step: 0 loss:1.098665 acc:0.031250\n",
      "eval epoch:0 step: 0 loss:1.098665 acc:0.031250\n",
      "saving the best_model...\n",
      "train epoch:0 step: 20 loss:1.072399 acc:0.125000\n",
      "train epoch:0 step: 40 loss:1.013545 acc:0.187500\n",
      "train epoch:0 step: 60 loss:1.003058 acc:0.187500\n",
      "train epoch:0 step: 80 loss:0.936091 acc:0.385417\n",
      "train epoch:0 step: 100 loss:0.941665 acc:0.364583\n",
      "train epoch:0 step: 120 loss:0.914977 acc:0.406250\n",
      "train epoch:0 step: 140 loss:0.890783 acc:0.416667\n",
      "train epoch:1 step: 160 loss:0.948920 acc:0.375000\n",
      "train epoch:1 step: 180 loss:0.907602 acc:0.375000\n",
      "train epoch:1 step: 200 loss:0.917006 acc:0.406250\n",
      "train epoch:1 step: 220 loss:0.916337 acc:0.385417\n",
      "train epoch:1 step: 240 loss:0.935393 acc:0.395833\n",
      "train epoch:1 step: 260 loss:0.902810 acc:0.437500\n",
      "train epoch:1 step: 280 loss:0.928185 acc:0.385417\n",
      "train epoch:1 step: 300 loss:0.928819 acc:0.406250\n",
      "train epoch:2 step: 320 loss:0.931290 acc:0.406250\n",
      "train epoch:2 step: 340 loss:0.930144 acc:0.437500\n",
      "train epoch:2 step: 360 loss:0.920897 acc:0.354167\n",
      "train epoch:2 step: 380 loss:0.914073 acc:0.354167\n",
      "train epoch:2 step: 400 loss:0.936636 acc:0.375000\n"
     ]
    }
   ],
   "source": [
    "# 初始化log写入器\r\n",
    "log_writer = LogWriter(logdir=\"./log\")\r\n",
    "\r\n",
    "# 模型参数设置\r\n",
    "embedding_size = 128\r\n",
    "hidden_size=128\r\n",
    "num_layers=1\r\n",
    "\r\n",
    "# 训练参数设置\r\n",
    "epoch_num = 200\r\n",
    "learning_rate = 0.001\r\n",
    "log_iter = 20\r\n",
    "eval_iter = 500\r\n",
    "\r\n",
    "# 定义一些所需变量\r\n",
    "global_step = 0\r\n",
    "log_step = 0\r\n",
    "max_acc = 0\r\n",
    "\r\n",
    "# 实例化模型\r\n",
    "model = Addition_Model(\r\n",
    "    char_len=len(label_dict), \r\n",
    "    embedding_size=embedding_size, \r\n",
    "    hidden_size=hidden_size, \r\n",
    "    num_layers=num_layers, \r\n",
    "    DIGITS=DIGITS)\r\n",
    "\r\n",
    "# 将模型设置为训练模式\r\n",
    "model.train()\r\n",
    "\r\n",
    "# 设置优化器，学习率，并且把模型参数给优化器\r\n",
    "opt = paddle.optimizer.Adam(\r\n",
    "    learning_rate=learning_rate,\r\n",
    "    parameters=model.parameters()\r\n",
    ")\r\n",
    "\r\n",
    "# 启动训练，循环epoch_num个轮次\r\n",
    "for epoch in range(epoch_num):\r\n",
    "    # 遍历数据集读取数据\r\n",
    "    for batch_id, data in enumerate(train_reader()):\r\n",
    "        # 读取数据\r\n",
    "        inputs, labels = data\r\n",
    "\r\n",
    "        # 模型前向计算\r\n",
    "        loss, acc = model(inputs, labels=labels)\r\n",
    "\r\n",
    "        # 打印训练数据\r\n",
    "        if global_step%log_iter==0:\r\n",
    "            print('train epoch:%d step: %d loss:%f acc:%f' % (epoch, global_step, loss.numpy(), acc.numpy()))\r\n",
    "            log_writer.add_scalar(tag=\"train/loss\", step=log_step, value=loss.numpy())\r\n",
    "            log_writer.add_scalar(tag=\"train/acc\", step=log_step, value=acc.numpy())\r\n",
    "            log_step+=1\r\n",
    "\r\n",
    "        # 模型验证\r\n",
    "        if global_step%eval_iter==0:\r\n",
    "            model.eval()\r\n",
    "            losses = []\r\n",
    "            accs = []\r\n",
    "            for data in dev_reader():\r\n",
    "                loss, acc = model(inputs, labels=labels)\r\n",
    "                losses.append(loss.numpy())\r\n",
    "                accs.append(acc.numpy())\r\n",
    "            avg_loss = np.concatenate(losses).mean()\r\n",
    "            avg_acc = np.concatenate(accs).mean()\r\n",
    "            print('eval epoch:%d step: %d loss:%f acc:%f' % (epoch, global_step, avg_loss, avg_acc))\r\n",
    "            log_writer.add_scalar(tag=\"dev/loss\", step=log_step, value=avg_loss)\r\n",
    "            log_writer.add_scalar(tag=\"dev/acc\", step=log_step, value=avg_acc)\r\n",
    "\r\n",
    "            # 保存最佳模型\r\n",
    "            if avg_acc>max_acc:\r\n",
    "                max_acc = avg_acc\r\n",
    "                print('saving the best_model...')\r\n",
    "                paddle.save(model.state_dict(), 'best_model')\r\n",
    "            model.train()\r\n",
    "\r\n",
    "        # 反向传播\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        # 使用优化器进行参数优化\r\n",
    "        opt.step()\r\n",
    "\r\n",
    "        # 清除梯度\r\n",
    "        opt.clear_grad()\r\n",
    "\r\n",
    "        # 全局步数加一\r\n",
    "        global_step += 1\r\n",
    "\r\n",
    "# 保存最终模型\r\n",
    "paddle.save(model.state_dict(),'final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型测试\n",
    "* 使用保存的最佳模型进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model answer: 12+40=52 \n",
      "the true answer: 12+40=52\n"
     ]
    }
   ],
   "source": [
    "# 反转字符表\r\n",
    "label_dict_adv = {v: k for k, v in label_dict.items()}\r\n",
    "\r\n",
    "# 输入计算题目\r\n",
    "input_text = '12+40'\r\n",
    "\r\n",
    "# 编码输入为ID\r\n",
    "inputs = encoder(input_text, MAXLEN, label_dict)\r\n",
    "\r\n",
    "# 转换输入为向量形式\r\n",
    "inputs = np.array(inputs).reshape(-1, MAXLEN)\r\n",
    "inputs = paddle.to_tensor(inputs)\r\n",
    "\r\n",
    "# 加载模型\r\n",
    "params_dict, _ = paddle.load('best_model')\r\n",
    "model.set_dict(params_dict)\r\n",
    "\r\n",
    "# 设置为评估模式\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 模型推理\r\n",
    "out = model(inputs)\r\n",
    "\r\n",
    "# 结果转换\r\n",
    "result = ''.join([label_dict_adv[_] for _ in np.argmax(out.numpy(), -1).reshape(-1)])\r\n",
    "\r\n",
    "# 打印结果\r\n",
    "print('the model answer: %s=%s' % (input_text, result))\r\n",
    "print('the true answer: %s=%s' % (input_text, eval(input_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 总结\n",
    "* 你还可以通过变换网络结构，调整数据集，尝试不同的参数的方式来进一步提升本示例当中的数字加法的效果\n",
    "* 同时，也可以尝试在其他的类似的任务中用飞桨来完成实际的实践"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
