{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用LeNet在MNIST数据集实现图像分类\n",
    "\n",
    "**作者:** [PaddlePaddle](https://github.com/PaddlePaddle) <br>\n",
    "**日期:** 2021.03 <br>\n",
    "**摘要:** 本示例教程演示如何在MNIST数据集上用LeNet进行图像分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 一、环境配置\n",
    "\n",
    "本教程基于Paddle 2.0 编写，如果您的环境不是本版本，请先参考官网[安装](https://www.paddlepaddle.org.cn/install/quick) Paddle 2.0 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "print(paddle.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 二、数据加载\n",
    "手写数字的MNIST数据集，包含60,000个用于训练的示例和10,000个用于测试的示例。这些数字已经过尺寸标准化并位于图像中心，图像是固定大小(28x28像素)，其值为0到1。该数据集的官方地址为：http://yann.lecun.com/exdb/mnist 。\n",
    "\n",
    "我们使用飞桨框架自带的 ``paddle.vision.datasets.MNIST`` 完成mnist数据集的加载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download training data and load training data\n",
      "load finished\n"
     ]
    }
   ],
   "source": [
    "from paddle.vision.transforms import Compose, Normalize\n",
    "\n",
    "transform = Compose([Normalize(mean=[127.5],\n",
    "                               std=[127.5],\n",
    "                               data_format='CHW')])\n",
    "# 使用transform对数据集做归一化\n",
    "print('download training data and load training data')\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "print('load finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "取训练集中的一条数据看一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data0 label is: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJIAAACPCAYAAAARM4LLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACHBJREFUeJzt3V1oVOkZB/D/42j8ql9pZInZYBYVIRT8INYWi0atH13Q4E2JilZZWC/8aMFgTb3QCy+KQi803ixWUrGmFGvYtSwEXcyFuEgSDDbZNasuxs3i1yJq0QtdeXsxx+k8B5M5mXnmnDOZ/w9Czv+cZM4LPr7zzjmTZ8Q5B6JcjYp6ADQysJDIBAuJTLCQyAQLiUywkMgEC4lMsJDIRE6FJCJrRaRPRG6LyH6rQVHhkWyvbItIAsA3AFYBGADQAWCjc+6rwX6nrKzMVVVVZXU+ikZXV9cPzrnpmX5udA7n+DmA2865bwFARP4BoA7AoIVUVVWFzs7OHE5JYROR/iA/l8tTWwWA79LygLfPP5CPRaRTRDofP36cw+kozvK+2HbOfeKcq3HO1UyfnnGGpAKVSyF9D6AyLb/v7aMilEshdQCYIyIfiEgJgHoAn9kMiwpN1ott59yPIrILQBuABIBTzrles5FRQcnlVRucc58D+NxoLFTAeGWbTLCQyAQLiUywkMgEC4lMsJDIBAuJTLCQyAQLiUywkMgEC4lM5HSvrZi8efNG5WfPngX+3aamJpVfvnypcl9fn8onTpxQuaGhQeWWlhaVx40bp/L+/f9/+/zBgwcDjzMXnJHIBAuJTLCQyETRrJHu3bun8qtXr1S+evWqyleuXFH56dOnKp87d85sbJWVlSrv3r1b5dbWVpUnTZqk8rx581RetmyZ2diC4oxEJlhIZIKFRCZG7Brp+vXrKq9YsULl4VwHspZIJFQ+fPiwyhMnTlR58+bNKs+YMUPladOmqTx37txchzhsnJHIBAuJTLCQyMSIXSPNnDlT5bKyMpUt10iLFy9W2b9muXz5ssolJSUqb9myxWwsUeGMRCZYSGSChUQmRuwaqbS0VOWjR4+qfOHCBZUXLFig8p49e4Z8/Pnz56e2L126pI75rwP19PSofOzYsSEfuxBxRiITGQtJRE6JyCMR6UnbVyoiF0Xklvd92lCPQSNfkBmpGcBa3779AL5wzs0B8IWXqYgFao8sIlUA/u2c+5mX+wDUOufui0g5gHbnXMYbPDU1NS4uXW2fP3+usv89Pjt27FD55MmTKp85cya1vWnTJuPRxYeIdDnnajL9XLZrpPecc/e97QcA3svycWiEyHmx7ZJT2qDTGtsjF4dsC+mh95QG7/ujwX6Q7ZGLQ7bXkT4D8DsAf/a+f2o2opBMnjx5yONTpkwZ8nj6mqm+vl4dGzWq+K6qBHn53wLgSwBzRWRARD5CsoBWicgtAL/2MhWxjDOSc27jIIdWGo+FCljxzcGUFyP2XluuDh06pHJXV5fK7e3tqW3/vbbVq1fna1ixxRmJTLCQyAQLiUxk/VGk2YjTvbbhunPnjsoLFy5MbU+dOlUdW758uco1NfpW1c6dO1UWEYsh5kW+77URKSwkMsGX/wHNmjVL5ebm5tT29u3b1bHTp08PmV+8eKHy1q1bVS4vL892mJHhjEQmWEhkgoVEJrhGytKGDRtS27Nnz1bH9u7dq7L/FkpjY6PK/f39Kh84cEDlioqKrMcZFs5IZIKFRCZYSGSCt0jywN9K2f/n4du2bVPZ/2+wcqV+z+DFixftBjdMvEVCoWIhkQkWEpngGikCY8eOVfn169cqjxkzRuW2tjaVa2tr8zKud+EaiULFQiITLCQywXttBm7cuKGy/yO4Ojo6VPavifyqq6tVXrp0aQ6jCwdnJDLBQiITLCQywTVSQP6PVD9+/Hhq+/z58+rYgwcPhvXYo0frfwb/e7YLoU1O/EdIBSFIf6RKEbksIl+JSK+I/N7bzxbJlBJkRvoRwF7nXDWAXwDYKSLVYItkShOk0dZ9APe97f+KyNcAKgDUAaj1fuxvANoB/DEvowyBf11z9uxZlZuamlS+e/du1udatGiRyv73aK9fvz7rx47KsNZIXr/tBQCugS2SKU3gQhKRnwD4F4A/OOdUt/OhWiSzPXJxCFRIIjIGySL6u3Pu7WvdQC2S2R65OGRcI0my58pfAXztnPtL2qGCapH88OFDlXt7e1XetWuXyjdv3sz6XP6PJt23b5/KdXV1KhfCdaJMglyQXAJgC4D/iEi3t+9PSBbQP712yf0AfpufIVIhCPKq7QqAwTpBsUUyAeCVbTIyYu61PXnyRGX/x2R1d3er7G/lN1xLlixJbfv/1n/NmjUqjx8/PqdzFQLOSGSChUQmWEhkoqDWSNeuXUttHzlyRB3zvy96YGAgp3NNmDBBZf/Ht6ffH/N/PHsx4oxEJlhIZKKgntpaW1vfuR2E/0981q1bp3IikVC5oaFBZX93f9I4I5EJFhKZYCGRCba1oSGxrQ2FioVEJlhIZIKFRCZYSGSChUQmWEhkgoVEJlhIZIKFRCZYSGQi1HttIvIYyb/KLQPwQ2gnHp64ji2qcc10zmVs2hBqIaVOKtIZ5EZgFOI6triO6y0+tZEJFhKZiKqQPonovEHEdWxxHReAiNZINPLwqY1MhFpIIrJWRPpE5LaIRNpOWUROicgjEelJ2xeL3uGF2Ns8tEISkQSAEwB+A6AawEavX3dUmgGs9e2LS+/wwutt7pwL5QvALwG0peVGAI1hnX+QMVUB6EnLfQDKve1yAH1Rji9tXJ8CWBXX8TnnQn1qqwDwXVoe8PbFSex6hxdKb3Mutgfhkv/tI31Jm21v8yiEWUjfA6hMy+97++IkUO/wMOTS2zwKYRZSB4A5IvKBiJQAqEeyV3ecvO0dDkTYOzxAb3Mgbr3NQ140fgjgGwB3AByIeAHbguSH9bxGcr32EYCfIvlq6BaASwBKIxrbr5B82roBoNv7+jAu43vXF69skwkutskEC4lMsJDIBAuJTLCQyAQLiUywkMgEC4lM/A+jN2A4bkW+2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train_data0, train_label_0 = train_dataset[0][0],train_dataset[0][1]\n",
    "train_data0 = train_data0.reshape([28,28])\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(train_data0, cmap=plt.cm.binary)\n",
    "print('train_data0 label is: ' + str(train_label_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 三、组网\n",
    "用paddle.nn下的API，如`Conv2D`、`MaxPool2D`、`Linear`完成LeNet的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as F\n",
    "class LeNet(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
    "        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)\n",
    "        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)\n",
    "        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=120)\n",
    "        self.linear2 = paddle.nn.Linear(in_features=120, out_features=84)\n",
    "        self.linear3 = paddle.nn.Linear(in_features=84, out_features=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = paddle.flatten(x, start_axis=1,stop_axis=-1)\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 四、方式1：基于高层API，完成模型的训练与预测\n",
    "通过paddle提供的`Model` 构建实例，使用封装好的训练与测试接口，快速完成模型训练与测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.1 使用 `Model.fit`来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.metric import Accuracy\n",
    "model = paddle.Model(LeNet())   # 用Model封装模型\n",
    "optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "\n",
    "# 配置模型\n",
    "model.prepare(\n",
    "    optim,\n",
    "    paddle.nn.CrossEntropyLoss(),\n",
    "    Accuracy()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/2\n",
      "step 938/938 [==============================] - loss: 0.0467 - acc: 0.9536 - 9ms/step        \n",
      "Epoch 2/2\n",
      "step 938/938 [==============================] - loss: 0.0047 - acc: 0.9854 - 11ms/step        \n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(train_dataset,\n",
    "        epochs=2,\n",
    "        batch_size=64,\n",
    "        verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 4.2 使用 `Model.evaluate` 来预测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 157/157 [==============================] - loss: 4.2981e-04 - acc: 0.9850 - 7ms/step       \n",
      "Eval samples: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.00042981372], 'acc': 0.985}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 方式一结束\n",
    "以上就是方式一，可以快速、高效的完成网络模型训练与预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 五、方式2：基于基础API，完成模型的训练与预测\n",
    "### 5.1 模型训练\n",
    "组网后，开始对模型进行训练，先构建`train_loader`，加载训练数据，然后定义`train`函数，设置好损失函数后，按batch加载数据，完成模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 0, loss is: [3.31986], acc is: [0.078125]\n",
      "epoch: 0, batch_id: 300, loss is: [0.05698059], acc is: [0.984375]\n",
      "epoch: 0, batch_id: 600, loss is: [0.03642814], acc is: [0.984375]\n",
      "epoch: 0, batch_id: 900, loss is: [0.13067417], acc is: [0.953125]\n",
      "epoch: 1, batch_id: 0, loss is: [0.03294292], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 300, loss is: [0.09340447], acc is: [0.96875]\n",
      "epoch: 1, batch_id: 600, loss is: [0.12020883], acc is: [0.96875]\n",
      "epoch: 1, batch_id: 900, loss is: [0.0349952], acc is: [0.984375]\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# 加载训练集 batch_size 设为 64\n",
    "def train(model):\n",
    "    model.train()\n",
    "    epochs = 2\n",
    "    optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())\n",
    "    # 用Adam作为优化函数\n",
    "    for epoch in range(epochs):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            x_data = data[0]\n",
    "            y_data = data[1]\n",
    "            predicts = model(x_data)\n",
    "            loss = F.cross_entropy(predicts, y_data)\n",
    "            # 计算损失\n",
    "            acc = paddle.metric.accuracy(predicts, y_data)\n",
    "            loss.backward()\n",
    "            if batch_id % 300 == 0:\n",
    "                print(\"epoch: {}, batch_id: {}, loss is: {}, acc is: {}\".format(epoch, batch_id, loss.numpy(), acc.numpy()))\n",
    "            optim.step()\n",
    "            optim.clear_grad()\n",
    "model = LeNet()\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 5.2 模型验证\n",
    "训练完成后，需要验证模型的效果，此时，加载测试数据集，然后用训练好的模对测试集进行预测，计算损失与精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_id: 0, loss is: [0.01972857], acc is: [0.984375]\n",
      "batch_id: 20, loss is: [0.19958115], acc is: [0.9375]\n",
      "batch_id: 40, loss is: [0.23575728], acc is: [0.953125]\n",
      "batch_id: 60, loss is: [0.07018849], acc is: [0.984375]\n",
      "batch_id: 80, loss is: [0.02309197], acc is: [0.984375]\n",
      "batch_id: 100, loss is: [0.00239462], acc is: [1.]\n",
      "batch_id: 120, loss is: [0.01583934], acc is: [1.]\n",
      "batch_id: 140, loss is: [0.00399609], acc is: [1.]\n"
     ]
    }
   ],
   "source": [
    "test_loader = paddle.io.DataLoader(test_dataset, places=paddle.CPUPlace(), batch_size=64)\n",
    "# 加载测试数据集\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    batch_size = 64\n",
    "    for batch_id, data in enumerate(test_loader()):\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts = model(x_data)\n",
    "        # 获取预测结果\n",
    "        loss = F.cross_entropy(predicts, y_data)\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        if batch_id % 20 == 0:\n",
    "            print(\"batch_id: {}, loss is: {}, acc is: {}\".format(batch_id, loss.numpy(), acc.numpy()))\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 方式二结束\n",
    "以上就是方式二，通过底层API，可以清楚的看到训练和测试中的每一步过程。但是，这种方式比较复杂。因此，我们提供了训练方式一，使用高层API来完成模型的训练与预测。对比底层API，高层API能够更加快速、高效的完成模型的训练与测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 六、总结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以上就是用LeNet对手写数字数据及MNIST进行分类。本示例提供了两种训练模型的方式，一种可以快速完成模型的组建与预测，非常适合新手用户上手。另一种则需要多个步骤来完成模型的训练，适合进阶用户使用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
